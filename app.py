import streamlit as st
import sqlite3
from datetime import datetime
import hashlib
import os
import shutil
import recalc_fund_history  # ğŸ”¥ å¼•å…¥è®¡ç®—å¼•æ“
from pathlib import Path
import re
import calendar # ç”¨äºå¤„ç†æœˆä»½å¤©æ•°
from streamlit import cache_data  # å¦‚æœä¹‹å‰æ²¡å¼•
from datetime import timedelta
from data_provider import DataProvider

import time
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication

# ğŸ”¥ ä¿®æ”¹è¿™é‡Œï¼šæ™ºèƒ½åˆ¤æ–­æ•°æ®åº“è·¯å¾„
# å¦‚æœç³»ç»Ÿé‡Œæœ‰ /share è¿™ä¸ªæ–‡ä»¶å¤¹ï¼Œè¯´æ˜æ˜¯åœ¨ HA é‡Œï¼Œå°±æŠŠæ•°æ®åº“å­˜é‚£é‡Œ
if os.path.exists('/share'):
    DB_FILE = '/share/asset_tracker.db'
else:
    # å¦åˆ™ï¼ˆåœ¨ç”µè„‘å¼€å‘æ—¶ï¼‰å­˜å½“å‰ç›®å½•
    DB_FILE = 'asset_tracker.db'
    
# --- å…¼å®¹æ€§ä¿®å¤ ---
# æŸäº›æ—§ç‰ˆåº“å¯èƒ½è¿˜åœ¨æ‰¾ np.bool8ï¼Œè¿™é‡Œåšä¸€ä¸ªç®€å•çš„æ˜ å°„é˜²æ­¢æŠ¥é”™
#if not hasattr(np, 'bool8'):
#    np.bool8 = np.bool_

# --- é…ç½® ---
st.set_page_config(
    page_title="ä¸ªäººèµ„äº§ç®¡ç†ç³»ç»Ÿ",
    page_icon="ğŸ’¼", # ç›´æ¥å†™æ­» Emojiï¼Œä¸è¦åŠ è½½å›¾ç‰‡äº†
    layout="wide"
)

DB_FILE = 'asset_tracker.db'

# --- æ•°æ®åº“å·¥å…·å‡½æ•° ---
def get_db_connection():
    conn = sqlite3.connect(DB_FILE)
    conn.row_factory = sqlite3.Row
    return conn

def get_all_usernames():
    """è·å–æ•°æ®åº“ä¸­æ‰€æœ‰å·²æ³¨å†Œçš„ç”¨æˆ·ååˆ—è¡¨"""
    conn = get_db_connection()
    try:
        users = conn.execute('SELECT username FROM users').fetchall()
        # å°†ç»“æœè½¬æ¢ä¸ºçº¯å­—ç¬¦ä¸²åˆ—è¡¨ ['çˆ¸çˆ¸', 'å¦ˆå¦ˆ', 'å­©å­']
        return [u['username'] for u in users]
    except Exception:
        return []
    finally:
        conn.close()

def init_db():
    """ç¡®ä¿æ•°æ®åº“è¡¨å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    # è¿™é‡Œç›´æ¥å¤ç”¨ä½ æä¾›çš„ init_db.py çš„é€»è¾‘ï¼Œä¸ºèŠ‚çœç¯‡å¹…ï¼Œä»…åšæ£€æŸ¥
    if not os.path.exists(DB_FILE):
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå»ºè®®å…ˆè¿è¡Œ init_db.py æˆ–åœ¨è¿™é‡Œå†™å®Œæ•´çš„å»ºè¡¨é€»è¾‘
        st.error("æ•°æ®åº“æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè¿è¡Œ init_db.py åˆå§‹åŒ–æ•°æ®åº“ï¼")
        st.stop()

# --- æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½è¡¨æ ¼åŒæ­¥ ---
def save_changes_to_db(edited_df, original_df, table_name, id_col, user_id, fixed_cols=None):
    """
    å¯¹æ¯”ç¼–è¾‘å‰åçš„æ•°æ®ï¼Œè‡ªåŠ¨å¤„ç†æ–°å¢ã€ä¿®æ”¹ã€åˆ é™¤
    :param edited_df: ç¼–è¾‘åçš„ DataFrame
    :param original_df: åŸå§‹ä»æ•°æ®åº“è¯»å‡ºçš„ DataFrame
    :param table_name: æ•°æ®åº“è¡¨å
    :param id_col: ä¸»é”®åˆ—å (å¦‚ 'asset_id')
    :param user_id: å½“å‰ç”¨æˆ·ID
    :param fixed_cols: éœ€è¦åœ¨æ’å…¥/æ›´æ–°æ—¶å¼ºåˆ¶å›ºå®šçš„åˆ— (å¦‚ {'user_id': 1})
    """
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # 1. å¤„ç†åˆ é™¤
        # åŸè¡¨ä¸­å­˜åœ¨ï¼Œä½†ç¼–è¾‘åè¡¨ä¸­ä¸å­˜åœ¨çš„ IDï¼Œå°±æ˜¯è¢«åˆ é™¤çš„
        if not original_df.empty and not edited_df.empty:
            orig_ids = set(original_df[id_col].dropna().astype(int))
            new_ids = set(edited_df[id_col].dropna().astype(int))
            deleted_ids = orig_ids - new_ids
        elif not original_df.empty and edited_df.empty:
            deleted_ids = set(original_df[id_col].dropna().astype(int))
        else:
            deleted_ids = set()

        for del_id in deleted_ids:
            # çº§è”åˆ é™¤å¤„ç†ï¼ˆç®€å•ç²—æš´ç‰ˆï¼‰
            if table_name == 'assets':
                cursor.execute('DELETE FROM snapshots WHERE asset_id = ?', (del_id,))
                cursor.execute('DELETE FROM asset_tag_map WHERE asset_id = ?', (del_id,))
            elif table_name == 'tags':
                cursor.execute('DELETE FROM asset_tag_map WHERE tag_id = ?', (del_id,))
            
            cursor.execute(f'DELETE FROM {table_name} WHERE {id_col} = ? AND user_id = ?', (del_id, user_id))

        # 2. å¤„ç†æ–°å¢å’Œä¿®æ”¹
        for index, row in edited_df.iterrows():
            # å‡†å¤‡æ•°æ®å­—å…¸
            data = row.to_dict()
            if fixed_cols:
                data.update(fixed_cols)
            
            # å¦‚æœ ID ä¸ºç©ºæˆ– NaNï¼Œè§†ä¸ºæ–°å¢
            if pd.isna(row[id_col]) or row[id_col] == 0:
                # æ„å»º INSERT è¯­å¥
                cols = [k for k in data.keys() if k != id_col and k != 'created_at'] # æ’é™¤è‡ªå¢IDå’Œæ—¶é—´
                placeholders = ', '.join(['?'] * len(cols))
                col_names = ', '.join(cols)
                values = [data[c] for c in cols]
                
                query = f"INSERT INTO {table_name} ({col_names}) VALUES ({placeholders})"
                cursor.execute(query, values)
            
            # å¦‚æœ ID å­˜åœ¨ä¸”åœ¨åŸå§‹ ID é›†åˆä¸­ï¼Œè§†ä¸ºä¿®æ”¹
            elif row[id_col] in (original_df[id_col].values if not original_df.empty else []):
                # æ£€æŸ¥æ•°æ®æ˜¯å¦çœŸçš„å˜äº†ï¼ˆç®€åŒ–èµ·è§ï¼Œè¿™é‡Œç›´æ¥ Updateï¼Œæ€§èƒ½æŸè€—å¯å¿½ç•¥ï¼‰
                cols = [k for k in data.keys() if k != id_col and k != 'created_at']
                set_clause = ', '.join([f"{c} = ?" for c in cols])
                values = [data[c] for c in cols]
                values.append(row[id_col]) # Where clause value
                values.append(user_id)     # Where clause user_id
                
                query = f"UPDATE {table_name} SET {set_clause} WHERE {id_col} = ? AND user_id = ?"
                cursor.execute(query, values)

        conn.commit()
        st.success("æ•°æ®å·²æˆåŠŸåŒæ­¥ï¼")
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
        return False
    finally:
        conn.close()

# --- æ ¸å¿ƒé€»è¾‘ï¼šçº§è”åˆ é™¤ç”¨æˆ·æ‰€æœ‰æ•°æ® ---
def delete_user_fully(target_user_id):
    """
    å½»åº•åˆ é™¤ä¸€ä¸ªç”¨æˆ·åŠå…¶åä¸‹æ‰€æœ‰æ•°æ®ã€‚
    é¡ºåºå¾ˆé‡è¦ï¼šå…ˆåˆ å­è¡¨ï¼ˆå¿«ç…§ã€å…³è”ï¼‰ï¼Œå†åˆ ä¸»è¡¨ï¼ˆèµ„äº§ï¼‰ï¼Œæœ€ååˆ ç”¨æˆ·ã€‚
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    try:
        # 1. è·å–è¯¥ç”¨æˆ·æ‰€æœ‰çš„ asset_idï¼Œä»¥ä¾¿åˆ é™¤å¿«ç…§å’Œæ ‡ç­¾å…³è”
        assets = conn.execute('SELECT asset_id FROM assets WHERE user_id = ?', (target_user_id,)).fetchall()
        asset_ids = [str(row['asset_id']) for row in assets]
        
        if asset_ids:
            # SQL IN è¯­æ³•éœ€è¦å ä½ç¬¦
            placeholders = ','.join(['?'] * len(asset_ids))
            
            # åˆ é™¤ snapshots (å…³è” asset_id)
            cursor.execute(f'DELETE FROM snapshots WHERE asset_id IN ({placeholders})', asset_ids)
            
            # åˆ é™¤ asset_tag_map (å…³è” asset_id)
            cursor.execute(f'DELETE FROM asset_tag_map WHERE asset_id IN ({placeholders})', asset_ids)

        # 2. åˆ é™¤å±äºè¯¥ç”¨æˆ·çš„ç›´æ¥æ•°æ®è¡¨
        tables_with_userid = [
            'assets',           # èµ„äº§è¡¨
            'tags',             # æ ‡ç­¾è¡¨
            'cashflows',        # ç°é‡‘æµ
            'investment_plans', # å®šæŠ•è®¡åˆ’
            'investment_notes', # ç¬”è®°
            'monthly_profits',  # æœˆåº¦æ”¶ç›Š
            'monthly_reviews',  # æœˆåº¦å¤ç›˜
            'rebalance_targets',# å†å¹³è¡¡ç›®æ ‡
            'user_sessions'     # ä¼šè¯è®°å½•
        ]
        
        for table in tables_with_userid:
            cursor.execute(f'DELETE FROM {table} WHERE user_id = ?', (target_user_id,))

        # 3. æœ€ååˆ é™¤ç”¨æˆ·æœ¬èº«
        cursor.execute('DELETE FROM users WHERE user_id = ?', (target_user_id,))
        
        conn.commit()
        return True, "åˆ é™¤æˆåŠŸ"
    except Exception as e:
        conn.rollback()
        return False, f"åˆ é™¤å¤±è´¥: {str(e)}"
    finally:
        conn.close()

# --- é¡µé¢æ¨¡å— ---
# --- ç®€åŒ–ç‰ˆç”¨æˆ·ç®¡ç† (æ— å¯†ç æ¨¡å¼) ---
def get_or_create_user_by_name(username):
    """
    æ ¹æ®åå­—ç›´æ¥è·å–ç”¨æˆ·ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºã€‚
    ä¸å†æ ¡éªŒå¯†ç ï¼Œä¸»æ‰“ä¸€ä¸ªå®¶åº­å†…éƒ¨äº’ä¿¡ã€‚
    """
    conn = get_db_connection()
    try:
        # 1. å°è¯•æŸ¥æ‰¾ç”¨æˆ·
        user = conn.execute('SELECT * FROM users WHERE username = ?', (username,)).fetchone()
        
        if user:
            return dict(user)
        else:
            # 2. å¦‚æœä¸å­˜åœ¨ï¼Œè‡ªåŠ¨æ³¨å†Œä¸€ä¸ª (å¯†ç ç•™ç©ºå³å¯ï¼Œåæ­£ä¸æŸ¥äº†)
            # æ³¨æ„ï¼šè¿™é‡Œç»™ä¸€ä¸ªé»˜è®¤åçš„ dummy å¯†ç å“ˆå¸Œï¼Œé˜²æ­¢æ•°æ®åº“éç©ºçº¦æŸæŠ¥é”™
            dummy_hash = hashlib.sha256("123456".encode()).hexdigest() 
            cursor = conn.execute('INSERT INTO users (username, password_hash) VALUES (?, ?)', 
                                 (username, dummy_hash))
            user_id = cursor.lastrowid
            conn.commit()
            
            # è¿”å›æ–°åˆ›å»ºçš„ç”¨æˆ·
            return {'user_id': user_id, 'username': username}
    except Exception as e:
        st.error(f"ç”¨æˆ·è·å–å¤±è´¥: {e}")
        return None
    finally:
        conn.close()

# âŒ åˆ é™¤æˆ–æ³¨é‡Šæ‰åŸæ¥çš„: hash_password, verify_user, create_user, create_session, get_user_from_token
# âŒ åˆ é™¤æˆ–æ³¨é‡Šæ‰åŸæ¥çš„: page_login å‡½æ•°

def page_assets_tags():
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("èµ„äº§ä¸æ ‡ç­¾ç®¡ç†")
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()
    
    # --- å…¬å…±ç­›é€‰é€»è¾‘ (å°è£…åœ¨è¿™é‡Œä»¥ä¾¿å¤ç”¨) ---
    def apply_advanced_filters(df, context_key):
        """
        df: å¿…é¡»åŒ…å« asset_id, name, code åˆ—
        è¿”å›: ç­›é€‰åçš„ df
        """
        with st.expander("ğŸ” é«˜çº§ç­›é€‰ (æ”¯æŒæŸ¥æ‰¾æœªåˆ†ç±»èµ„äº§)", expanded=False):
            c1, c2, c3 = st.columns([2, 1, 2])
            
            # 1. å…³é”®å­—æœç´¢
            with c1:
                kw = st.text_input("1. å…³é”®å­—æœç´¢", placeholder="èµ„äº§åæˆ–ä»£ç ...", key=f"kw_{context_key}")
            
            # 2. æ ‡ç­¾ç»„é€‰æ‹©
            # è·å–æ‰€æœ‰æ ‡ç­¾ç»„
            all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
            groups_list = ["(ä¸ç­›é€‰)"] + all_groups['tag_group'].tolist()
            
            with c2:
                sel_group = st.selectbox("2. é€‰æ‹©æ ‡ç­¾ç»„", groups_list, key=f"grp_{context_key}")
            
            # 3. æ ‡ç­¾åé€‰æ‹© (æ ¹æ®ç»„åŠ¨æ€å˜åŒ–)
            selected_tag_names = []
            if sel_group != "(ä¸ç­›é€‰)":
                # è·å–è¯¥ç»„ä¸‹çš„æ‰€æœ‰æ ‡ç­¾
                tags_in_group = pd.read_sql("SELECT tag_name FROM tags WHERE user_id = ? AND tag_group = ?", 
                                          conn, params=(user_id, sel_group))
                # â˜…â˜…â˜… æ ¸å¿ƒåŠŸèƒ½ï¼šæ·»åŠ ã€æ— æ ‡ç­¾ã€‘é€‰é¡¹ â˜…â˜…â˜…
                options = ["ã€æ— æ­¤æ ‡ç­¾ã€‘"] + tags_in_group['tag_name'].tolist()
                
                with c3:
                    selected_tag_names = st.multiselect(
                        f"3. ç­›é€‰ '{sel_group}' ä¸‹çš„çŠ¶æ€", 
                        options=options,
                        key=f"tag_{context_key}",
                        placeholder="ç•™ç©ºåˆ™æ˜¾ç¤ºå…¨éƒ¨"
                    )
        
        # --- å¼€å§‹æ‰§è¡Œç­›é€‰ ---
        filtered_ids = df['asset_id'].tolist()
        
        # A. å…³é”®å­—è¿‡æ»¤
        if kw:
            df = df[df['name'].str.contains(kw, case=False) | df['code'].str.contains(kw, case=False, na=False)]
            filtered_ids = df['asset_id'].tolist()
            
        # B. æ ‡ç­¾è¿‡æ»¤ (æ ¸å¿ƒé€»è¾‘)
        if sel_group != "(ä¸ç­›é€‰)" and selected_tag_names:
            # 1. æ‰¾å‡ºåœ¨è¯¥ç»„ä¸‹ï¼Œæ‹¥æœ‰ç‰¹å®šæ ‡ç­¾çš„èµ„äº§ID
            # å…ˆæŸ¥å‡ºæ‰€æœ‰æ‰“è¿‡è¯¥ç»„æ ‡ç­¾çš„æ˜ å°„å…³ç³»
            sql_labeled = '''
                SELECT atm.asset_id, t.tag_name 
                FROM asset_tag_map atm
                JOIN tags t ON atm.tag_id = t.tag_id
                WHERE t.user_id = ? AND t.tag_group = ?
            '''
            df_labeled = pd.read_sql(sql_labeled, conn, params=(user_id, sel_group))
            
            target_ids = set()
            
            # æƒ…å†µ1: ç”¨æˆ·é€‰äº† ã€æ— æ­¤æ ‡ç­¾ã€‘
            if "ã€æ— æ­¤æ ‡ç­¾ã€‘" in selected_tag_names:
                # åœ¨è¯¥ç»„ä¸‹æœ‰è®°å½•çš„èµ„äº§ID
                ids_with_tags = set(df_labeled['asset_id'].unique())
                # å½“å‰ä¸Šä¸‹æ–‡æ‰€æœ‰èµ„äº§ID
                all_current_ids = set(df['asset_id'].unique())
                # å·®é›† = æ²¡æœ‰è¯¥ç»„æ ‡ç­¾çš„èµ„äº§
                ids_without_tags = all_current_ids - ids_with_tags
                target_ids.update(ids_without_tags)
            
            # æƒ…å†µ2: ç”¨æˆ·é€‰äº†å…·ä½“çš„æ ‡ç­¾ (å¦‚ "é«˜é£é™©")
            real_tags = [t for t in selected_tag_names if t != "ã€æ— æ­¤æ ‡ç­¾ã€‘"]
            if real_tags:
                ids_with_specific_tags = set(df_labeled[df_labeled['tag_name'].isin(real_tags)]['asset_id'])
                target_ids.update(ids_with_specific_tags)
            
            # å–äº¤é›†ï¼šæ—¢æ»¡è¶³å…³é”®å­—ï¼Œåˆæ»¡è¶³æ ‡ç­¾æ¡ä»¶
            df = df[df['asset_id'].isin(target_ids)]
            
        return df

    tab1, tab2, tab3 = st.tabs(["1. èµ„äº§åˆ—è¡¨", "2. æ ‡ç­¾å®šä¹‰", "3. å…³è”æ‰“æ ‡"])
    
    # 1. èµ„äº§ç®¡ç†
    with tab1:
        # --- ä¿®æ”¹ç‚¹1: SQL å¢åŠ  auto_update ---
        assets_df = pd.read_sql(
            'SELECT asset_id, name, code, type, currency, remarks, auto_update FROM assets WHERE user_id = ?', 
            conn, params=(user_id,)
        )
        
        # åº”ç”¨ç­›é€‰ (ä¿æŒä¸å˜)
        assets_df = apply_advanced_filters(assets_df, "tab1")
        
        st.caption(f"å…±æ˜¾ç¤º {len(assets_df)} æ¡èµ„äº§")
        
        # --- ä¿®æ”¹ç‚¹2: é…ç½® auto_update åˆ— ---
        edited_assets = st.data_editor(
            assets_df,
            num_rows="dynamic",
            column_config={
                "asset_id": st.column_config.NumberColumn("ID", disabled=True),
                "name": st.column_config.TextColumn("èµ„äº§åç§°", required=True),
                "code": "ä»£ç ",
                "type": st.column_config.SelectboxColumn("å¤§ç±»", options=["åŸºé‡‘", "è‚¡ç¥¨", "å€ºåˆ¸", "ç°é‡‘", "å…¶ä»–"]),
                "currency": st.column_config.SelectboxColumn("å¸ç§", options=["CNY", "USD", "HKD", "JPY", "EUR", "GBP", "BTC"], required=True, default="CNY", width="small"),
                # ğŸ”¥ æ–°å¢é…ç½®
                "auto_update": st.column_config.CheckboxColumn("è‡ªåŠ¨æ›´æ–°?", help="å‹¾é€‰åï¼Œ'ä¸€é”®æ›´æ–°'åŠŸèƒ½ä¼šè‡ªåŠ¨æ‹‰å–è¯¥èµ„äº§å‡€å€¼", default=False),
                "remarks": st.column_config.TextColumn("å¤‡æ³¨", width="medium")
            },
            key="editor_assets",
            use_container_width=True
        )
        
        if st.button("ğŸ’¾ ä¿å­˜èµ„äº§å˜åŠ¨", type="primary"):
            if save_changes_to_db(edited_assets, assets_df, 'assets', 'asset_id', user_id, fixed_cols={'user_id': user_id}):
                st.rerun()

    # 2. æ ‡ç­¾ç®¡ç† (ä¸éœ€è¦ç­›é€‰ï¼Œé€»è¾‘ä¸å˜)
    with tab2:
        tags_df = pd.read_sql('SELECT tag_id, tag_group, tag_name FROM tags WHERE user_id = ?', conn, params=(user_id,))
        edited_tags = st.data_editor(
            tags_df,
            num_rows="dynamic",
            column_config={
                "tag_id": st.column_config.NumberColumn("ID", disabled=True),
                "tag_group": st.column_config.TextColumn("æ ‡ç­¾ç»„", required=True),
                "tag_name": st.column_config.TextColumn("æ ‡ç­¾å", required=True)
            },
            key="editor_tags",
            use_container_width=True
        )
        if st.button("ğŸ’¾ ä¿å­˜æ ‡ç­¾å˜åŠ¨", type="primary"):
            if save_changes_to_db(edited_tags, tags_df, 'tags', 'tag_id', user_id, fixed_cols={'user_id': user_id}):
                st.rerun()

    # 3. å…³è”æ‰“æ ‡ (çº§è”ç­›é€‰ + å…¨é€‰æ”¯æŒ)
    with tab3:
        st.write("### ğŸ·ï¸ æ‰¹é‡èµ„äº§æ‰“æ ‡")
        
        # --- A. å‡†å¤‡èµ„äº§åˆ—è¡¨æ•°æ® ---
        df_assets_tags = pd.read_sql('''
            SELECT 
                a.asset_id, 
                a.name, 
                a.code, 
                GROUP_CONCAT(t.tag_group || '-' || t.tag_name, ', ') as "å½“å‰æ ‡ç­¾"
            FROM assets a
            LEFT JOIN asset_tag_map atm ON a.asset_id = atm.asset_id
            LEFT JOIN tags t ON atm.tag_id = t.tag_id
            WHERE a.user_id = ?
            GROUP BY a.asset_id
        ''', conn, params=(user_id,))
        
        # åˆå§‹åŒ–é€‰æ‹©åˆ—ï¼ˆé»˜è®¤ä¸º Falseï¼Œåç»­å¯èƒ½ä¼šè¢«å…¨é€‰æŒ‰é’®è¦†ç›–ï¼‰
        df_assets_tags.insert(0, "é€‰æ‹©", False)

        # --- B. åº”ç”¨é«˜çº§ç­›é€‰ ---
        df_filtered = apply_advanced_filters(df_assets_tags, "tab3")
        
        # --- C. å…¨é€‰/åé€‰ æ§åˆ¶åŒº (æ–°å¢) ---
        # å¼•å…¥ session state æ¥æ§åˆ¶ data_editor çš„é‡ç½®
        if 'tag_batch_version' not in st.session_state:
            st.session_state.tag_batch_version = 0
        if 'tag_batch_default_val' not in st.session_state:
            st.session_state.tag_batch_default_val = False

        c_info, c_btn1, c_btn2 = st.columns([3, 1, 1])
        with c_info:
             st.caption(f"å½“å‰ç­›é€‰ç»“æœ: {len(df_filtered)} ä¸ªèµ„äº§")
        
        with c_btn1:
            if st.button("âœ… å…¨é€‰å½“å‰", key="btn_sel_all", help="é€‰ä¸­å½“å‰åˆ—è¡¨ä¸­çš„æ‰€æœ‰èµ„äº§", use_container_width=True):
                st.session_state.tag_batch_default_val = True
                st.session_state.tag_batch_version += 1 # å¼ºåˆ¶æ›´æ–° keyï¼Œè§¦å‘è¡¨æ ¼é‡ç»˜
                st.rerun()
        
        with c_btn2:
            if st.button("â¬œ å–æ¶ˆå…¨é€‰", key="btn_sel_none", help="å–æ¶ˆæ‰€æœ‰å‹¾é€‰", use_container_width=True):
                st.session_state.tag_batch_default_val = False
                st.session_state.tag_batch_version += 1
                st.rerun()

        # æ ¹æ®æŒ‰é’®çŠ¶æ€ï¼Œå¼ºåˆ¶è®¾ç½®æŸä¸€åˆ—çš„å€¼
        df_filtered["é€‰æ‹©"] = st.session_state.tag_batch_default_val

        # --- D. è¡¨æ ¼æ˜¾ç¤º ---
        # å…³é”®ç‚¹ï¼škey åŒ…å«äº† versionã€‚ä¸€æ—¦ version å˜äº†ï¼ŒStreamlit ä¼šè®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„è¡¨æ ¼ï¼Œ
        # ä»è€Œä¸¢å¼ƒä¹‹å‰çš„ç¼–è¾‘çŠ¶æ€ï¼Œé‡æ–°åŠ è½½ df_filtered (ä¹Ÿå°±æ˜¯æˆ‘ä»¬åˆšè®¾ä¸º True çš„é‚£äº›æ•°æ®)
        unique_key = f"tag_editor_{len(df_filtered)}_{st.session_state.tag_batch_version}"
        
        edited_df = st.data_editor(
            df_filtered,
            column_config={
                "é€‰æ‹©": st.column_config.CheckboxColumn("âœ…", default=False),
                "asset_id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
                "name": st.column_config.TextColumn("èµ„äº§åç§°", disabled=True),
                "code": st.column_config.TextColumn("ä»£ç ", disabled=True),
                "å½“å‰æ ‡ç­¾": st.column_config.TextColumn("å½“å‰æ ‡ç­¾", disabled=True, width="large"),
            },
            hide_index=True,
            use_container_width=True,
            key=unique_key
        )
        
        # --- E. æ“ä½œåŒºåŸŸ (çº§è”æ ‡ç­¾é€‰æ‹©) ---
        st.divider()
        st.markdown("##### ğŸ› ï¸ æ‰¹é‡æ“ä½œ")
        
        col_actions, col_submit = st.columns([3, 1])
        
        with col_actions:
            all_tags_data = conn.execute('SELECT tag_id, tag_group, tag_name FROM tags WHERE user_id = ? ORDER BY tag_group, tag_name', (user_id,)).fetchall()
            
            if not all_tags_data:
                st.warning("æš‚æ— æ ‡ç­¾ï¼Œè¯·å…ˆå»ã€æ ‡ç­¾å®šä¹‰ã€‘é¡µç­¾æ·»åŠ ã€‚")
                selected_tags_to_apply = []
                action_mode = "â• æ·»åŠ "
            else:
                all_groups = sorted(list(set([t['tag_group'] for t in all_tags_data])))
                
                # [ç¬¬ä¸€çº§] æ ‡ç­¾ç»„
                filter_groups = st.multiselect(
                    "1. å…ˆç­›é€‰æ ‡ç­¾ç»„", 
                    options=all_groups,
                    placeholder="ç•™ç©ºåˆ™æ˜¾ç¤ºå…¨éƒ¨æ ‡ç­¾...",
                    key="tag_action_group_filter"
                )
                
                # [ç¬¬äºŒçº§] å…·ä½“æ ‡ç­¾
                if filter_groups:
                    available_tags = [t for t in all_tags_data if t['tag_group'] in filter_groups]
                else:
                    available_tags = all_tags_data
                
                tag_options = {t['tag_id']: f"ã€{t['tag_group']}ã€‘{t['tag_name']}" for t in available_tags}
                
                selected_tags_to_apply = st.multiselect(
                    f"2. é€‰æ‹©è¦åº”ç”¨çš„æ ‡ç­¾ (å¯é€‰ {len(available_tags)} ä¸ª)", 
                    options=tag_options.keys(), 
                    format_func=lambda x: tag_options[x],
                    placeholder="å¯å¤šé€‰...",
                    key="tag_action_final_select"
                )
                
                action_mode = st.radio("3. æ“ä½œæ¨¡å¼", ["â• æ·»åŠ  (ä¿ç•™å·²æœ‰)", "ğŸ”„ è¦†ç›– (æ¸…é™¤æ—§æ ‡)", "â– ç§»é™¤ (ä»…åˆ é€‰ä¸­)"], horizontal=True)

        with col_submit:
            st.write(" ")
            st.write(" ")
            st.write(" ")
            if st.button("ğŸš€ æ‰§è¡Œæ›´æ–°", type="primary", use_container_width=True):
                # ç»Ÿè®¡æœ‰å¤šå°‘è¡Œè¢«é€‰ä¸­äº†
                selected_assets = edited_df[edited_df["é€‰æ‹©"] == True]["asset_id"].tolist()
                
                if not selected_assets:
                    st.warning("è¯·åœ¨è¡¨æ ¼å·¦ä¾§å‹¾é€‰è‡³å°‘ä¸€ä¸ªèµ„äº§ï¼")
                elif not selected_tags_to_apply:
                    st.warning("è¯·é€‰æ‹©è¦æ“ä½œçš„æ ‡ç­¾ï¼")
                else:
                    try:
                        cursor = conn.cursor()
                        if "è¦†ç›–" in action_mode:
                            placeholders = ','.join(['?'] * len(selected_assets))
                            cursor.execute(f'DELETE FROM asset_tag_map WHERE asset_id IN ({placeholders})', selected_assets)
                            for aid in selected_assets:
                                for tid in selected_tags_to_apply:
                                    cursor.execute('INSERT INTO asset_tag_map (asset_id, tag_id) VALUES (?, ?)', (aid, tid))
                                    
                        elif "æ·»åŠ " in action_mode:
                            for aid in selected_assets:
                                for tid in selected_tags_to_apply:
                                    cursor.execute('INSERT OR IGNORE INTO asset_tag_map (asset_id, tag_id) VALUES (?, ?)', (aid, tid))
                                    
                        elif "ç§»é™¤" in action_mode:
                            for aid in selected_assets:
                                for tid in selected_tags_to_apply:
                                    cursor.execute('DELETE FROM asset_tag_map WHERE asset_id = ? AND tag_id = ?', (aid, tid))
                                    
                        conn.commit()
                        st.success(f"âœ… æˆåŠŸæ›´æ–° {len(selected_assets)} ä¸ªèµ„äº§ï¼")
                        
                        # æ›´æ–°åï¼Œæˆ‘ä»¬é‡ç½®ä¸€ä¸‹å…¨é€‰çŠ¶æ€ï¼Œé˜²æ­¢è¯¯æ“ä½œ
                        st.session_state.tag_batch_default_val = False
                        st.session_state.tag_batch_version += 1
                        
                        import time
                        time.sleep(0.5)
                        st.rerun()
                    except Exception as e:
                        conn.rollback()
                        st.error(str(e))
    conn.close()

# --- æ”¾åœ¨ page_data_entry ä¹‹å‰ ---
def execute_daily_plans_safe(user_id, target_date_str):
    """
    å®‰å…¨æ‰§è¡Œå½“æ—¥å®šæŠ•è®¡åˆ’ (å«æˆæœ¬åŠ æƒå¹³å‡è®¡ç®—)
    """
    from datetime import datetime
    import pandas as pd
    
    conn = get_db_connection()
    logs = []
    
    try:
        # 1. è·å–ä»Šæ—¥éœ€æ‰§è¡Œçš„è®¡åˆ’
        plans = conn.execute('''
            SELECT p.*, a.code, a.type, a.name as asset_name
            FROM investment_plans p
            JOIN assets a ON p.asset_id = a.asset_id
            WHERE p.user_id = ? AND p.is_active = 1
        ''', (user_id,)).fetchall()
        
        target_date = datetime.strptime(target_date_str, '%Y-%m-%d').date()
        
        executed_count = 0
        
        for plan in plans:
            # --- A. æ£€æŸ¥æ—¥æœŸ (ä¿æŒä¸å˜) ---
            freq = plan['frequency']
            exec_day = int(plan['execution_day'])
            is_due = False
            if freq == 'æ¯å¤©': is_due = True
            elif freq == 'æ¯å‘¨' and target_date.weekday() == exec_day: is_due = True
            elif freq == 'æ¯æœˆ' and target_date.day == exec_day: is_due = True
            
            if not is_due: continue

            # --- B. å¹‚ç­‰æ€§æ£€æŸ¥ (ä¿æŒä¸å˜) ---
            check_note_pattern = f"è‡ªåŠ¨å®šæŠ•: {plan['asset_name']}"
            exist_flow = conn.execute('''
                SELECT id FROM cashflows 
                WHERE user_id = ? AND date = ? AND category = 'å®šæŠ•æ‰£æ¬¾' AND note LIKE ?
            ''', (user_id, target_date_str, f"%{check_note_pattern}%")).fetchone()
            if exist_flow:
                logs.append(f"â­ï¸ è·³è¿‡: {plan['asset_name']} (ä»Šæ—¥å·²æ‰§è¡Œ)")
                continue

            # --- C. æ‰§è¡Œé€»è¾‘ ---
            asset_id = plan['asset_id']
            amount = plan['amount']
            source_id = plan['source_asset_id']
            code = plan['code']
            
            # === Part 1: ä¹°å…¥ç›®æ ‡èµ„äº§ (æ›´æ–°ä»½é¢ & æ‘Šè–„æˆæœ¬) ===
            nav = 1.0
            if plan['type'] in ['åŸºé‡‘', 'è‚¡ç¥¨'] and code:
                nav = DataProvider.get_fund_nav(code) or 1.0
            
            shares_to_add = amount / nav
            
            # æŸ¥å½“å‰çŠ¶æ€
            curr_target = conn.execute('SELECT last_shares, unit_cost FROM assets WHERE asset_id = ?', (asset_id,)).fetchone()
            old_shares = curr_target['last_shares'] if curr_target and curr_target['last_shares'] else 0.0
            old_cost = curr_target['unit_cost'] if curr_target and curr_target['unit_cost'] else 0.0
            
            # ğŸ”¥ æ ¸å¿ƒï¼šç§»åŠ¨åŠ æƒå¹³å‡ç®—æˆæœ¬
            new_shares = old_shares + shares_to_add
            if new_shares > 0:
                # (æ—§å¸‚å€¼ + æ–°æŠ•å…¥) / æ€»ä»½é¢
                new_unit_cost = ((old_shares * old_cost) + amount) / new_shares
            else:
                new_unit_cost = 0.0 # ç†è®ºä¸Šä¸ä¼šèµ°åˆ°è¿™
            
            # æ›´æ–° Assets è¡¨
            conn.execute('UPDATE assets SET last_shares = ?, unit_cost = ? WHERE asset_id = ?', (new_shares, new_unit_cost, asset_id))
            
            # === Part 2: æ‰£å‡æ¥æºèµ„äº§ (ä¿æŒä¸å˜) ===
            if source_id:
                curr_source = conn.execute('SELECT last_shares FROM assets WHERE asset_id = ?', (source_id,)).fetchone()
                curr_source_shares = curr_source['last_shares'] if curr_source and curr_source['last_shares'] else 0.0
                
                # ç°é‡‘ï¼šå‡€å€¼1ï¼Œé‡‘é¢å³ä»½é¢
                new_source_shares = curr_source_shares - amount
                conn.execute('UPDATE assets SET last_shares = ? WHERE asset_id = ?', (new_source_shares, source_id))
                
                # å†™å…¥ Snapshots
                new_source_amt = new_source_shares * 1.0
                conn.execute('''
                    INSERT INTO snapshots (asset_id, date, amount, profit, cost, yield_rate, shares, unit_nav, is_cleared)
                    VALUES (?, ?, ?, 0, ?, 0, ?, 1.0, 0)
                    ON CONFLICT(asset_id, date) DO UPDATE SET
                    amount=excluded.amount, cost=excluded.cost, shares=excluded.shares, unit_nav=1.0
                ''', (source_id, target_date_str, new_source_amt, new_source_amt, new_source_shares))

            # === Part 3: å†™å…¥æµæ°´ (ä¿æŒä¸å˜) ===
            note = f"{check_note_pattern} (ä»½é¢+{shares_to_add:.2f}, æ–°æˆæœ¬{new_unit_cost:.4f})"
            conn.execute('''
                INSERT INTO cashflows (user_id, date, type, amount, category, note, created_at)
                VALUES (?, ?, 'æ”¯å‡º', ?, 'å®šæŠ•æ‰£æ¬¾', ?, datetime('now'))
            ''', (user_id, target_date_str, amount, note))
            
            executed_count += 1
            logs.append(f"âœ… ä¹°å…¥ {plan['asset_name']}: {amount}å…ƒ, æˆæœ¬æ›´æ–° {old_cost:.3f}->{new_unit_cost:.3f}")
            
        conn.commit()
        return True, logs
        
    except Exception as e:
        return False, [f"æ‰§è¡Œå‡ºé”™: {str(e)}"]
    finally:
        conn.close()

def recalculate_daily_nav(user_id, target_date_str, progress_bar=None, status_text=None, limit_asset_ids=None):
    """
    ä¸€é”®æ›´æ–°åŠŸèƒ½ï¼šæ‹‰å–è¡Œæƒ… -> æ›´æ–°å¿«ç…§ -> é‡ç®—å¸‚å€¼/æ”¶ç›Š
    (æ”¯æŒè¿›åº¦æ¡ã€é”™è¯¯æ”¶é›†ã€ä»¥åŠæŒ‡å®šèµ„äº§èŒƒå›´)
    :param limit_asset_ids: list/tuple, ä»…æ›´æ–°è¿™äº› ID çš„èµ„äº§ã€‚å¦‚æœä¸º None æˆ–ç©ºï¼Œåˆ™ä¸æ›´æ–°ä»»ä½•èµ„äº§ã€‚
    """
    from data_provider import DataProvider
    import time
    
    conn = get_db_connection()
    results = {"success": [], "fail": []} 
    
    try:
        # 1. æ„å»ºæŸ¥è¯¢ SQL
        # åŸºç¡€æ¡ä»¶ï¼šå±äºè¯¥ç”¨æˆ· AND å¼€å¯è‡ªåŠ¨æ›´æ–° AND ä»£ç ä¸ä¸ºç©º
        sql = '''
            SELECT asset_id, name, code, type, last_shares, unit_cost 
            FROM assets 
            WHERE user_id = ? AND auto_update = 1 AND code IS NOT NULL
        '''
        params = [user_id]
        
        # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šå¢åŠ  ID ç­›é€‰é™åˆ¶
        if limit_asset_ids:
            # åŠ¨æ€æ„å»º IN (?,?,?)
            placeholders = ','.join(['?'] * len(limit_asset_ids))
            sql += f" AND asset_id IN ({placeholders})"
            params.extend(limit_asset_ids)
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®š ID (åˆ—è¡¨ä¸ºç©º)ï¼ŒæŒ‰ç…§ä½ çš„éœ€æ±‚ï¼Œç›´æ¥è¿”å›ï¼Œä¸è¿›è¡Œå…¨é‡æ›´æ–°
            return True, {"success": [], "fail": ["æœªé€‰ä¸­ä»»ä½•éœ€è¦æ›´æ–°çš„èµ„äº§"]}

        targets = conn.execute(sql, params).fetchall()
        
        total_tasks = len(targets)
        if total_tasks == 0:
            return True, {"success": [], "fail": ["å½“å‰ç­›é€‰åˆ—è¡¨å†…æ²¡æœ‰å¼€å¯'è‡ªåŠ¨æ›´æ–°'çš„èµ„äº§"]}

        updated_count = 0
        
        for idx, asset in enumerate(targets):
            asset_id = asset['asset_id']
            name = asset['name']
            code = asset['code']
            a_type = asset['type']
            
            # --- æ›´æ–° UI è¿›åº¦ ---
            if progress_bar:
                progress_bar.progress((idx) / total_tasks)
            if status_text:
                status_text.caption(f"ğŸ”„ [{idx+1}/{total_tasks}] æ­£åœ¨æ›´æ–°: {name} ({code})...")

            try:
                # A. è·å–æœ€æ–°å‡€å€¼/ä»·æ ¼ (å¸¦è¶…æ—¶)
                nav = 1.0
                if 'åŸºé‡‘' in a_type:
                    nav = DataProvider.get_fund_nav(code, end_date=target_date_str)
                elif 'è‚¡ç¥¨' in a_type:
                    nav = DataProvider.get_stock_price(code)
                
                # B. æŸ¥å‡ºå½“å¤©çš„å¿«ç…§
                snap = conn.execute('SELECT shares, cost FROM snapshots WHERE asset_id=? AND date=?', (asset_id, target_date_str)).fetchone()
                current_shares = snap['shares'] if (snap and snap['shares'] > 0) else asset['last_shares']

                # C. è®¡ç®—æ•°å€¼
                unit_cost = asset['unit_cost'] if asset['unit_cost'] else 0.0
                
                new_amount = current_shares * nav
                new_cost = current_shares * unit_cost
                new_profit = new_amount - new_cost
                new_yield = (new_profit / new_cost * 100) if new_cost != 0 else 0.0
                
                # D. æ›´æ–°æ•°æ®åº“
                conn.execute('''
                    INSERT INTO snapshots (asset_id, date, amount, profit, cost, yield_rate, shares, unit_nav, is_cleared)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, 0)
                    ON CONFLICT(asset_id, date) DO UPDATE SET
                    amount=excluded.amount,
                    profit=excluded.profit,
                    cost=excluded.cost,
                    yield_rate=excluded.yield_rate,
                    shares=excluded.shares,
                    unit_nav=excluded.unit_nav
                ''', (asset_id, target_date_str, new_amount, new_profit, new_cost, new_yield, current_shares, nav))
                
                updated_count += 1
                results['success'].append(f"{name}: {nav}")
                
            except TimeoutError:
                results['fail'].append(f"{name}: âŒ ç½‘ç»œè¶…æ—¶")
            except Exception as e:
                results['fail'].append(f"{name}: âŒ {str(e)}")
            
        conn.commit()
        if progress_bar: progress_bar.progress(1.0)
        return True, results

    except Exception as e:
        return False, f"ç³»ç»Ÿé”™è¯¯: {e}"
    finally:
        conn.close()

def page_data_entry():
    import pandas as pd
    st.header("ğŸ“ æ¯æ—¥èµ„äº§å¿«ç…§å½•å…¥ (ä½™é¢æ³•)")
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()
    
    # --- 1. æ—¥æœŸé€‰æ‹© ---
    col_date, _ = st.columns([1, 2])
    with col_date:
        date_input = st.date_input("é€‰æ‹©å¿«ç…§æ—¥æœŸ", datetime.now())
        str_date = date_input.strftime('%Y-%m-%d')

    # å‡†å¤‡åŸºç¡€èµ„äº§æ•°æ®
    assets = pd.read_sql('SELECT asset_id, name, code, type, currency, last_shares, auto_update FROM assets WHERE user_id = ?', conn, params=(user_id,))
    
    if assets.empty:
        st.warning("æš‚æ— èµ„äº§ï¼Œè¯·å…ˆå»ã€èµ„äº§ä¸æ ‡ç­¾ç®¡ç†ã€‘æ·»åŠ èµ„äº§ã€‚")
        conn.close()
        return

    # --- 2. æ±‡ç‡å½•å…¥åŒº (è‡ªåŠ¨åŒ–å‡çº§ç‰ˆ) ---
    if 'currency' in assets.columns:
        unique_currencies = assets['currency'].unique().tolist()
        foreign_currencies = [c for c in unique_currencies if c and c != 'CNY']
    else:
        foreign_currencies = []
    
    if foreign_currencies:
        with st.expander(f"ğŸ’± è®¾ç½®å½“æ—¥æ±‡ç‡ ({str_date})", expanded=False):
            # å¸ƒå±€ï¼šå·¦è¾¹æç¤ºï¼Œå³è¾¹æ”¾ä¸ªè‡ªåŠ¨æ‹‰å–æŒ‰é’®
            h1, h2 = st.columns([3, 1])
            with h1:
                st.caption("æ£€æµ‹åˆ°æ‚¨æŒæœ‰å¤–å¸èµ„äº§ï¼Œè¯·ç¡®è®¤å½“æ—¥æ±‡ç‡ï¼ˆå¯¹äººæ°‘å¸ï¼‰ï¼š")
            with h2:
                if st.button("ğŸ”„ è‡ªåŠ¨æ‹‰å–æ±‡ç‡(ä¸­è¡Œæ±‡ä¹°ä»·)", help="è°ƒç”¨ AkShare è·å–ä¸­å›½é“¶è¡Œå½“æ—¥ä¸­é—´ä»·", key="btn_auto_rate"):
                    from data_provider import DataProvider
                    with st.spinner("æ­£åœ¨è¿æ¥ä¸­å›½é“¶è¡Œæ¥å£..."):
                        fetched_count = 0
                        for curr in foreign_currencies:
                            # è°ƒç”¨æ•°æ®æ¥å£
                            r = DataProvider.get_exchange_rate(curr, str_date)
                            if r:
                                # ğŸ”¥ å…³é”®ï¼šæ›´æ–° session_state ä»¥åˆ·æ–° number_input çš„å€¼
                                k = f"rate_{curr}_{str_date}"
                                st.session_state[k] = r
                                fetched_count += 1
                        
                        if fetched_count > 0:
                            st.toast(f"æˆåŠŸæ‹‰å– {fetched_count} ä¸ªå¸ç§æ±‡ç‡", icon="âœ…")
                            import time; time.sleep(0.5); st.rerun() # åˆ·æ–°ç•Œé¢æ˜¾ç¤ºæ•°å€¼
                        else:
                            st.error("æœªèƒ½è·å–æ±‡ç‡ï¼Œè¯·æ£€æŸ¥æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼Œæˆ–æ‰‹åŠ¨è¾“å…¥ã€‚")

            # è¯»å–æ•°æ®åº“å·²å­˜çš„ï¼Œæˆ–è€… Session State é‡Œçš„(åˆšæ‹‰å–çš„)
            saved_rates = pd.read_sql("SELECT currency, rate FROM exchange_rates WHERE date = ?", conn, params=(str_date,))
            saved_rate_map = dict(zip(saved_rates['currency'], saved_rates['rate']))
            
            cols = st.columns(len(foreign_currencies) + 1)
            rates_to_save = {}
            
            for i, curr in enumerate(foreign_currencies):
                # ä¼˜å…ˆçº§ï¼šSessionState (åˆšæ‹‰å–çš„) > Database (å·²å­˜çš„) > 1.0 (é»˜è®¤)
                input_key = f"rate_{curr}_{str_date}"
                
                # å¦‚æœ session_state é‡Œæ²¡æœ‰ï¼Œæ‰å»æ•°æ®åº“å–é»˜è®¤å€¼
                if input_key not in st.session_state:
                    default_val = saved_rate_map.get(curr, 1.0)
                else:
                    default_val = st.session_state[input_key] # è¿™ä¸€æ­¥å…¶å®æ˜¯å¤šä½™çš„ï¼Œst.number_inputä¼šè‡ªåŠ¨å–keyçš„å€¼ï¼Œä½†ä¸ºäº†é€»è¾‘æ¸…æ™°å†™å‡ºæ¥
                
                with cols[i]:
                    # æ³¨æ„ï¼šst.number_input å¦‚æœ key å¯¹åº”çš„å€¼å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨è¯¥å€¼
                    r = st.number_input(
                        f"{curr} â¡ï¸ CNY", 
                        value=float(default_val) if input_key not in st.session_state else None, # å¦‚æœkeyå­˜åœ¨ï¼Œvalueå‚æ•°ä¼šè¢«å¿½ç•¥
                        format="%.4f", 
                        key=input_key
                    )
                    rates_to_save[curr] = r
            
            with cols[-1]:
                st.write(""); st.write("") 
                if st.button("ğŸ’¾ ä¿å­˜æ±‡ç‡", type="secondary"):
                    try:
                        for curr, rate in rates_to_save.items():
                            conn.execute("INSERT OR REPLACE INTO exchange_rates (date, currency, rate) VALUES (?, ?, ?)", (str_date, curr, rate))
                        conn.commit()
                        st.toast("æ±‡ç‡å·²æ›´æ–°", icon="ğŸ’±")
                    except Exception as e: st.error(f"æ±‡ç‡ä¿å­˜å¤±è´¥: {e}")


    # --- 3. ç­›é€‰ä¸æ’åºå·¥å…· (ç®€åŒ–ç‰ˆ) ---
    with st.expander("ğŸ” ç­›é€‰èµ„äº§", expanded=True):
        c1, c2, c3 = st.columns([2, 1, 2])
        with c1:
            kw = st.text_input("å…³é”®å­—æœç´¢", placeholder="åç§°/ä»£ç ")
        with c2:
            hide_cleared = st.checkbox("ğŸ™ˆ éšè—å·²æ¸…ä»“", value=True)
        with c3:
            all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
            grp_list = ["(ä¸ç­›é€‰)"] + all_groups['tag_group'].tolist()
            sel_group = st.selectbox("æ ‡ç­¾ç»„", grp_list)
        
        # æ ‡ç­¾äºŒçº§ç­›é€‰é€»è¾‘
        sel_tags = []
        if sel_group != "(ä¸ç­›é€‰)":
            t_df = pd.read_sql("SELECT tag_name FROM tags WHERE user_id=? AND tag_group=?", conn, params=(user_id, sel_group))
            opts = ["ã€æ— æ­¤æ ‡ç­¾ã€‘"] + t_df['tag_name'].tolist()
            sel_tags = st.multiselect("æ ‡ç­¾å", opts)
            
            # æ’åºé€»è¾‘
            sort_option = st.radio("æ’åº", ["é»˜è®¤", "é‡‘é¢(é«˜â†’ä½)", "æ”¶ç›Š(é«˜â†’ä½)"], horizontal=True, label_visibility="collapsed")
        else:
            sort_option = "é»˜è®¤"

    # --- 4. æ•°æ®å‡†å¤‡ä¸åˆå¹¶ ---
    # è·å–æ¸…ä»“çŠ¶æ€
    all_asset_ids = tuple(assets['asset_id'].tolist())
    if not all_asset_ids: return

    if len(all_asset_ids) == 1: str_ids = f"({all_asset_ids[0]})"
    else: str_ids = str(all_asset_ids)
    
    last_status_df = pd.read_sql(f'SELECT asset_id, is_cleared FROM snapshots WHERE asset_id IN {str_ids} ORDER BY date DESC', conn)
    last_status_df = last_status_df.drop_duplicates(subset=['asset_id'])
    assets = pd.merge(assets, last_status_df, on='asset_id', how='left')
    assets['is_cleared'] = assets['is_cleared'].fillna(0).astype(bool)

    # ç­›é€‰
    filtered_df = assets.copy()
    if hide_cleared: filtered_df = filtered_df[filtered_df['is_cleared'] == False]
    if kw: filtered_df = filtered_df[filtered_df['name'].str.contains(kw, case=False) | filtered_df['code'].str.contains(kw, case=False, na=False)]
    if sel_group != "(ä¸ç­›é€‰)" and sel_tags:
        # ... (æ ‡ç­¾ç­›é€‰é€»è¾‘ä¿æŒä¸å˜ï¼Œä¸ºèŠ‚çœç¯‡å¹…çœç•¥ï¼Œæ­¤å¤„ç›´æ¥å¼•ç”¨ä¸Šä¸€ç‰ˆé€»è¾‘) ...
        sql_labeled = '''SELECT atm.asset_id, t.tag_name FROM asset_tag_map atm JOIN tags t ON atm.tag_id = t.tag_id WHERE t.user_id = ? AND t.tag_group = ?'''
        df_labeled = pd.read_sql(sql_labeled, conn, params=(user_id, sel_group))
        target_ids = set()
        current_ids = set(filtered_df['asset_id'])
        if "ã€æ— æ­¤æ ‡ç­¾ã€‘" in sel_tags: target_ids.update(current_ids - set(df_labeled['asset_id']))
        real_tags = [t for t in sel_tags if t != "ã€æ— æ­¤æ ‡ç­¾ã€‘"]
        if real_tags: target_ids.update(set(df_labeled[df_labeled['tag_name'].isin(real_tags)]['asset_id']))
        filtered_df = filtered_df[filtered_df['asset_id'].isin(target_ids)]

    # --- 5. å‡†å¤‡ DataEditor æ•°æ® ---
    if filtered_df.empty:
        st.info("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„èµ„äº§ã€‚")
    else:
        final_ids = tuple(filtered_df['asset_id'].tolist())
        q_ids = str(final_ids) if len(final_ids) > 1 else f"({final_ids[0]})"
        
        # æŸ¥ä»Šæ—¥å¿«ç…§ (å¦‚æœä»Šå¤©è¿˜æ²¡å¡«ï¼Œå°±å–æœ€è¿‘ä¸€æ¬¡çš„ amount, profit, unit_nav ç”¨äºé¢„å¡«å……)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åšä¸ªä¼˜åŒ–ï¼Œå¦‚æœä»Šå¤©æ²¡å¡«ï¼Œ amount/profit å–"æ˜¨å¤©"çš„å€¼ä½œä¸ºé»˜è®¤å€¼ï¼Œæ–¹ä¾¿ç”¨æˆ·åªæ”¹å˜åŠ¨çš„éƒ¨åˆ†
        
        # 1. å…ˆæŸ¥ä»Šå¤©çš„
        snap_today = pd.read_sql(f'SELECT * FROM snapshots WHERE date = ? AND asset_id IN {q_ids}', conn, params=(str_date,))
        
        # 2. å†æŸ¥æœ€è¿‘ä¸€æ¬¡çš„ (ä½œä¸ºé»˜è®¤å€¼å…œåº•)
        snap_last = pd.read_sql(f'''
            SELECT asset_id, amount, profit, unit_nav 
            FROM snapshots 
            WHERE asset_id IN {q_ids} AND date < ? 
            ORDER BY date DESC
        ''', conn, params=(str_date,))
        snap_last = snap_last.drop_duplicates(subset=['asset_id'])
        
        merged = pd.merge(filtered_df, snap_today, on='asset_id', how='left', suffixes=('', '_today'))
        merged = pd.merge(merged, snap_last, on='asset_id', how='left', suffixes=('', '_last'))
        
        # --- å¡«å……é€»è¾‘ (æ ¸å¿ƒ) ---
        # ä¼˜å…ˆç”¨ä»Šå¤©çš„ï¼›å¦‚æœæ²¡æœ‰ï¼Œç”¨ä¸Šæ¬¡çš„ï¼›è¿˜æ²¡æœ‰ï¼Œç”¨0
        merged['amount'] = merged['amount'].fillna(merged['amount_last']).fillna(0.0)
        merged['profit'] = merged['profit'].fillna(merged['profit_last']).fillna(0.0)
        
        # å‡€å€¼ä¼˜å…ˆç”¨ä»Šå¤©çš„ï¼›å¦‚æœæ²¡æœ‰ï¼Œç”¨ä¸Šæ¬¡çš„ï¼›å†æ²¡æœ‰ï¼Œç”¨1.0
        # æ³¨æ„ï¼šç°é‡‘ç±»å¼ºåˆ¶ 1.0 (è™½ç„¶ DataEditor ä¼šæ˜¾ç¤ºï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ Column config æç¤º)
        merged['unit_nav'] = merged['unit_nav'].fillna(merged['unit_nav_last']).fillna(1.0)
        
        # ç°é‡‘ç±»ç‰¹æ®Šå¤„ç†ï¼šå‡€å€¼é»˜è®¤ä¸º1
        if 'type' in merged.columns:
            merged.loc[merged['type'] == 'ç°é‡‘', 'unit_nav'] = 1.0

        # åæ¨é€»è¾‘æ¼”ç¤º (ä»…ç”¨äºæ˜¾ç¤ºï¼Œä¸å­˜åº“ï¼ŒçœŸæ­£è®¡ç®—åœ¨ä¿å­˜æ—¶)
        # shares = amount / nav
        # cost = amount - profit
        # unit_cost = cost / shares
        # è¿™äº›å­—æ®µæˆ‘ä»¬å±•ç¤ºåœ¨è¡¨æ ¼é‡Œä¾›å‚è€ƒï¼Œä½†è®¾ä¸º disabled
        merged['shares_est'] = merged.apply(lambda r: r['amount'] / r['unit_nav'] if r['unit_nav'] else 0, axis=1)
        merged['cost_est'] = merged['amount'] - merged['profit']
        merged['unit_cost_est'] = merged.apply(lambda r: r['cost_est'] / r['shares_est'] if r['shares_est'] else 0, axis=1)
        merged['yield_est'] = merged.apply(lambda r: (r['profit'] / r['cost_est'] * 100) if r['cost_est'] else 0, axis=1)

        # æ’åº
        if "é‡‘é¢" in sort_option: merged = merged.sort_values(by='amount', ascending=False)
        elif "æ”¶ç›Š" in sort_option: merged = merged.sort_values(by='profit', ascending=False)

        # --- 6. æŒ‰é’®åŒº ---
        col_act, _ = st.columns([1, 4])
        with col_act:
            # ğŸ”¥ ä»…ä¿ç•™â€œåˆ·æ–°å‡€å€¼â€åŠŸèƒ½ï¼Œç§»é™¤â€œå®šæŠ•â€å’Œâ€œè°ƒä»“â€
            # è¿™é‡Œçš„åˆ·æ–°åªæ˜¯ä¸ºäº†è·å–æœ€æ–°çš„ NAVï¼Œæ–¹ä¾¿åæ¨ä»½é¢
            visible_ids = merged['asset_id'].tolist()
            if st.button("ğŸ”„ åˆ·æ–°å½“å‰åˆ—è¡¨å‡€å€¼", help="ä»ç½‘ç»œæ‹‰å–æœ€æ–°å‡€å€¼ï¼Œå¡«å…¥è¡¨æ ¼ï¼ˆä¸æ”¹å˜å¸‚å€¼ï¼Œåªå½±å“åæ¨çš„ä»½é¢ï¼‰"):
                progress_bar = st.progress(0.0)
                status_text = st.empty()
                success, res = recalculate_daily_nav(user_id, str_date, progress_bar, status_text, limit_asset_ids=visible_ids)
                status_text.empty(); progress_bar.empty()
                if success:
                    st.toast("å‡€å€¼å·²æ›´æ–°ï¼Œè¯·æ£€æŸ¥æ•°æ®", icon="âœ…")
                    import time; time.sleep(1); st.rerun()
                else:
                    st.error(f"æ›´æ–°å¤±è´¥: {res}")

        # --- 7. DataEditor (ä½™é¢æ³•æ ¸å¿ƒ) ---
        st.caption("ğŸ’¡ **ä½™é¢æ³•æ“ä½œæŒ‡å—**ï¼šç›´æ¥å¯¹ç…§ç†è´¢APPï¼Œä¿®æ”¹ã€å¸‚å€¼ã€‘å’Œã€æŒæœ‰æ”¶ç›Šã€‘å³å¯ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨åæ¨ä»½é¢å’Œæˆæœ¬ã€‚")
        
        col_cfg = {
            "asset_id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
            "name": st.column_config.TextColumn("åç§°", disabled=True),
            "code": st.column_config.TextColumn("ä»£ç ", disabled=True),
            
            # ğŸ”¥ æ ¸å¿ƒè¾“å…¥åˆ—ï¼šå…è®¸ç¼–è¾‘
            "amount": st.column_config.NumberColumn("ğŸ’° æ€»å¸‚å€¼ (æŸ¥APP)", required=True, format="%.2f", help="å¯¹ç…§æ”¯ä»˜å®/åˆ¸å•†APPå¡«å†™å½“å‰æ€»é‡‘é¢"),
            "profit": st.column_config.NumberColumn("ğŸ‰ æŒæœ‰æ”¶ç›Š (æŸ¥APP)", required=True, format="%.2f", help="å¯¹ç…§APPå¡«å†™æ˜¾ç¤ºçš„æŒæœ‰æ”¶ç›Š"),
            "unit_nav": st.column_config.NumberColumn("ğŸ“ˆ å½“æ—¥å‡€å€¼", required=True, format="%.4f", help="å¯æ‰‹åŠ¨ä¿®æ”¹ï¼Œæˆ–ç‚¹åˆ·æ–°æŒ‰é’®è‡ªåŠ¨æ‹‰å–"),
            
            # ğŸ”¥ è¡ç”Ÿåˆ—ï¼šç¦æ­¢ç¼–è¾‘ (ç”±åæ¨å¾—åˆ°)
            "shares_est": st.column_config.NumberColumn("ä»½é¢ (åæ¨)", disabled=True, format="%.2f"),
            "unit_cost_est": st.column_config.NumberColumn("æˆæœ¬ä»· (åæ¨)", disabled=True, format="%.4f"),
            "yield_est": st.column_config.NumberColumn("æ”¶ç›Šç‡", disabled=True, format="%.2f%%"),
            
            "is_cleared": st.column_config.CheckboxColumn("ğŸ æ¸…ä»“?", help="å‹¾é€‰åè¡¨ç¤ºè¯¥èµ„äº§å·²æ¸…ä»“"),
        }
        if 'currency' in merged.columns:
            col_cfg["currency"] = st.column_config.TextColumn("å¸", disabled=True, width="small")

        # åªè¦è¿™å‡ åˆ—
        cols_show = ['asset_id','name','code','currency','amount','profit','unit_nav','shares_est','unit_cost_est','yield_est','is_cleared']
        cols_show = [c for c in cols_show if c in merged.columns]

        edited_snapshot = st.data_editor(
            merged[cols_show],
            column_config=col_cfg,
            hide_index=True,
            use_container_width=True,
            key=f"entry_v3_{str_date}"
        )

        # --- 8. ä¿å­˜é€»è¾‘ (åæ¨å¹¶å­˜åº“) ---
        if st.button("ğŸ’¾ ä¿å­˜å¿«ç…§ (è‡ªåŠ¨åæ¨ä»½é¢)", type="primary"):
            try:
                c = 0
                for _, row in edited_snapshot.iterrows():
                    asset_id = row['asset_id']
                    
                    # 1. è·å–ç”¨æˆ·å¡«å†™çš„æ ¸å¿ƒæ•°æ®
                    amount = float(row['amount'])
                    profit = float(row['profit'])
                    nav = float(row['unit_nav'])
                    is_clr = 1 if row['is_cleared'] else 0
                    
                    # 2. æ‰§è¡Œåæ¨ (Reverse Calculation)
                    # ä»½é¢ = å¸‚å€¼ / å‡€å€¼
                    shares = 0.0
                    if nav > 0:
                        shares = amount / nav
                    
                    # æœ¬é‡‘ = å¸‚å€¼ - æ”¶ç›Š
                    cost = amount - profit
                    
                    # å•ä½æˆæœ¬ = æœ¬é‡‘ / ä»½é¢
                    unit_cost = 0.0
                    if shares > 0:
                        unit_cost = cost / shares
                    
                    # æ”¶ç›Šç‡
                    y_rate = 0.0
                    if cost != 0:
                        y_rate = (profit / cost) * 100
                    
                    # 3. å­˜å…¥ snapshots è¡¨
                    conn.execute('''
                        INSERT INTO snapshots (asset_id, date, amount, profit, cost, yield_rate, shares, unit_nav, is_cleared) 
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ON CONFLICT(asset_id, date) DO UPDATE SET 
                        amount=excluded.amount, profit=excluded.profit, 
                        cost=excluded.cost, yield_rate=excluded.yield_rate,
                        shares=excluded.shares, unit_nav=excluded.unit_nav,
                        is_cleared=excluded.is_cleared
                    ''', (asset_id, str_date, amount, profit, cost, y_rate, shares, nav, is_clr))
                    
                    # 4. åŒæ­¥æ›´æ–° assets è¡¨ (ä¸ºäº†ä¸‹æ¬¡æ‰“å¼€èƒ½ç»§æ‰¿ï¼Œä»¥åŠ Tab 1 æ˜¾ç¤ºæ­£ç¡®)
                    # åªæ›´æ–°ä»½é¢å’Œå•ä½æˆæœ¬ï¼Œè¿™ä¿©æ˜¯èµ„äº§å±æ€§
                    conn.execute('UPDATE assets SET last_shares=?, unit_cost=? WHERE asset_id=?', (shares, unit_cost, asset_id))
                    
                    c += 1
                
                conn.commit()

                # ğŸ”¥ è§¦å‘ä¸ªäººåŸºé‡‘å‡€å€¼é‡ç®—
                with st.spinner("æ­£åœ¨é‡æ–°è®¡ç®—ä¸ªäººåŸºé‡‘å†å²å‡€å€¼..."):
                    success, msg = recalc_fund_history.recalculate_user_history(user_id)
                    if not success:
                        st.error(msg)
                    else:
                        st.toast(msg, icon="ğŸ“ˆ")
                        
                st.cache_data.clear()
                st.success(f"å·²ä¿å­˜ {c} æ¡è®°å½•ï¼ä»½é¢å·²åæ¨ï¼Œå‡€å€¼æ›²çº¿å·²æ›´æ–°ã€‚")
                import time; time.sleep(1); st.rerun()
                
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")

        # --- 9. åˆ é™¤/é‡ç½® (ä¿ç•™) ---
        st.write(""); st.write(""); st.divider()
        exist_count = conn.execute('SELECT COUNT(*) FROM snapshots s JOIN assets a ON s.asset_id = a.asset_id WHERE s.date = ? AND a.user_id = ?', (str_date, user_id)).fetchone()[0]

        if exist_count > 0:
            with st.expander(f"ğŸ—‘ï¸ åˆ é™¤/é‡ç½® ã€{str_date}ã€‘ çš„æ•°æ®", expanded=False):
                if st.button("ğŸ§¨ ç¡®è®¤å½»åº•åˆ é™¤", type="primary", key="btn_del_daily"):
                    conn.execute('DELETE FROM snapshots WHERE date = ? AND asset_id IN (SELECT asset_id FROM assets WHERE user_id = ?)', (str_date, user_id))
                    conn.commit()
                    st.success(f"å·²åˆ é™¤ {str_date} è®°å½•ï¼"); import time; time.sleep(1); st.rerun()
    
    conn.close()

def page_cashflow():
    import pandas as pd
    import plotly.express as px
    import time  # <--- ğŸ”¥ åŠ ä¸Šè¿™ä¸€è¡Œï¼Œé—®é¢˜è§£å†³ï¼
    st.header("ğŸ’° ç°é‡‘æµä¸æœ¬é‡‘å½’é›†")
    st.caption("â€œæ¨¡ç³Šè®°è´¦æ³•â€æ ¸å¿ƒï¼šåªè®°å¤§é¢è¿›å‡º (å¤–éƒ¨æ”¶æ”¯)ï¼Œå€’æ¨æœ¬é‡‘æŠ•å…¥ã€‚")
    
    user_id = st.session_state.user['user_id']
    username = st.session_state.user['username'] # è·å–å½“å‰ç”¨æˆ·åä½œä¸ºé»˜è®¤æ“ä½œäºº
    conn = get_db_connection()

    # --- 1. é¡¶éƒ¨ï¼šæç®€å½•å…¥åŒº ---
    with st.container(border=True):
        st.subheader("â• æ–°å¢è®°å½•")
        
        # ç¬¬ä¸€è¡Œï¼šåŸºç¡€ä¿¡æ¯
        c1, c2, c3, c4 = st.columns([2, 2, 2, 2])
        with c1:
            record_date = st.date_input("æ—¥æœŸ", datetime.now(), key="cf_date")
        with c2:
            flow_type = st.selectbox("ç±»å‹", ["ğŸ“¥ æ”¶å…¥ (æŠ•å…¥æœ¬é‡‘)", "ğŸ“¤ æ”¯å‡º (æ¶ˆè€—æœ¬é‡‘)"], key="cf_type")
        with c3:
            amount = st.number_input("é‡‘é¢", min_value=0.0, step=1000.0, format="%.2f", key="cf_amt")
        with c4:
            # ğŸ”¥ æ–°å¢ï¼šæ“ä½œäºº (é»˜è®¤å¡«è‡ªå·±ï¼Œå¯æ”¹)
            operator = st.text_input("æ“ä½œäºº", value=username, key="cf_operator")

        # ç¬¬äºŒè¡Œï¼šç±»åˆ«ä¸æäº¤
        c5, c6 = st.columns([3, 1])
        with c5:
            if "æ”¶å…¥" in flow_type:
                options = ["å·¥èµ„/å¥–é‡‘", "ç†è´¢èµå›", "å…¶ä»–æ”¶å…¥"]
            else:
                options = ["ä¿¡ç”¨å¡/èŠ±å‘—è´¦å•", "æˆ¿è´·/æˆ¿ç§Ÿ", "å¤§é¢è½¬è´¦", "å…¶ä»–å¤§é¢æ”¯å‡º"]
            category = st.selectbox("ç±»åˆ« (å¯ç¼–è¾‘)", options, key="cf_cat") 
            
        with c6:
            st.write("")
            st.write("")
            if st.button("ğŸ’¾ è®°ä¸€ç¬”", type="primary", use_container_width=True):
                if amount > 0:
                    real_type = "æ”¶å…¥" if "æ”¶å…¥" in flow_type else "æ”¯å‡º"
                    # ğŸ”¥ ä¿®æ”¹ï¼šæ’å…¥ operator
                    conn.execute('''
                        INSERT INTO cashflows (user_id, date, type, amount, category, operator, created_at)
                        VALUES (?, ?, ?, ?, ?, ?, datetime('now'))
                    ''', (user_id, record_date.strftime('%Y-%m-%d'), real_type, amount, category, operator))
                    
                    conn.commit()
                    st.success("å·²è®°å½•")
                    import time
                    time.sleep(0.5)
                    st.rerun()
                else:
                    st.warning("é‡‘é¢éœ€å¤§äº0")

    # --- 2. ä¸­éƒ¨ï¼šå¹´åº¦ç»Ÿè®¡å¡ç‰‡ ---
    current_year = datetime.now().year
    
    # è¿™é‡Œçš„æŸ¥è¯¢ä»…ç”¨äºç»Ÿè®¡æ€»æ•°ï¼Œç®€å•æŸ¥å³å¯
    df_stat = pd.read_sql('''
        SELECT type, amount, date 
        FROM cashflows 
        WHERE user_id = ? 
        AND category NOT IN ('å®šæŠ•æ‰£æ¬¾', 'å†…éƒ¨è°ƒä»“') -- æ’é™¤å†…éƒ¨äº¤æ˜“
    ''', conn, params=(user_id,))
    
    if not df_stat.empty:
        df_stat['date'] = pd.to_datetime(df_stat['date'])
        df_stat['year'] = df_stat['date'].dt.year
        
        df_this_year = df_stat[df_stat['year'] == current_year]
        income_year = df_this_year[df_this_year['type'] == 'æ”¶å…¥']['amount'].sum()
        expense_year = df_this_year[df_this_year['type'] == 'æ”¯å‡º']['amount'].sum()
        net_input = income_year - expense_year
        
        st.divider()
        st.markdown(f"### ğŸ“… {current_year} å¹´åº¦æœ¬é‡‘æŠ•å…¥æ¦‚è§ˆ")
        k1, k2, k3 = st.columns(3)
        k1.metric("ğŸ“¥ æœ¬å¹´ç´¯è®¡å¤§é¢æ”¶å…¥", f"Â¥{income_year:,.2f}")
        k2.metric("ğŸ“¤ æœ¬å¹´ç´¯è®¡å¤§é¢æ”¯å‡º", f"Â¥{expense_year:,.2f}")
        k3.metric("ğŸŒ± æœ¬å¹´å‡€æŠ•å…¥æœ¬é‡‘", f"Â¥{net_input:,.2f}", 
                 delta="è¿™æ˜¯ä½ çš„åŠªåŠ›å­˜ä¸‹çš„é’±" if net_input > 0 else "æœ¬é‡‘æ­£åœ¨æµå‡º",
                 delta_color="normal" if net_input > 0 else "inverse")

    # --- 3. åº•éƒ¨ï¼šæ•°æ®ç®¡ç† (å‡çº§ç‰ˆï¼šå«ä»½é¢è®¡ç®—) ---
    st.divider()
    st.subheader("ğŸ“‹ å†å²æµæ°´æ˜ç»†")
    
    # ğŸ”¥ æ ¸å¿ƒæŸ¥è¯¢å‡çº§ï¼šå…³è” my_fund_history è·å–å½“æ—¶çš„å‡€å€¼
    # å·¦è¿æ¥ (Left Join)ï¼Œå› ä¸ºå¯èƒ½æœ‰äº›æ—¥å­è¿˜æ²¡ç”Ÿæˆå‡€å€¼(æ¯”å¦‚ä»Šå¤©åˆšè®°çš„ï¼Œè¿˜æ²¡ç‚¹é‡ç®—)
    df_display = pd.read_sql('''
        SELECT 
            c.id, c.date, c.type, c.amount, c.category, c.operator, c.note,
            h.unit_nav as nav_at_date
        FROM cashflows c
        LEFT JOIN my_fund_history h ON c.user_id = h.user_id AND c.date = h.date
        WHERE c.user_id = ? 
        AND c.category NOT IN ('å®šæŠ•æ‰£æ¬¾', 'å†…éƒ¨è°ƒä»“')
        ORDER BY c.date DESC
    ''', conn, params=(user_id,))
    
    if not df_display.empty:
        df_display['date_obj'] = pd.to_datetime(df_display['date'])
        df_display['date'] = df_display['date_obj'].dt.date
        
        # ğŸ”¥ è®¡ç®—ä»½é¢é€»è¾‘
        # å¦‚æœå½“å¤©è¿˜æ²¡æœ‰å‡€å€¼(NaN)ï¼Œæš‚æ—¶æŒ‰ 1.0 æ˜¾ç¤ºï¼Œæˆ–è€…æ˜¾ç¤ºç©º
        # æˆ‘ä»¬å¯ä»¥å¡«å……ä¸€ä¸ªé»˜è®¤å€¼ 1.0ï¼Œä½†ä¸ºäº†ä¸¥è°¨ï¼Œæœ€å¥½è®©ç”¨æˆ·å»ç‚¹ä¸€ä¸‹"é‡ç®—å‡€å€¼"
        # è¿™é‡Œä¸ºäº†å±•ç¤ºç¾è§‚ï¼Œè‹¥æ— å‡€å€¼åˆ™å¡« 1.0 (IPOä»·æ ¼)
        df_display['nav_at_date'] = df_display['nav_at_date'].fillna(1.0)
        
        # è®¡ç®—ä»½é¢ = é‡‘é¢ / å½“æ—¥å‡€å€¼
        df_display['shares_calc'] = df_display['amount'] / df_display['nav_at_date']
        
        edited_df = st.data_editor(
            df_display,
            column_config={
                "id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
                "date": st.column_config.DateColumn("æ—¥æœŸ", format="YYYY-MM-DD"),
                "type": st.column_config.SelectboxColumn("ç±»å‹", options=["æ”¶å…¥", "æ”¯å‡º"], required=True, width="small"),
                "amount": st.column_config.NumberColumn("é‡‘é¢", format="%.2f", min_value=0),
                "operator": st.column_config.TextColumn("æ“ä½œäºº", width="small"), # ğŸ”¥ æ–°å¢åˆ—
                
                # ğŸ”¥ æ–°å¢å±•ç¤ºåˆ— (åªè¯»ï¼Œç”¨äºç»™ç”¨æˆ·å³æ—¶åé¦ˆ)
                "nav_at_date": st.column_config.NumberColumn("å½“æ—¥å‡€å€¼", format="%.4f", disabled=True, help="è¯¥æ—¥æœŸå¯¹åº”çš„ä¸ªäººåŸºé‡‘å‡€å€¼"),
                "shares_calc": st.column_config.NumberColumn("å¯¹åº”ä»½é¢", format="%.2f", disabled=True, help="é‡‘é¢ Ã· å‡€å€¼ = ä¹°å…¥/å–å‡ºçš„ä»½é¢æ•°"),
                
                "category": st.column_config.TextColumn("ç±»åˆ«"),
                "note": st.column_config.TextColumn("å¤‡æ³¨"),
            },
            # éšè—ä¸éœ€è¦æ˜¾ç¤ºçš„è¾…åŠ©åˆ—
            column_order=["date", "type", "amount", "operator", "nav_at_date", "shares_calc", "category", "note"],
            use_container_width=True,
            num_rows="dynamic",
            key="cf_editor_v2"
        )
        
        if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹ (æ”¯æŒåˆ é™¤)", type="secondary"):
            try:
                # 1. æ‰¾å‡ºè¢«åˆ é™¤çš„
                orig_ids = set(df_display['id'].tolist())
                new_ids = set(edited_df['id'].dropna().tolist())
                del_ids = orig_ids - new_ids
                
                for did in del_ids:
                    conn.execute("DELETE FROM cashflows WHERE id = ?", (did,))
                
                # 2. æ›´æ–°/æ–°å¢
                for index, row in edited_df.iterrows():
                    # æ³¨æ„ï¼šnav_at_date å’Œ shares_calc æ˜¯è®¡ç®—åˆ—ï¼Œä¸éœ€è¦ä¿å­˜å› cashflows
                    if pd.isna(row['id']): # æ–°å¢
                         conn.execute("INSERT INTO cashflows (user_id, date, type, amount, category, operator, note) VALUES (?,?,?,?,?,?,?)",
                                      (user_id, row['date'], row['type'], row['amount'], row['category'], row['operator'], row['note']))
                    elif row['id'] in new_ids: # ä¿®æ”¹
                         conn.execute("UPDATE cashflows SET date=?, type=?, amount=?, category=?, operator=?, note=? WHERE id=?",
                                      (row['date'], row['type'], row['amount'], row['category'], row['operator'], row['note'], row['id']))
                
                conn.commit()
                
                # ğŸ”¥ å…³é”®è”åŠ¨ï¼šä¿®æ”¹ç°é‡‘æµåï¼Œå†å²å‡€å€¼è‚¯å®šå˜äº†ï¼Œå»ºè®®è‡ªåŠ¨è§¦å‘é‡ç®—
                # è¿™é‡Œå¼•å…¥ recalc æ¨¡å—
                import recalc_fund_history
                with st.spinner("æ­£åœ¨å› æµæ°´å˜åŠ¨é‡ç®—å†å²å‡€å€¼..."):
                    recalc_fund_history.recalculate_user_history(user_id)
                
                st.success("æ›´æ–°æˆåŠŸï¼å†å²å‡€å€¼å·²åŒæ­¥ä¿®æ­£ã€‚")
                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
    else:
        st.info("æš‚æ— è®°å½•ï¼Œè¯·åœ¨ä¸Šæ–¹æ·»åŠ ã€‚")

    conn.close()


def get_latest_rates(conn):
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    """è·å–ç³»ç»Ÿä¸­æ¯ç§è´§å¸æœ€æ–°çš„æ±‡ç‡ (å¯¹CNY)"""
    # æŒ‰æ—¥æœŸé™åºæ’ï¼Œå»é‡å–ç¬¬ä¸€ä¸ª
    df = pd.read_sql("SELECT currency, rate, date FROM exchange_rates ORDER BY date DESC", conn)
    if df.empty:
        return {}
    # drop_duplicates é»˜è®¤ä¿ç•™ç¬¬ä¸€ä¸ªï¼Œä¹Ÿå°±æ˜¯æœ€æ–°çš„
    return df.drop_duplicates(subset=['currency']).set_index('currency')['rate'].to_dict()


# ==============================================================================
# ğŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šæ™ºèƒ½ç¼“å­˜åˆ†æå‡½æ•° (PCå®æ—¶ç®— / æ ‘è“æ´¾å­˜ç¡¬ç›˜)
# ==============================================================================

# 1. å®šä¹‰ç¯å¢ƒä¸ç­–ç•¥
IS_RASPBERRY_PI = os.path.exists('/share') # å¤ç”¨ä½ ä¹‹å‰çš„åˆ¤æ–­é€»è¾‘

if IS_RASPBERRY_PI:
    # ğŸ“ æ ‘è“æ´¾æ¨¡å¼ï¼šç¡¬ç›˜æŒä¹…åŒ–ï¼Œæ°¸ä¸è¿‡æœŸ (é™¤éæ‰‹åŠ¨ç‚¹åˆ·æ–°)
    # è¿™æ ·é‡å¯ Streamlit åä¾ç„¶ç§’å¼€
    CACHE_PARAMS = {
        "persist": "disk", 
        "ttl": None, 
        "show_spinner": "æ­£åœ¨ä»ç¡¬ç›˜è¯»å–å†å²æ•°æ® (æ ‘è“æ´¾æ¨¡å¼)..."
    }
else:
    # ğŸ’» PC å¼€å‘æ¨¡å¼ï¼šttl=0 ç­‰äºä¸ç¼“å­˜/ç«‹å³è¿‡æœŸ
    # æ¯æ¬¡åˆ·æ–°éƒ½é‡æ–°è®¡ç®—ï¼Œæ–¹ä¾¿ä½ è°ƒè¯•ä»£ç æˆ–æ•°æ®
    CACHE_PARAMS = {
        "persist": None, 
        "ttl": 0, 
        "show_spinner": "æ­£åœ¨å®æ—¶è®¡ç®— (PCå¼€å‘æ¨¡å¼)..."
    }

# 2. åº”ç”¨åŠ¨æ€å‚æ•°
@st.cache_data(**CACHE_PARAMS)
def get_cached_analytics_data(user_id):
    """
    æ›¿ä»£åŸæ¥çš„ process_analytics_dataï¼Œå¢åŠ äº†æ™ºèƒ½ç¼“å­˜æœºåˆ¶
    """
    # å»¶è¿ŸåŠ è½½é‡å‹åº“
    import pandas as pd
    import sqlite3
    
    # å‡½æ•°å†…éƒ¨å»ºç«‹è¿æ¥ (å› ä¸ºè¿æ¥å¯¹è±¡ä¸èƒ½è¢«ç¼“å­˜)
    local_conn = sqlite3.connect(DB_FILE)
    
    try:
        # --- åŸæœ‰é€»è¾‘å¼€å§‹ ---
        # 1. è·å–åŸºç¡€æ•°æ®
        df_raw = pd.read_sql('''
            SELECT s.date, s.asset_id, s.amount, s.profit, s.cost, s.yield_rate, a.name, a.currency, a.type
            FROM snapshots s
            JOIN assets a ON s.asset_id = a.asset_id
            WHERE a.user_id = ?
        ''', local_conn, params=(user_id,))

        if df_raw.empty:
            return None, None

        df_raw['date'] = pd.to_datetime(df_raw['date'])
        
        # 2. è·å–æ±‡ç‡è¡¨
        df_rates = pd.read_sql("SELECT date, currency, rate FROM exchange_rates", local_conn)
        df_rates['date'] = pd.to_datetime(df_rates['date'])
        
        # 3. æ±‡ç‡åŒ¹é…ä¸æŠ˜ç®—
        df_merged = pd.merge(df_raw, df_rates, on=['date', 'currency'], how='left')
        
        df_merged['rate'] = df_merged.apply(
            lambda row: 1.0 if row['currency'] == 'CNY' else row['rate'], axis=1
        )
        df_merged['rate'] = df_merged['rate'].fillna(1.0)
        
        df_merged['amount_cny'] = df_merged['amount'] * df_merged['rate']
        df_merged['profit_cny'] = df_merged['profit'] * df_merged['rate']
        df_merged['cost_cny'] = df_merged['cost'] * df_merged['rate']
        
        # 4. è·å–æ ‡ç­¾ (ğŸ”¥ æ¢å¤å…¨é‡æŸ¥è¯¢ï¼Œä¸åœ¨è¿™é‡Œå‰”é™¤ï¼Œä»¥å…å½±å“å…¶ä»–å›¾è¡¨)
        df_tags = pd.read_sql('''
            SELECT t.tag_group, t.tag_name, atm.asset_id
            FROM tags t
            JOIN asset_tag_map atm ON t.tag_id = atm.tag_id
            WHERE t.user_id = ?
        ''', local_conn, params=(user_id,))

        # --- ğŸ”¥ å‡†å¤‡å·¥ä½œï¼šè·å–â€œå·²æ¸…ä»“â€èµ„äº§ ID é›†åˆ ---
        # ä»…ç”¨äºä¸‹æ–¹çš„å®Œæ•´æ€§æ ¡éªŒé€»è¾‘
        cleared_assets_set = set()
        status_df = pd.read_sql('SELECT asset_id, is_cleared FROM snapshots ORDER BY date DESC', local_conn)
        if not status_df.empty:
            # è¿™é‡Œçš„ drop_duplicates ä¼šä¿ç•™æ¯ä¸ª asset_id çš„æœ€æ–°ä¸€æ¡è®°å½•
            latest_status = status_df.drop_duplicates(subset=['asset_id'])
            # æ‹¿åˆ°æ‰€æœ‰æœ€æ–°çŠ¶æ€ä¸º 1 (å·²æ¸…ä»“) çš„ ID
            cleared_assets_set = set(latest_status[latest_status['is_cleared'] == 1]['asset_id'].tolist())

        # 5. æ ‡ç­¾èšåˆè®¡ç®—
        tag_analytics = []
        if not df_tags.empty:
            merged_tags = pd.merge(df_merged, df_tags, on='asset_id', how='inner')
            
            # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šé¢„å…ˆè®¡ç®—æ¯ä¸ªæ ‡ç­¾ç»„ä¸‹ã€ç†è®ºä¸Šåº”è¯¥æœ‰å“ªäº›èµ„äº§ IDã€‘
            # å˜æˆå­—å…¸ï¼š{ ('èµ„äº§å¤§ç±»', 'åŸºé‡‘'): {1, 2, 3}, ... }
            tag_expected_ids_map = df_tags.groupby(['tag_group', 'tag_name'])['asset_id'].apply(set).to_dict()
            
            grouped = merged_tags.groupby(['date', 'tag_group', 'tag_name'])
            
            for name, group in grouped:
                date, tag_group, tag_name = name
                total_amount = group['amount_cny'].sum()
                total_profit = group['profit_cny'].sum()
                total_cost = group['cost_cny'].sum()
                weighted_yield = (total_profit / total_cost * 100) if total_cost != 0 else 0.0
                
                # --- ğŸ”¥ å¾®è°ƒåçš„æ ¡éªŒé€»è¾‘ ---
                # 1. ç†è®ºåº”æœ‰çš„èµ„äº§ ID é›†åˆ
                expected_ids = tag_expected_ids_map.get((tag_group, tag_name), set())
                # 2. å®é™…å½“æ—¥å½•å…¥çš„èµ„äº§ ID é›†åˆ
                current_ids = set(group['asset_id'])
                
                # 3. è®¡ç®—ç¼ºå¤±çš„ ID
                missing_ids = expected_ids - current_ids
                
                # 4. å…³é”®ä¸€æ­¥ï¼šä»ç¼ºå¤±åå•ä¸­ï¼Œå‰”é™¤æ‰é‚£äº›â€œå·²æ¸…ä»“â€çš„
                # å¦‚æœç¼ºå¤±çš„èµ„äº§æœ¬æ¥å°±æ˜¯å·²æ¸…ä»“çš„ï¼Œé‚£å°±ä¸ç®—ç¼ºå¤±
                real_missing_ids = missing_ids - cleared_assets_set
                
                tag_analytics.append({
                    'date': date, 'tag_group': tag_group, 'tag_name': tag_name,
                    'amount': total_amount, 'profit': total_profit, 'cost': total_cost,
                    'yield_rate': weighted_yield, 
                    # åªæœ‰å½“ã€çœŸæ­£ã€‘ç¼ºå¤±çš„æ•°é‡ä¸º 0 æ—¶ï¼Œæ‰ç®—å®Œæ•´
                    'is_complete': len(real_missing_ids) == 0,
                    'missing_count': len(real_missing_ids)
                })
                
        df_tags_agg = pd.DataFrame(tag_analytics)
        
        # æ„é€ è¿”å›
        df_final_assets = df_merged.copy()
        df_final_assets['amount'] = df_final_assets['amount_cny']
        df_final_assets['profit'] = df_final_assets['profit_cny']
        df_final_assets['cost'] = df_final_assets['cost_cny']
        
        return df_final_assets, df_tags_agg
        
    finally:
        local_conn.close()

# --- åŒ…è£…å‡½æ•°ï¼šå¸¦ç¼“å­˜çš„æŒ‡æ•°è·å– ---
@st.cache_data(ttl=3600*12)  # ç¼“å­˜æ§åˆ¶ä¾ç„¶åœ¨ UI å±‚
def get_market_index_data_cached(index_name, start_date_str, end_date_str):
    # è°ƒç”¨ DataProvider çš„çº¯é€»è¾‘æ–¹æ³•
    return DataProvider.get_market_index_data(index_name, start_date_str, end_date_str)

# --- æ–°ç‰ˆçœ‹æ¿é¡µé¢ ---
def page_dashboard():
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    import numpy as np
    from datetime import datetime, timedelta
    
    st.header("ğŸ“Š ä¸ªäººåŸºé‡‘é©¾é©¶èˆ±(é•¿æµåŸºé‡‘)")
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    # ==========================================
    # 1. é¡¶éƒ¨æ ¸å¿ƒæŒ‡æ ‡
    # ==========================================
    df_fund = pd.read_sql('SELECT * FROM my_fund_history WHERE user_id = ? ORDER BY date ASC', conn, params=(user_id,))
    
    if not df_fund.empty:
        df_fund['date'] = pd.to_datetime(df_fund['date'])
        latest = df_fund.iloc[-1]
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡ (ç™¾åˆ†æ¯”)
        total_ret_pct = (latest['unit_nav'] - 1.0) * 100
        
        # å¸ƒå±€æ”¹ä¸º 5 åˆ—
        k1, k2, k3, k4, k5 = st.columns(5)
        
        with k1:
            st.metric("å½“å‰æ€»èµ„äº§", f"Â¥{latest['total_assets']/10000:,.2f}ä¸‡", 
                      help="å½“å‰ä¸ªäººåŸºé‡‘çš„æ€»å¸‚å€¼")
        with k2:
            st.metric("æŒæœ‰æ”¶ç›Š", f"Â¥{latest['accumulated_profit']:,.2f}")
        with k3:
            st.metric("æœ€æ–°å‡€å€¼", f"{latest['unit_nav']:.4f}", 
                      delta=f"{latest['daily_return']*100:.2f}% (æœ€æ–°)", 
                      delta_color="normal")
        with k4:
            st.metric("ç´¯è®¡æ”¶ç›Šç‡", f"{total_ret_pct:.2f}%", 
                      help="å•ä½å‡€å€¼ç›¸å¯¹äº 1.0 çš„æ¶¨å¹…")
        with k5:
            st.metric("å†å²æœ€å¤§å›æ’¤", f"{df_fund['drawdown'].min()*100:.2f}%", 
                      delta_color="inverse")
        
        st.divider()
    else:
        st.info("â³ æš‚æ— åŸºé‡‘å‡€å€¼æ•°æ®ï¼Œè¯·å…ˆå»ã€æ•°æ®å½•å…¥ã€‘ä¿å­˜ä¸€æ¬¡å¿«ç…§ã€‚")
        conn.close()
        return
    
    # ==========================================
    # 2. å‡†å¤‡è¯¦ç»†èµ„äº§æ•°æ®
    # ==========================================
    df_assets, df_tags = get_cached_analytics_data(user_id)
    
    # ==========================================
    # 3. åŠŸèƒ½æ ‡ç­¾é¡µ
    # ==========================================
    tab1, tab2, tab3 = st.tabs(["ğŸš€ å‡€å€¼ä¸å›æ’¤", "ğŸ“ˆ ç»“æ„å¯¹æ¯”", "ğŸ° æ¯æ—¥é€è§†"])
    
   
    # --- Tab 1: åŸºé‡‘å‡€å€¼ä¸å›æ’¤ (å…¨å›¾è¡¨ä¼˜åŒ–ç‰ˆ) ---
    with tab1:
        if not df_fund.empty:
            # 1. é¡¶éƒ¨é€šç”¨æ—¶é—´ç­›é€‰
            st.write("â±ï¸ **ç»Ÿè®¡å‘¨æœŸé€‰æ‹©**")
            period_map = {
                "è¿‘1æœˆ": 30, "è¿‘3æœˆ": 90, "è¿‘6æœˆ": 180, 
                "è¿‘1å¹´": 365, "è¿‘3å¹´": 365*3, "è¿‘5å¹´": 365*5, "æˆç«‹ä»¥æ¥": 99999
            }
            sel_period = st.radio("ç»Ÿè®¡å‘¨æœŸ", list(period_map.keys()), index=3, horizontal=True, label_visibility="collapsed", key="dash_period_sel")
            
            # 2. æ•°æ®åˆ‡ç‰‡
            days = period_map[sel_period]
            end_date = df_fund['date'].max()
            start_date_limit = end_date - timedelta(days=days)
            
            if sel_period == "æˆç«‹ä»¥æ¥":
                df_slice = df_fund.copy()
            else:
                df_slice = df_fund[df_fund['date'] >= start_date_limit].copy()

            if df_slice.empty:
                st.warning("æ‰€é€‰å‘¨æœŸå†…æ— æ•°æ®")
            else:
                # å®šä¹‰é€šç”¨çš„ X è½´æ ·å¼é…ç½® (å¤ç”¨ä»£ç )
                common_xaxis_config = dict(
                    title="æ—¥æœŸ",
                    tickformat="%Yå¹´%mæœˆ%dæ—¥", 
                    tickmode='array',
                    tickvals=[df_slice['date'].min(), df_slice['date'].max()], # ä»…æ˜¾ç¤ºé¦–å°¾
                    tickangle=0,
                    ticklabelmode='period',
                    range=[
                        df_slice['date'].min() - pd.Timedelta(days=1), 
                        df_slice['date'].max() + pd.Timedelta(days=3)
                    ]
                )

                # === A. ç¬¬ä¸€æ’ï¼šæ€»èµ„äº§ & æŒæœ‰æ”¶ç›Š ===
                c_top1, c_top2 = st.columns(2)
                
                with c_top1:
                    st.subheader("æ€»èµ„äº§å˜åŒ–")
                    fig_asset = go.Figure()
                    fig_asset.add_trace(go.Scatter(
                        x=df_slice['date'], 
                        y=df_slice['total_assets'] / 10000, 
                        mode='lines', name='æ€»èµ„äº§',
                        line=dict(width=2, color='#2980B9'),
                        fill='tozeroy',
                        fillcolor='rgba(41, 128, 185, 0.2)',
                        hovertemplate='æ—¥æœŸ: %{x|%Yå¹´%mæœˆ%dæ—¥}<br>æ€»èµ„äº§: %{y:.2f} ä¸‡å…ƒ<extra></extra>'
                    ))
                    fig_asset.update_layout(
                        hovermode="x unified", height=350, margin=dict(t=10),
                        yaxis=dict(title="é‡‘é¢ (ä¸‡å…ƒ)", tickformat=",.2f"),
                        xaxis=common_xaxis_config # åº”ç”¨é€šç”¨é…ç½®
                    )
                    st.plotly_chart(fig_asset, use_container_width=True)

                with c_top2:
                    st.subheader("æŒæœ‰æ”¶ç›Šå˜åŒ–")
                    fig_profit = go.Figure()
                    fig_profit.add_trace(go.Scatter(
                        x=df_slice['date'], y=df_slice['accumulated_profit'],
                        mode='lines', name='æŒæœ‰æ”¶ç›Š',
                        line=dict(width=2, color='#E74C3C'), # çº¢è‰²
                        fill='tozeroy', # å¢åŠ å¡«å……ï¼Œé£æ ¼ç»Ÿä¸€
                        fillcolor='rgba(231, 76, 60, 0.2)', # æ·¡çº¢è‰²èƒŒæ™¯
                        hovertemplate='æ—¥æœŸ: %{x|%Yå¹´%mæœˆ%dæ—¥}<br>æŒæœ‰æ”¶ç›Š: %{y:,.2f} å…ƒ<extra></extra>'
                    ))
                    fig_profit.update_layout(
                        hovermode="x unified", height=350, margin=dict(t=10),
                        yaxis=dict(title="é‡‘é¢ (å…ƒ)", tickformat=",.2f"),
                        xaxis=common_xaxis_config # åº”ç”¨é€šç”¨é…ç½®
                    )
                    st.plotly_chart(fig_profit, use_container_width=True)

                st.divider()

                # === B. ç¬¬äºŒæ’ï¼šä¸šç»©èµ°åŠ¿ & å›æ’¤ä¿®å¤ ===
                
                nav_start = df_slice.iloc[0]['unit_nav']
                nav_end = df_slice.iloc[-1]['unit_nav']
                period_return = (nav_end - nav_start) / nav_start
                return_color = "red" if period_return >= 0 else "green"
                return_sign = "+" if period_return >= 0 else ""

                c_chart1, c_chart2 = st.columns(2)
                
                with c_chart1:
                    # æ ‡é¢˜æ ï¼šå·¦è¾¹æ ‡é¢˜ï¼Œå³è¾¹æ”¾ä¸ªå°çš„ä¸‹æ‹‰æ¡†
                    h_col1, h_col2 = st.columns([2, 1])
                    with h_col1:
                        st.subheader("ä¸šç»©èµ°åŠ¿")
                    with h_col2:
                        benchmark_name = st.selectbox(
                            "ğŸ†š å¯¹æ¯”åŸºå‡†", 
                            ["(æ— )", "æ²ªæ·±300", "çº³æ–¯è¾¾å…‹100", "æ ‡æ™®500"], 
                            index=3,
                            label_visibility="collapsed",
                            key="bench_sel"
                        )

                    # æ˜¾ç¤ºæ¶¨è·Œå¹…æ–‡æœ¬
                    st.markdown(f"åŒºé—´æ¶¨è·Œ: <span style='color:{return_color}; font-weight:bold; font-size:1.1em'>{return_sign}{period_return*100:.2f}%</span>", unsafe_allow_html=True)
                    
                    fig_nav = px.line(df_slice, x='date', y='unit_nav', title=None)
                    
                    # 1. ä¸ªäººåŸºé‡‘æ›²çº¿ (å®çº¿ï¼Œçº¢è‰²)
                    fig_nav.update_traces(
                        showlegend=True,
                        line_color="#0E44E5", line_width=2.5, name='æˆ‘çš„å‡€å€¼',
                        hovertemplate='å‡€å€¼: %{y:.4f}<extra></extra>'
                    )
                    
                    # 2. å¯¹æ¯”æŒ‡æ•°æ›²çº¿
                    if benchmark_name != "(æ— )":
                        # è·å–æŒ‡æ•°æ•°æ® (æ—¶é—´èŒƒå›´ç¨å¾®æ”¾å®½ä¸€ç‚¹ï¼Œé˜²æ­¢æ—¶åŒºå·®å¼‚å¯¼è‡´å–ä¸åˆ°èµ·ç‚¹)
                        s_str = df_slice['date'].min().strftime('%Y-%m-%d')
                        e_str = df_slice['date'].max().strftime('%Y-%m-%d')
                        
                        df_bench = get_market_index_data_cached(benchmark_name, s_str, e_str)
                        
                        if not df_bench.empty and len(df_bench) > 1:
                            # --- æ ¸å¿ƒï¼šå½’ä¸€åŒ–å¤„ç† (Rebase) ---
                            # é€»è¾‘ï¼šè®©æŒ‡æ•°çš„èµ·ç‚¹ï¼Œè·Ÿæˆ‘çš„åŸºé‡‘èµ·ç‚¹å¯¹é½
                            my_start_nav = df_slice.iloc[0]['unit_nav'] # æˆ‘çš„èµ·ç‚¹å‡€å€¼ (e.g. 1.2)
                            bench_start_val = df_bench.iloc[0]['close'] # æŒ‡æ•°èµ·ç‚¹ç‚¹ä½ (e.g. 4000)
                            
                            if bench_start_val > 0:
                                # è®¡ç®—å½’ä¸€åŒ–åçš„å‡€å€¼æ›²çº¿
                                df_bench['rebased_nav'] = (df_bench['close'] / bench_start_val) * my_start_nav
                                
                                # è®¡ç®—æŒ‡æ•°æ¶¨è·Œå¹…ç”¨äºå›¾ä¾‹æ˜¾ç¤º
                                bench_ret = (df_bench.iloc[-1]['close'] - bench_start_val) / bench_start_val
                                b_sign = "+" if bench_ret >= 0 else ""
                                
                                fig_nav.add_trace(go.Scatter(
                                    x=df_bench['date'], 
                                    y=df_bench['rebased_nav'],
                                    mode='lines',
                                    name=f'{benchmark_name} ({b_sign}{bench_ret*100:.1f}%)',
                                    line_color="#29BEF0", line_width=2.5, opacity=0.2,
                                    hovertemplate=f'{benchmark_name}: %{{y:.4f}}<extra></extra>'
                                ))
                        else:
                            st.caption(f"âš ï¸ æš‚æœªè·å–åˆ° {benchmark_name} æ•°æ® (å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–éäº¤æ˜“æ—¥)")

                    # åŸºå‡†çº¿ 1.0
                    fig_nav.add_hline(y=1.0, line_dash="solid", line_color="#ECF0F1", line_width=1)
                    
                    fig_nav.update_layout(
                        hovermode="x unified", 
                        yaxis_title="å•ä½å‡€å€¼", 
                        height=380, 
                        margin=dict(t=10),
                        legend=dict(
                            orientation="h",  # ä¿æŒæ°´å¹³æ’åˆ—ï¼ˆä¸¤ä¸ªå›¾ä¾‹å¹¶æ’ï¼‰
                            yanchor="top", y=0.1,    # å‚ç›´ä½ç½®ï¼šå›¾è¡¨å†…ä¾§é¡¶éƒ¨
                            xanchor="right", x=0.98,   # æ°´å¹³ä½ç½®ï¼šå›¾è¡¨å†…ä¾§å³ä¾§
                            bgcolor="rgba(0,0,0,0)", # ç™½è‰²åŠé€æ˜èƒŒæ™¯ï¼Œé®æŒ¡ä¸‹æ–¹æ›²çº¿æ›´æ¸…æ™°
                            bordercolor="rgba(0,0,0,0)"     # æ— è¾¹æ¡†ï¼Œæ›´ç¾è§‚
                        ),
                        xaxis=common_xaxis_config # å¤ç”¨ä¹‹å‰çš„é€šç”¨é…ç½®
                    )
                    st.plotly_chart(fig_nav, use_container_width=True)

                with c_chart2:
                    st.subheader("å›æ’¤ä¿®å¤")
                    
                    # å›æ’¤ç®—æ³•
                    df_slice['rolling_max'] = df_slice['unit_nav'].cummax()
                    df_slice['period_dd'] = (df_slice['unit_nav'] - df_slice['rolling_max']) / df_slice['rolling_max']
                    
                    min_dd_val = df_slice['period_dd'].min()
                    trough_idx = df_slice['period_dd'].idxmin()
                    trough_date = df_slice.loc[trough_idx]['date']
                    trough_nav = df_slice.loc[trough_idx]['unit_nav']
                    
                    peak_val = df_slice.loc[trough_idx]['rolling_max']
                    peak_date = df_slice[(df_slice['date'] <= trough_date) & (df_slice['unit_nav'] >= peak_val)].iloc[-1]['date']
                    
                    recover_df = df_slice[(df_slice['date'] > trough_date) & (df_slice['unit_nav'] >= peak_val)]
                    repair_status = "æœªä¿®å¤"
                    end_shade_date = df_slice['date'].max()
                    
                    if not recover_df.empty:
                        recover_date = recover_df.iloc[0]['date']
                        days_used = (recover_date - peak_date).days
                        repair_status = f"{days_used}å¤©ä¿®å¤"
                        end_shade_date = recover_date
                    else:
                        repair_status = "ä¿®å¤ä¸­..."

                    st.markdown(f"åŒºé—´æœ€å¤§å›æ’¤: **{min_dd_val*100:.2f}%** | çŠ¶æ€: **{repair_status}**")

                    fig_repair = go.Figure()
                    fig_repair.add_trace(go.Scatter(
                        x=df_slice['date'], y=df_slice['unit_nav'], 
                        mode='lines', name='å‡€å€¼', 
                        line=dict(color='#2980B9', width=2),
                        hovertemplate='æ—¥æœŸ: %{x|%Yå¹´%mæœˆ%dæ—¥}<br>å•ä½å‡€å€¼: %{y:.4f}<extra></extra>'
                    ))
                    
                    if abs(min_dd_val) > 0.001:
                        fig_repair.add_vrect(
                            x0=peak_date, x1=end_shade_date,
                            fillcolor="rgba(231, 76, 60, 0.2)", layer="below", line_width=0
                        )
                        fig_repair.add_trace(go.Scatter(
                            x=[trough_date], y=[trough_nav],
                            mode='markers+text',
                            text=[f"æœ€å¤§å›æ’¤\n{min_dd_val*100:.2f}%"],
                            textposition="bottom center",
                            marker=dict(color='red', size=8), showlegend=False,
                            hovertemplate='æ—¥æœŸ: %{x|%Yå¹´%mæœˆ%dæ—¥}<br>æœ€å¤§å›æ’¤ç‚¹: %{y:.4f}<extra></extra>'
                        ))
                        fig_repair.add_trace(go.Scatter(x=[peak_date], y=[peak_val], mode='markers', marker=dict(color='green', size=6), showlegend=False, hoverinfo='skip'))

                    fig_repair.update_layout(
                        showlegend=False,
                        hovermode="x unified", yaxis_title="å•ä½å‡€å€¼", height=380, margin=dict(t=10),
                        xaxis=common_xaxis_config # åº”ç”¨é€šç”¨é…ç½®
                    )
                    st.plotly_chart(fig_repair, use_container_width=True)

    # --- Tab 2: ç»“æ„å¯¹æ¯” (å®Œæ•´æ‰¾å›ç‰ˆ) ---
    with tab2:
        st.subheader("ğŸ“Š ç»“æ„åŒ–è¶‹åŠ¿åˆ†æ")
        
        # 1. ç­›é€‰ä¸ç»˜å›¾æ§åˆ¶
        c1, c2, c3 = st.columns([1, 1, 2])
        with c1:
            view_mode = st.radio("åˆ†æç»´åº¦", ["æŒ‰å…·ä½“èµ„äº§", "æŒ‰æ ‡ç­¾ç»„"], horizontal=True, key="trend_view")
        with c2:
            metric_type = st.selectbox("ç”»å›¾æŒ‡æ ‡ (Yè½´)", ["æ€»é‡‘é¢ (Amount)", "æŒæœ‰æ”¶ç›Š (Profit)", "æ”¶ç›Šç‡ (Yield %)", "å æ¯” (Share %)"], key="trend_metric")
        with c3:
            tooltip_extras = st.multiselect("ğŸ–±ï¸ æ‚¬åœæ˜¾ç¤ºé¢å¤–æŒ‡æ ‡", ["æ€»é‡‘é¢", "æŒæœ‰æ”¶ç›Š", "æœ¬é‡‘", "æ”¶ç›Šç‡", "å æ¯”"], default=["å æ¯”", "æŒæœ‰æ”¶ç›Š", "æ”¶ç›Šç‡"], key="trend_tooltip")

        plot_df = None
        color_col = ""
        
        # 1.1 æ•°æ®ç­›é€‰é€»è¾‘
        if view_mode == "æŒ‰å…·ä½“èµ„äº§":
            plot_df = df_assets.copy()
            color_col = "name"
            
            with st.expander("ğŸ” èµ„äº§ç²¾å‡†ç­›é€‰", expanded=False):
                f_col1, f_col2, f_col3 = st.columns([2, 2, 2])
                with f_col1:
                    filter_kw = st.text_input("1. å…³é”®å­— (åç§°/ä»£ç )", placeholder="æœè‚¡ç¥¨ã€åŸºé‡‘...", key="trend_kw")
                
                # ä¸´æ—¶æŸ¥ä¸€ä¸‹æ ‡ç­¾æ˜ å°„
                conn_temp = get_db_connection()
                df_tag_map = pd.read_sql('''
                    SELECT t.tag_group, t.tag_name, atm.asset_id 
                    FROM tags t JOIN asset_tag_map atm ON t.tag_id = atm.tag_id
                    WHERE t.user_id = ?
                ''', conn_temp, params=(user_id,))
                conn_temp.close()

                with f_col2:
                    if not df_tag_map.empty:
                        all_groups = sorted(df_tag_map['tag_group'].unique().tolist())
                        sel_filter_group = st.selectbox("2. ç­›é€‰æ ‡ç­¾ç»„", ["(å…¨éƒ¨)"] + all_groups, key="trend_f_group")
                    else:
                        sel_filter_group = "(å…¨éƒ¨)"
                        st.selectbox("2. ç­›é€‰æ ‡ç­¾ç»„", ["(æ— æ ‡ç­¾æ•°æ®)"], disabled=True)
                        
                with f_col3:
                    if sel_filter_group != "(å…¨éƒ¨)" and not df_tag_map.empty:
                        available_tags = sorted(df_tag_map[df_tag_map['tag_group'] == sel_filter_group]['tag_name'].unique().tolist())
                        sel_filter_tag = st.selectbox("3. ç­›é€‰æ ‡ç­¾å", ["(å…¨éƒ¨)"] + available_tags, key="trend_f_tag")
                    else:
                        sel_filter_tag = "(å…¨éƒ¨)"
                        st.selectbox("3. ç­›é€‰æ ‡ç­¾å", ["(å…ˆé€‰æ ‡ç­¾ç»„)"], disabled=True)

                # æ‰§è¡Œç­›é€‰
                valid_asset_ids = set(plot_df['asset_id'].unique())
                if sel_filter_group != "(å…¨éƒ¨)" and not df_tag_map.empty:
                    target_map = df_tag_map[df_tag_map['tag_group'] == sel_filter_group]
                    if sel_filter_tag != "(å…¨éƒ¨)":
                        target_map = target_map[target_map['tag_name'] == sel_filter_tag]
                    valid_asset_ids = valid_asset_ids.intersection(set(target_map['asset_id']))
                
                if filter_kw:
                    # æ£€æŸ¥ name åˆ—æ˜¯å¦å­˜åœ¨ï¼Œé˜²æ­¢æç«¯æƒ…å†µæŠ¥é”™
                    if 'name' in plot_df.columns:
                        kw_matched = plot_df[plot_df['name'].str.contains(filter_kw, case=False, na=False)]
                        valid_asset_ids = valid_asset_ids.intersection(set(kw_matched['asset_id']))
                
                # æœ€ç»ˆé€‰æ‹©æ¡†
                asset_meta = plot_df[['asset_id', 'name']].drop_duplicates()
                asset_meta = asset_meta[asset_meta['asset_id'].isin(valid_asset_ids)]
                available_names = sorted(asset_meta['name'].unique().tolist())
                
                selected_assets = st.multiselect(
                    f"4. å‹¾é€‰è¦å¯¹æ¯”çš„èµ„äº§ (ç­›é€‰åå¯é€‰ {len(available_names)} ä¸ª)",
                    options=available_names,
                    placeholder="ç•™ç©ºåˆ™æ˜¾ç¤ºç­›é€‰å‡ºçš„ã€æ‰€æœ‰ã€‘èµ„äº§...",
                    key="trend_final_select"
                )
                
                if selected_assets:
                    plot_df = plot_df[plot_df['name'].isin(selected_assets)]
                else:
                    plot_df = plot_df[plot_df['asset_id'].isin(valid_asset_ids)]
                
        else: # æŒ‰æ ‡ç­¾ç»„
            if df_tags is None or df_tags.empty:
                st.warning("æš‚æ— æ ‡ç­¾æ•°æ®ã€‚")
            else:
                groups = df_tags['tag_group'].unique()
                selected_group = st.selectbox("é€‰æ‹©æ ‡ç­¾åˆ†ç»„", groups, key="trend_group")
                plot_df = df_tags[df_tags['tag_group'] == selected_group].copy()
                color_col = "tag_name"

        # 1.2 ç»˜åˆ¶æŠ˜çº¿å›¾
        if plot_df is not None and not plot_df.empty:
            plot_df['amt_w'] = plot_df['amount'] / 10000
            plot_df['prof_w'] = plot_df['profit'] / 10000
            plot_df['cost_w'] = plot_df['cost'] / 10000
            daily_sums = plot_df.groupby('date')['amount'].transform('sum')
            plot_df['share'] = (plot_df['amount'] / daily_sums * 100).fillna(0)

            y_col, y_unit, y_title = "amt_w", "w", "é‡‘é¢ (ä¸‡)"
            if metric_type.startswith("æŒæœ‰æ”¶ç›Š"): y_col, y_unit, y_title = "prof_w", "w", "æ”¶ç›Š (ä¸‡)"
            elif metric_type.startswith("æ”¶ç›Šç‡"): y_col, y_unit, y_title = "yield_rate", "%", "æ”¶ç›Šç‡ (%)"
            elif metric_type.startswith("å æ¯”"): y_col, y_unit, y_title = "share", "%", "å æ¯” (%)"

            custom_data_cols = ['amt_w', 'prof_w', 'cost_w', 'yield_rate', 'share']
            fig = px.line(plot_df, x='date', y=y_col, color=color_col, markers=True, custom_data=custom_data_cols)
            
            hover_html = f"<b>%{{fullData.name}}</b>: <b>{metric_type.split(' ')[0]}:%{{y:.2f}}{y_unit}</b>"
            extra_info = []
            if "æ€»é‡‘é¢" in tooltip_extras: extra_info.append("ğŸ’°%{customdata[0]:.2f}w")
            if "æŒæœ‰æ”¶ç›Š" in tooltip_extras: extra_info.append("ğŸ“ˆ%{customdata[1]:.2f}w")
            if "æœ¬é‡‘" in tooltip_extras: extra_info.append("ğŸŒ±%{customdata[2]:.2f}w")
            if "æ”¶ç›Šç‡" in tooltip_extras: extra_info.append("ğŸš€%{customdata[3]:.1f}%")
            if "å æ¯”" in tooltip_extras: extra_info.append("ğŸ°%{customdata[4]:.1f}%")
            if extra_info: hover_html += "<br>" + "   ".join(extra_info)
            hover_html += "<extra></extra>"
            
            fig.update_traces(hovertemplate=hover_html)
            fig.update_layout(hovermode="x unified", yaxis_title=y_title, legend_title_text="")
            st.plotly_chart(fig, use_container_width=True)

            # 1.3 ä¸¤æœŸæ•°æ®æ¨ªå‘æ¯”å¯¹
            st.divider()
            st.subheader("ä¸¤æœŸæ•°æ®æ¨ªå‘æ¯”å¯¹")
            
            # === ğŸ”¥ æ ¸å¿ƒä¿®æ”¹å¼€å§‹ï¼šæ™ºèƒ½è®¡ç®—é»˜è®¤å¯¹æ¯”æ—¥æœŸ ===
            # 1. æå–å½“å‰ç­›é€‰èŒƒå›´å†…æ‰€æœ‰çš„æœ‰æ•ˆæ—¥æœŸ (å»é‡å¹¶æ’åº)
            available_dates = sorted(plot_df['date'].dt.date.unique())
            
            if not available_dates:
                st.warning("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ•°æ®ã€‚")
            else:
                # 2. è®¾å®šé»˜è®¤å€¼
                # é»˜è®¤ B (æ–°) = æœ€æ–°çš„ä¸€å¤©
                default_d2 = available_dates[-1]
                
                # é»˜è®¤ A (æ—§) = æœ€æ–°æ—¥æœŸçš„â€œä¸Šä¸€æ¡æœ‰æ•ˆè®°å½•â€
                # é€»è¾‘ï¼šå¦‚æœæœ‰ >=2 å¤©çš„æ•°æ®ï¼Œå–å€’æ•°ç¬¬2ä¸ªï¼›å¦åˆ™å–ç¬¬1ä¸ª
                if len(available_dates) > 1:
                    default_d1 = available_dates[-2]
                else:
                    default_d1 = available_dates[0]

                # 3. è®¾å®šæ—¥æœŸé€‰æ‹©å™¨çš„èŒƒå›´
                valid_min = available_dates[0]
                valid_max = available_dates[-1]
                
                dc1, dc2, dc3 = st.columns([2, 2, 3])
                with dc1:
                    d1_input = st.date_input(
                        "ğŸ“… æ—¥æœŸ A (æ—§)", 
                        value=default_d1, 
                        min_value=valid_min, 
                        max_value=valid_max, 
                        key="diff_d1",
                        help="é»˜è®¤é€‰ä¸­æœ€æ–°æ—¥æœŸçš„ä¸Šä¸€æ¡æœ‰æ•ˆè®°å½•"
                    )
                with dc2:
                    d2_input = st.date_input(
                        "ğŸ“… æ—¥æœŸ B (æ–°)", 
                        value=default_d2, 
                        min_value=valid_min, 
                        max_value=valid_max, 
                        key="diff_d2"
                    )
                with dc3:
                    diff_metric = st.radio("å¯¹æ¯”æŒ‡æ ‡", ["æ€»é‡‘é¢ (Amount)", "æŒæœ‰æ”¶ç›Š (Profit)", "æ”¶ç›Šç‡ (Yield %)", "å æ¯” (Share %)"], horizontal=True, key="diff_m")

                d1_ts = pd.Timestamp(d1_input)
                d2_ts = pd.Timestamp(d2_input)
                
                # å†æ¬¡æ ¡éªŒç”¨æˆ·é€‰çš„æ—¥æœŸæ˜¯å¦çœŸçš„æœ‰æ•°æ® (é˜²æ­¢ç”¨æˆ·æ‰‹åŠ¨é€‰äº†ä¸­é—´çš„ç©ºæ¡£æ—¥)
                has_d1 = not plot_df[plot_df['date'] == d1_ts].empty
                has_d2 = not plot_df[plot_df['date'] == d2_ts].empty

                if d1_ts == d2_ts:
                    st.info("è¯·é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æ—¥æœŸè¿›è¡Œå¯¹æ¯”ã€‚")
                elif not has_d1 or not has_d2:
                    st.warning(f"æ‰€é€‰æ—¥æœŸæ— æ•°æ®ã€‚è¯·ç¡®ä¿é€‰ä¸­çš„æ—¥æœŸ ({d1_input} æˆ– {d2_input}) æœ‰èµ„äº§å¿«ç…§è®°å½•ã€‚")
                else:
                    if "æ€»é‡‘é¢" in diff_metric: val_col = "amount"; unit_suffix = "å…ƒ"
                    elif "æŒæœ‰æ”¶ç›Š" in diff_metric: val_col = "profit"; unit_suffix = "å…ƒ"
                    elif "æ”¶ç›Šç‡" in diff_metric: val_col = "yield_rate"; unit_suffix = "%"
                    elif "å æ¯”" in diff_metric: val_col = "share"; unit_suffix = "%"

                    df_d1 = plot_df[plot_df['date'] == d1_ts].copy(); df_d1['Period'] = d1_ts.strftime('%Y-%m-%d')
                    df_d2 = plot_df[plot_df['date'] == d2_ts].copy(); df_d2['Period'] = d2_ts.strftime('%Y-%m-%d')
                    df_viz = pd.concat([df_d1, df_d2], ignore_index=True)
                    
                    # æ’åºä¼˜åŒ–
                    rank_order = df_d2.sort_values(val_col, ascending=False)[color_col].tolist()
                    
                    fig_compare = px.bar(
                        df_viz, x=color_col, y=val_col, color='Period', barmode='group', 
                        category_orders={color_col: rank_order}, text_auto='.2s' if unit_suffix == "å…ƒ" else '.2f'
                    )
                    
                    metric_label = diff_metric.split(' ')[0]
                    if unit_suffix == "å…ƒ":
                        hover_template = f"<b>%{{x}}</b><br>ğŸ“… %{{fullData.name}}<br>{metric_label}: <b>Â¥%{{y:,.2f}}</b><extra></extra>"
                    else:
                        hover_template = f"<b>%{{x}}</b><br>ğŸ“… %{{fullData.name}}<br>{metric_label}: <b>%{{y:.2f}}%</b><extra></extra>"
                    fig_compare.update_traces(hovertemplate=hover_template)
                    fig_compare.update_layout(yaxis_title=diff_metric, xaxis_title="", legend_title_text="", hovermode="x unified")
                    st.plotly_chart(fig_compare, use_container_width=True)

                    # ğŸ”¥ğŸ”¥ æ‰¾å›çš„åˆ—è¡¨ï¼šæ•°æ®é€è§†è¡¨ ğŸ”¥ğŸ”¥
                    with st.expander(f"ğŸ“‹ æŸ¥çœ‹ {metric_label} å…·ä½“å˜åŠ¨æ˜ç»†è¡¨", expanded=True):
                        df_pivot = df_viz.pivot(index=color_col, columns='Period', values=val_col).reset_index()
                        d1_str = d1_ts.strftime('%Y-%m-%d')
                        d2_str = d2_ts.strftime('%Y-%m-%d')
                        
                        df_pivot = df_pivot.fillna(0)
                        df_pivot['å˜åŠ¨é‡'] = df_pivot[d2_str] - df_pivot[d1_str]
                        df_pivot = df_pivot.sort_values(d2_str, ascending=False)
                        
                        # æ ¼å¼åŒ–é…ç½®
                        col_config = {
                            color_col: "åç§°",
                            d1_str: st.column_config.NumberColumn(f"{d1_str} (æ—§)", format="%.2f"),
                            d2_str: st.column_config.NumberColumn(f"{d2_str} (æ–°)", format="%.2f"),
                            "å˜åŠ¨é‡": st.column_config.NumberColumn("å·®å€¼ (æ–°-æ—§)", format="%.2f")
                        }
                        if unit_suffix == "%":
                            col_config[d1_str] = st.column_config.NumberColumn(f"{d1_str} (æ—§)", format="%.2f%%")
                            col_config[d2_str] = st.column_config.NumberColumn(f"{d2_str} (æ–°)", format="%.2f%%")
                            col_config["å˜åŠ¨é‡"] = st.column_config.NumberColumn("å·®å€¼", format="%.2f%%")

                        st.dataframe(df_pivot, column_config=col_config, hide_index=True, use_container_width=True)

    # --- Tab 3: æ¯æ—¥é€è§† (ä¿ç•™è€é€»è¾‘) ---
    with tab3:
        st.subheader("ğŸ° æ¯æ—¥èµ„äº§å¿«ç…§åˆ†æ")
        control_c1, control_c2 = st.columns(2)
        with control_c1:
            default_date = df_assets['date'].max().date()
            min_date = df_assets['date'].min().date()
            selected_date_input = st.date_input("ğŸ“… é€‰æ‹©è¦æŸ¥çœ‹çš„æ—¥æœŸ", value=default_date, min_value=min_date, max_value=default_date)
            selected_date = pd.Timestamp(selected_date_input)
        
        with control_c2:
            tag_groups = list(df_tags['tag_group'].unique()) if (df_tags is not None and not df_tags.empty) else []
            dim_options = ["æŒ‰å…·ä½“èµ„äº§"] + tag_groups
            selected_dim = st.selectbox("ğŸ” åˆ†æç»´åº¦ (ç­›é€‰æ ‡ç­¾ç»„)", dim_options)

        st.divider()

        if selected_dim == "æŒ‰å…·ä½“èµ„äº§":
            day_data = df_assets[df_assets['date'] == selected_date].copy()
            name_col = 'name'
        else:
            if df_tags is None: day_data = pd.DataFrame()
            else:
                day_data = df_tags[(df_tags['date'] == selected_date) & (df_tags['tag_group'] == selected_dim)].copy()
                name_col = 'tag_name'

        if day_data.empty:
            st.warning(f"ğŸ“… {selected_date_input} å½“å¤©æ²¡æœ‰å½•å…¥æ•°æ®ã€‚")
        else:
            day_data['amount_w'] = day_data['amount'] / 10000
            day_data['profit_w'] = day_data['profit'] / 10000
            
            day_total_amt = day_data['amount'].sum()
            day_total_profit = day_data['profit'].sum()
            total_cost = day_total_amt - day_total_profit
            
            m1, m2, m3 = st.columns(3)
            m1.metric("å½“æ—¥æ€»èµ„äº§", f"Â¥{day_total_amt/10000:,.2f}ä¸‡")
            m2.metric("å½“æ—¥æŒæœ‰æ”¶ç›Š", f"Â¥{day_total_profit/10000:,.2f}ä¸‡", delta_color="normal" if day_total_profit >= 0 else "inverse")
            m3.metric("å½“æ—¥ç»¼åˆæ”¶ç›Šç‡", f"{(day_total_profit/total_cost*100 if total_cost!=0 else 0):.2f}%")

            chart_c1, chart_c2 = st.columns(2)
            with chart_c1:
                fig_pie_amt = px.pie(day_data, values='amount', names=name_col, title=f"ã€æ€»é‡‘é¢ã€‘å æ¯” ({selected_dim})", hole=0.4, custom_data=['amount_w'])
                fig_pie_amt.update_traces(textposition='inside', textinfo='percent+label', hovertemplate='<b>%{label}</b>: ğŸ’°%{customdata[0]:.2f}ä¸‡ (ğŸ°%{percent})<extra></extra>')
                st.plotly_chart(fig_pie_amt, use_container_width=True)
            
            with chart_c2:
                if (day_data['profit'] > 0).any():
                    pos_profit_data = day_data[day_data['profit'] > 0]
                    fig_pie_prof = px.pie(pos_profit_data, values='profit', names=name_col, title=f"ã€æ­£æ”¶ç›Šã€‘è´¡çŒ®å æ¯” ({selected_dim})", hole=0.4, custom_data=['profit_w'])
                    fig_pie_prof.update_traces(textposition='inside', textinfo='percent+label', hovertemplate='<b>%{label}</b>: ğŸ“ˆ%{customdata[0]:.2f}ä¸‡ (ğŸ°%{percent})<extra></extra>')
                    st.plotly_chart(fig_pie_prof, use_container_width=True)
                else:
                    st.info("å½“æ—¥æ— æ­£æ”¶ç›Šèµ„äº§ï¼Œä¸å±•ç¤ºè´¡çŒ®å›¾ã€‚")

            st.dataframe(day_data[[name_col, 'amount', 'profit', 'yield_rate']].sort_values('amount', ascending=False), use_container_width=True, hide_index=True)

    conn.close()

def page_investment_plans():
    import pandas as pd
    import plotly.express as px
    st.header("ğŸ“… å®šæŠ•è®¡åˆ’ä¸æœªæ¥ç°é‡‘æµ")
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    tab1, tab2 = st.tabs(["âš™ï¸ è®¡åˆ’ç®¡ç†", "ğŸ”® æœªæ¥ç°é‡‘æµçœ‹æ¿"])

    # === å‡†å¤‡å·¥ä½œï¼šè·å–ç°é‡‘ç±»èµ„äº§åˆ—è¡¨ (ç”¨äºæ‰£æ¬¾æ¥æº) ===
    # åªæœ‰ã€ç°é‡‘ã€‘ç±»å‹çš„èµ„äº§æ‰èƒ½ä½œä¸ºæ‰£æ¬¾æ¥æº
    cash_assets = pd.read_sql(
        "SELECT asset_id, name FROM assets WHERE user_id = ? AND type = 'ç°é‡‘'", 
        conn, params=(user_id,)
    )
    # åˆ¶ä½œå­—å…¸æ–¹ä¾¿åç»­è½¬æ¢: Name -> ID
    cash_map_name_to_id = dict(zip(cash_assets['name'], cash_assets['asset_id']))
    # åˆ¶ä½œå­—å…¸: ID -> Name
    cash_map_id_to_name = dict(zip(cash_assets['asset_id'], cash_assets['name']))
    
    # ä¸‹æ‹‰æ¡†é€‰é¡¹ (åŠ ä¸€ä¸ªç©ºçš„é€‰é¡¹è¡¨ç¤ºä¸è‡ªåŠ¨æ‰£æ¬¾)
    source_options = ["(ä¸è‡ªåŠ¨æ‰£æ¬¾)"] + cash_assets['name'].tolist()

    # === TAB 1: è®¡åˆ’ç®¡ç† (CRUD) ===
    with tab1:
        st.caption("åœ¨è¿™é‡Œç®¡ç†ä½ çš„è‡ªåŠ¨å®šæŠ•è®¡åˆ’ã€‚")
        
        # 1. æ–°å¢è®¡åˆ’è¡¨å•
        with st.expander("â• æ–°å¢å®šæŠ•è®¡åˆ’", expanded=True):
            
            # --- A. å‡†å¤‡åŸºç¡€æ•°æ® ---
            all_assets = pd.read_sql('SELECT asset_id, name, code, currency FROM assets WHERE user_id = ?', conn, params=(user_id,))
            
            if all_assets.empty:
                st.warning("âš ï¸ è¯·å…ˆå»ã€èµ„äº§ä¸æ ‡ç­¾ç®¡ç†ã€‘é¡µé¢æ·»åŠ è‡³å°‘ä¸€ä¸ªèµ„äº§ã€‚")
            else:
                # --- B. ç­›é€‰å·¥å…·æ  ---
                st.markdown("##### ğŸ” ç¬¬ä¸€æ­¥ï¼šç­›é€‰ç›®æ ‡èµ„äº§")
                f_col1, f_col2, f_col3 = st.columns([2, 1, 2])
                with f_col1:
                    filter_kw = st.text_input("å…³é”®å­—æœç´¢", placeholder="åç§°/ä»£ç ...", key="plan_filter_kw")
                with f_col2:
                    all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
                    grp_list = ["(ä¸ç­›é€‰)"] + all_groups['tag_group'].tolist()
                    sel_group = st.selectbox("æ ‡ç­¾ç»„", grp_list, key="plan_filter_group")
                with f_col3:
                    sel_tags = []
                    if sel_group != "(ä¸ç­›é€‰)":
                        t_df = pd.read_sql("SELECT tag_name FROM tags WHERE user_id=? AND tag_group=?", conn, params=(user_id, sel_group))
                        opts = ["ã€æ— æ­¤æ ‡ç­¾ã€‘"] + t_df['tag_name'].tolist()
                        sel_tags = st.multiselect("æ ‡ç­¾çŠ¶æ€", opts, key="plan_filter_tags")

                # ç­›é€‰é€»è¾‘ (åŒåŸç‰ˆ)
                filtered_ids = set(all_assets['asset_id'].tolist())
                if filter_kw:
                    matched = all_assets[all_assets['name'].str.contains(filter_kw, case=False) | all_assets['code'].str.contains(filter_kw, case=False, na=False)]
                    filtered_ids = filtered_ids.intersection(set(matched['asset_id']))
                if sel_group != "(ä¸ç­›é€‰)" and sel_tags:
                    sql_labeled = '''
                        SELECT atm.asset_id, t.tag_name 
                        FROM asset_tag_map atm JOIN tags t ON atm.tag_id = t.tag_id 
                        WHERE t.user_id = ? AND t.tag_group = ?
                    '''
                    df_labeled = pd.read_sql(sql_labeled, conn, params=(user_id, sel_group))
                    target_group_ids = set()
                    if "ã€æ— æ­¤æ ‡ç­¾ã€‘" in sel_tags: target_group_ids.update(filtered_ids - set(df_labeled['asset_id']))
                    real_tags = [t for t in sel_tags if t != "ã€æ— æ­¤æ ‡ç­¾ã€‘"]
                    if real_tags: target_group_ids.update(set(df_labeled[df_labeled['tag_name'].isin(real_tags)]['asset_id']))
                    filtered_ids = filtered_ids.intersection(target_group_ids)
                
                final_assets = all_assets[all_assets['asset_id'].isin(filtered_ids)].copy()
                
                st.divider()
                st.markdown("##### ğŸ“ ç¬¬äºŒæ­¥ï¼šè®¾ç½®å®šæŠ•å‚æ•°")
                
                if final_assets.empty:
                    st.info("æ²¡æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„èµ„äº§ã€‚")
                else:
                    c1, c2 = st.columns(2)
                    with c1:
                        sel_asset = st.selectbox(
                            f"é€‰æ‹©å®šæŠ•ç›®æ ‡ (ç­›é€‰å‡º {len(final_assets)} ä¸ª)", 
                            options=final_assets['asset_id'], 
                            format_func=lambda x: f"{final_assets[final_assets['asset_id']==x]['name'].values[0]} ({final_assets[final_assets['asset_id']==x]['currency'].values[0]})",
                            key="plan_new_asset"
                        )
                        curr_symbol = final_assets[final_assets['asset_id']==sel_asset]['currency'].values[0]
                        amount = st.number_input(f"æ¯æ¬¡å®šæŠ•é‡‘é¢ (å•ä½: {curr_symbol})", min_value=0.0, step=100.0, key="plan_new_amount")
                    
                    with c2:
                        freq = st.selectbox("é¢‘ç‡", ["æ¯å‘¨", "æ¯æœˆ", "æ¯å¤©"], key="plan_new_freq")
                        exec_day = 0
                        if freq == "æ¯å‘¨":
                            weekdays = {0:"å‘¨ä¸€", 1:"å‘¨äºŒ", 2:"å‘¨ä¸‰", 3:"å‘¨å››", 4:"å‘¨äº”", 5:"å‘¨å…­", 6:"å‘¨æ—¥"}
                            exec_day = st.selectbox("é€‰æ‹©å‘¨å‡ ", options=list(weekdays.keys()), format_func=lambda x: weekdays[x], key="plan_new_day_week")
                        elif freq == "æ¯æœˆ":
                            exec_day = st.number_input("é€‰æ‹©æ¯æœˆå‡ å·", min_value=1, max_value=28, value=1, key="plan_new_day_month")

                    # ğŸ”¥ æ–°å¢ï¼šé€‰æ‹©æ‰£æ¬¾æ¥æº
                    st.write("")
                    st.markdown("##### ğŸ’³ èµ„é‡‘æ¥æºè®¾ç½®")
                    col_src, _ = st.columns([1, 1])
                    with col_src:
                        sel_source_name = st.selectbox(
                            "æ¯æ¬¡å®šæŠ•ä»å“ªä¸ªç°é‡‘è´¦æˆ·æ‰£æ¬¾?", 
                            options=source_options,
                            help="å¦‚æœé€‰æ‹©äº†ä¸€ä¸ªç°é‡‘è´¦æˆ·ï¼Œç³»ç»Ÿä¼šåœ¨æ¯æ¬¡å®šæŠ•æ—¥è‡ªåŠ¨å‡å°‘è¯¥è´¦æˆ·ä½™é¢ï¼Œå¹¶å¢åŠ ç›®æ ‡èµ„äº§æŒä»“ã€‚",
                            key="plan_new_source"
                        )
                        # è§£æ ID
                        sel_source_id = None
                        if sel_source_name != "(ä¸è‡ªåŠ¨æ‰£æ¬¾)":
                            sel_source_id = cash_map_name_to_id.get(sel_source_name)

                    st.write("") 
                    
                    if st.button("ğŸ’¾ ä¿å­˜å®šæŠ•è®¡åˆ’", type="primary", key="btn_save_plan"):
                        if amount <= 0:
                            st.error("å®šæŠ•é‡‘é¢å¿…é¡»å¤§äº 0")
                        else:
                            try:
                                conn.execute('''
                                    INSERT INTO investment_plans (user_id, asset_id, amount, frequency, execution_day, source_asset_id)
                                    VALUES (?, ?, ?, ?, ?, ?)
                                ''', (user_id, sel_asset, amount, freq, exec_day, sel_source_id))
                                conn.commit()
                                st.success(f"âœ… å·²æ·»åŠ å®šæŠ•è®¡åˆ’ï¼")
                                st.rerun()
                            except Exception as e:
                                st.error(f"ä¿å­˜å¤±è´¥: {e}")

        # 2. ç°æœ‰è®¡åˆ’åˆ—è¡¨
        st.subheader("ğŸ“‹ æ­£åœ¨è¿è¡Œçš„è®¡åˆ’")
        
        # ğŸ”¥ ä¿®æ”¹æŸ¥è¯¢ï¼šå¤šæŸ¥ source_asset_id
        plans_df = pd.read_sql('''
            SELECT p.plan_id, a.name, a.currency, p.amount, p.frequency, p.execution_day, p.is_active, p.source_asset_id
            FROM investment_plans p
            JOIN assets a ON p.asset_id = a.asset_id
            WHERE p.user_id = ?
        ''', conn, params=(user_id,))

        if not plans_df.empty:
            def format_freq(row):
                if row['frequency'] == 'æ¯å¤©': return "æ¯å¤©"
                if row['frequency'] == 'æ¯å‘¨': 
                    ws = ["å‘¨ä¸€","å‘¨äºŒ","å‘¨ä¸‰","å‘¨å››","å‘¨äº”","å‘¨å…­","å‘¨æ—¥"]
                    return f"æ¯å‘¨ {ws[int(row['execution_day'])]}"
                if row['frequency'] == 'æ¯æœˆ': return f"æ¯æœˆ {int(row['execution_day'])} å·"
                return ""

            plans_df['æè¿°'] = plans_df.apply(format_freq, axis=1)
            
            # ğŸ”¥ æ ¸å¿ƒè½¬æ¢ï¼šæŠŠ source_asset_id (æ•°å­—) è½¬æˆ source_name (æ–‡æœ¬) æ–¹ä¾¿ç¼–è¾‘
            # å¦‚æœ ID æ‰¾ä¸åˆ°(æ¯”å¦‚å·²åˆ é™¤)æˆ–ä¸ºç©ºï¼Œæ˜¾ç¤º "(ä¸è‡ªåŠ¨æ‰£æ¬¾)"
            plans_df['source_name'] = plans_df['source_asset_id'].map(cash_map_id_to_name).fillna("(ä¸è‡ªåŠ¨æ‰£æ¬¾)")

            edited_plans = st.data_editor(
                plans_df,
                column_config={
                    "plan_id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
                    "name": st.column_config.TextColumn("ç›®æ ‡èµ„äº§", disabled=True),
                    "currency": st.column_config.TextColumn("å¸ç§", disabled=True, width="small"),
                    "amount": st.column_config.NumberColumn("å®šæŠ•é‡‘é¢", format="%.2f"),
                    "frequency": st.column_config.TextColumn("é¢‘ç‡", disabled=True),
                    "source_name": st.column_config.SelectboxColumn(
                        "ğŸ’³ æ‰£æ¬¾æ¥æº", 
                        options=source_options,
                        width="medium",
                        required=True,
                        help="é€‰æ‹©å…³è”çš„ç°é‡‘è´¦æˆ·"
                    ),
                    "is_active": st.column_config.CheckboxColumn("å¯ç”¨"),
                    # éšè—ä¸æƒ³æ˜¾ç¤ºçš„åˆ—
                    "execution_day": None, 
                    "source_asset_id": None
                },
                hide_index=True,
                use_container_width=True,
                num_rows="dynamic",
                key="plans_editor"
            )
            
            if st.button("ğŸ’¾ ä¿å­˜è®¡åˆ’å˜æ›´"):
                # --- ä¿å­˜å‰çš„é€†å‘è½¬æ¢ ---
                # 1. æŠŠ source_name å˜å› source_asset_id
                # è¿™ä¸€æ­¥å¾ˆå…³é”®ï¼šç”¨æˆ·åœ¨è¡¨æ ¼é‡Œæ”¹çš„æ˜¯æ–‡å­—ï¼Œæˆ‘ä»¬å­˜å›æ•°æ®åº“è¦æ˜¯ ID
                def map_back_id(row):
                    val = row['source_name']
                    if val == "(ä¸è‡ªåŠ¨æ‰£æ¬¾)": return None
                    return cash_map_name_to_id.get(val, None) # æ‰¾ä¸åˆ°è¿”å› None

                edited_plans['source_asset_id'] = edited_plans.apply(map_back_id, axis=1)
                
                # 2. å‰”é™¤çº¯å±•ç¤ºç”¨çš„åˆ—
                # 'name', 'currency', 'æè¿°' æ˜¯å±•ç¤ºç”¨çš„
                # 'source_name' æ˜¯æˆ‘ä»¬åˆšæ‰è¾…åŠ©ç¼–è¾‘ç”¨çš„ï¼Œä¹Ÿè¦å‰”é™¤
                cols_to_drop = ['name', 'currency', 'æè¿°', 'source_name']
                
                df_to_save = edited_plans.drop(columns=[c for c in cols_to_drop if c in edited_plans.columns])
                
                # 3. æäº¤ä¿å­˜
                if save_changes_to_db(df_to_save, plans_df, 'investment_plans', 'plan_id', user_id, fixed_cols={'user_id':user_id}):
                    st.rerun()
        else:
            st.info("æš‚æ— å®šæŠ•è®¡åˆ’ã€‚")

    # === TAB 2: ç°é‡‘æµçœ‹æ¿ (ä¿æŒä¸å˜) ===
    with tab2:
        # 1. è®¡ç®—æœªæ¥ç°é‡‘æµé€»è¾‘
        st.subheader("ğŸ—“ï¸ æœªæ¥ 30 å¤©èµ„é‡‘éœ€æ±‚æ¨æ¼” (æŠ˜åˆäººæ°‘å¸)")
        
        # è·å–æœ€æ–°æ±‡ç‡è¡¨
        rates_map = get_latest_rates(conn)
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„è®¡åˆ’
        active_plans = pd.read_sql('''
            SELECT p.asset_id, a.name, a.currency, p.amount, p.frequency, p.execution_day
            FROM investment_plans p
            JOIN assets a ON p.asset_id = a.asset_id
            WHERE p.user_id = ? AND p.is_active = 1
        ''', conn, params=(user_id,))
        
        asset_tags = pd.read_sql('''
            SELECT atm.asset_id, t.tag_group, t.tag_name
            FROM asset_tag_map atm
            JOIN tags t ON atm.tag_id = t.tag_id
            WHERE t.user_id = ?
        ''', conn, params=(user_id,))

        if active_plans.empty:
            st.info("è¯·å…ˆå¯ç”¨è‡³å°‘ä¸€ä¸ªå®šæŠ•è®¡åˆ’ã€‚")
        else:
            from datetime import datetime, timedelta
            today = datetime.now().date()
            future_days = 30
            projection_data = []

            for i in range(future_days):
                current_date = today + timedelta(days=i)
                current_weekday = current_date.weekday()
                current_day = current_date.day
                
                for _, plan in active_plans.iterrows():
                    hit = False
                    if plan['frequency'] == 'æ¯å¤©': hit = True
                    elif plan['frequency'] == 'æ¯å‘¨' and int(plan['execution_day']) == current_weekday: hit = True
                    elif plan['frequency'] == 'æ¯æœˆ' and int(plan['execution_day']) == current_day: hit = True
                    
                    if hit:
                        raw_amt = plan['amount']
                        curr = plan['currency']
                        rate = 1.0 if curr == 'CNY' else rates_map.get(curr, 1.0)
                        cny_amt = raw_amt * rate
                        
                        projection_data.append({
                            "date": current_date,
                            "asset_id": plan['asset_id'],
                            "asset_name": plan['name'],
                            "amount_cny": cny_amt,
                            "raw_info": f"{raw_amt} {curr}"
                        })

            if not projection_data:
                st.warning("æœªæ¥30å¤©å†…æ²¡æœ‰åŒ¹é…çš„å®šæŠ•æ—¥ã€‚")
            else:
                df_proj = pd.DataFrame(projection_data)
                
                total_needed = df_proj['amount_cny'].sum()
                col1, col2 = st.columns(2)
                col1.metric("æœªæ¥ 30 å¤©æ€»å®šæŠ• (CNY)", f"Â¥{total_needed:,.2f}")
                col2.metric("å¹³å‡æ¯æ—¥æµå‡º (CNY)", f"Â¥{total_needed/30:,.2f}")

                st.divider()

                all_groups = asset_tags['tag_group'].unique().tolist() if not asset_tags.empty else []
                dim_options = ["æŒ‰å…·ä½“èµ„äº§"] + all_groups
                selected_dim = st.selectbox("é€‰æ‹©åˆ†æç»´åº¦ (å †å æ–¹å¼)", dim_options)
                
                df_viz = df_proj.copy()
                
                if selected_dim == "æŒ‰å…·ä½“èµ„äº§":
                    df_viz['category'] = df_viz['asset_name']
                else:
                    tags_in_group = asset_tags[asset_tags['tag_group'] == selected_dim]
                    df_viz = pd.merge(df_viz, tags_in_group, on='asset_id', how='left')
                    df_viz['tag_name'] = df_viz['tag_name'].fillna('æœªåˆ†ç±»')
                    df_viz['category'] = df_viz['tag_name']

                df_agg = df_viz.groupby(['date', 'category'])['amount_cny'].sum().reset_index()
                daily_totals = df_agg.groupby('date')['amount_cny'].transform('sum')
                df_agg['share'] = (df_agg['amount_cny'] / daily_totals) * 100

                fig = px.bar(
                    df_agg, 
                    x='date', 
                    y='amount_cny', 
                    color='category',
                    title=f"æœªæ¥ 30 å¤©æ¯æ—¥å®šæŠ•åˆ†å¸ƒ ({selected_dim}) - æŠ˜åˆäººæ°‘å¸",
                    labels={'amount_cny': 'é‡‘é¢ (CNY)', 'date': 'æ—¥æœŸ', 'category': 'ç±»åˆ«'},
                    custom_data=['share'] 
                )
                fig.update_traces(hovertemplate='<b>%{fullData.name}</b>: Â¥%{y:,.0f} (%{customdata[0]:.1f}%)<extra></extra>')
                fig.update_layout(hovermode="x unified", legend_title_text="")
                
                st.plotly_chart(fig, use_container_width=True)

    conn.close()

def page_rebalance():
    import pandas as pd            # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    import plotly.graph_objects as go  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("âš–ï¸ æŠ•èµ„ç»„åˆå†å¹³è¡¡åŠ©æ‰‹")
    st.caption("è®¾å®šä½ çš„ç†æƒ³èµ„äº§é…æ¯”ï¼Œç³»ç»Ÿå°†è®¡ç®—å¦‚ä½•è°ƒæ•´ä»“ä½ä»¥ç»´æŒé£é™©å¹³è¡¡ã€‚")
    
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    # --- 1. é€‰æ‹©è¦è¿›è¡Œå†å¹³è¡¡çš„ç»´åº¦ ---
    # é€šå¸¸æˆ‘ä»¬åªå¯¹å¤§çš„ç»´åº¦åšå†å¹³è¡¡ï¼Œæ¯”å¦‚ "èµ„äº§å¤§ç±»" (è‚¡/å€º/é‡‘) æˆ– "é£é™©ç­‰çº§"
    all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
    
    if all_groups.empty:
        st.warning("è¯·å…ˆå»è®¾ç½®æ ‡ç­¾ã€‚")
        conn.close()
        return

    col1, col2 = st.columns([1, 2])
    with col1:
        # é»˜è®¤å°è¯•é€‰ä¸­ "èµ„äº§å¤§ç±»" æˆ– "é£é™©ç­‰çº§"ï¼Œå¦‚æœæ²¡æœ‰å°±é€‰ç¬¬ä¸€ä¸ª
        default_idx = 0
        groups_list = all_groups['tag_group'].tolist()
        if "èµ„äº§å¤§ç±»" in groups_list: default_idx = groups_list.index("èµ„äº§å¤§ç±»")
        elif "é£é™©ç­‰çº§" in groups_list: default_idx = groups_list.index("é£é™©ç­‰çº§")
        
        selected_group = st.selectbox("é€‰æ‹©é…ç½®ç»´åº¦", groups_list, index=default_idx)

    # --- 2. è·å–å½“å‰æŒä»“æ•°æ® (Real) ---
    _, df_tags = get_cached_analytics_data(user_id)
    
    if df_tags is None or df_tags.empty:
        st.info("æš‚æ— èµ„äº§æ•°æ®ã€‚")
        conn.close()
        return

    # è¿‡æ»¤å‡ºå½“å‰ç»´åº¦çš„æœ€æ–°æ•°æ®
    latest_date = df_tags['date'].max()
    current_portfolio = df_tags[
        (df_tags['date'] == latest_date) & 
        (df_tags['tag_group'] == selected_group)
    ].copy()
    
    total_asset_val = current_portfolio['amount'].sum() # æ€»èµ„äº§ (CNY)

    # --- 3. è·å–/è®¾ç½®ç›®æ ‡é…ç½® (Target) ---
    # è¯»å–å·²ä¿å­˜çš„ç›®æ ‡
    saved_targets = pd.read_sql(
        "SELECT tag_name, target_percentage FROM rebalance_targets WHERE user_id = ? AND tag_group = ?",
        conn, params=(user_id, selected_group)
    )
    
    # æ„é€ ç¼–è¾‘è¡¨æ ¼æ•°æ®
    # æ‹¿åˆ°è¯¥ç»„ä¸‹æ‰€æœ‰çš„æ ‡ç­¾å
    all_tags_in_group = pd.read_sql(
        "SELECT tag_name FROM tags WHERE user_id = ? AND tag_group = ?", 
        conn, params=(user_id, selected_group)
    )
    
    # åˆå¹¶ï¼šæ ‡ç­¾å + ç°æœ‰ç›®æ ‡ + å½“å‰æŒä»“
    # è¿™æ ·å³ä½¿ç”¨æˆ·è¿˜æ²¡æŒæœ‰æŸä¸ªæ ‡ç­¾çš„èµ„äº§ï¼Œä¹Ÿèƒ½ç»™å®ƒè®¾ç›®æ ‡ï¼ˆå‡†å¤‡ä¹°å…¥ï¼‰
    df_editor = pd.merge(all_tags_in_group, saved_targets, on='tag_name', how='left')
    df_editor['target_percentage'] = df_editor['target_percentage'].fillna(0.0)
    
    # å…³è”å½“å‰å®é™…æŒä»“å æ¯”ï¼Œæ–¹ä¾¿å‚è€ƒ
    current_portfolio['actual_percentage'] = (current_portfolio['amount'] / total_asset_val * 100)
    df_editor = pd.merge(df_editor, current_portfolio[['tag_name', 'actual_percentage']], on='tag_name', how='left')
    df_editor['actual_percentage'] = df_editor['actual_percentage'].fillna(0.0)
    
    st.divider()
    
    c_edit, c_chart = st.columns([2, 3])
    
    with c_edit:
        st.subheader("ğŸ¯ è®¾å®šç›®æ ‡æ¯”ä¾‹")
        st.caption("è¯·ç›´æ¥åœ¨è¡¨æ ¼ä¸­ä¿®æ”¹ã€ç›®æ ‡å æ¯”ã€‘ï¼Œæ€»å’Œåº”ä¸º 100%ã€‚")
        
        edited_df = st.data_editor(
            df_editor[['tag_name', 'target_percentage', 'actual_percentage']],
            column_config={
                "tag_name": st.column_config.TextColumn("ç±»åˆ«", disabled=True),
                "target_percentage": st.column_config.NumberColumn("ç›®æ ‡å æ¯” (%)", min_value=0, max_value=100, step=1.0, required=True),
                "actual_percentage": st.column_config.NumberColumn("å½“å‰å æ¯” (%)", disabled=True, format="%.2f%%"),
            },
            hide_index=True,
            use_container_width=True,
            key=f"rebalance_editor_{selected_group}"
        )
        
        current_sum = edited_df['target_percentage'].sum()
        if abs(current_sum - 100) > 0.01:
            st.warning(f"âš ï¸ å½“å‰ç›®æ ‡æ€»å’Œä¸º {current_sum:.2f}%ï¼Œè¯·è°ƒæ•´è‡³ 100%ã€‚")
        else:
            if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary"):
                # ä¿å­˜é€»è¾‘
                try:
                    conn.execute("DELETE FROM rebalance_targets WHERE user_id = ? AND tag_group = ?", (user_id, selected_group))
                    for _, row in edited_df.iterrows():
                        if row['target_percentage'] > 0:
                            conn.execute(
                                "INSERT INTO rebalance_targets (user_id, tag_group, tag_name, target_percentage) VALUES (?, ?, ?, ?)",
                                (user_id, selected_group, row['tag_name'], row['target_percentage'])
                            )
                    conn.commit()
                    st.success("é…ç½®å·²ä¿å­˜ï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"ä¿å­˜å¤±è´¥: {e}")

    # --- 4. è®¡ç®—ä¸å±•ç¤ºå†å¹³è¡¡å»ºè®® ---
    if abs(current_sum - 100) <= 0.01:
        with c_chart:
            st.subheader("ğŸ“Š åå·®åˆ†æ")
            
            # å‡†å¤‡ç»˜å›¾æ•°æ®
            # æ¯”è¾ƒ Target vs Actual
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=edited_df['tag_name'],
                y=edited_df['actual_percentage'],
                name='å½“å‰å®é™…',
                marker_color='#95A5A6'
            ))
            fig.add_trace(go.Bar(
                x=edited_df['tag_name'],
                y=edited_df['target_percentage'],
                name='ç†æƒ³ç›®æ ‡',
                marker_color='#3498DB'
            ))
            fig.update_layout(barmode='group', title=f"å®é™… vs ç›®æ ‡ ({selected_group})", hovermode="x unified")
            st.plotly_chart(fig, use_container_width=True)

        st.divider()
        st.subheader("ğŸ’Š å†å¹³è¡¡æ“ä½œå»ºè®®")
        st.caption(f"åŸºäºå½“å‰æ€»èµ„äº§æŠ˜åˆäººæ°‘å¸ï¼šÂ¥{total_asset_val:,.2f}")

        # è®¡ç®—å…·ä½“ä¹°å–é‡‘é¢
        # é€»è¾‘ï¼šç†æƒ³é‡‘é¢ = æ€»èµ„äº§ * ç›®æ ‡% - å®é™…æŒæœ‰çš„é‡‘é¢
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾æ€»èµ„äº§ä¸å˜ï¼ˆå³é€šè¿‡å–å‡ºå¤šçš„ä¹°å…¥å°‘çš„ï¼Œæˆ–è€…ç”¨æ–°å¢èµ„é‡‘å»å¡«è¡¥ï¼‰
        
        # é‡æ–°mergeä¸€ä¸‹ç¡®ä¿æ•°æ®æœ€æ–°
        # éœ€è¦æŠŠ edited_df é‡Œçš„ target_percentage å’Œ current_portfolio é‡Œçš„ amount ç»“åˆ
        # current_portfolio å¯èƒ½ç¼ºæŸäº› tagï¼ˆå¦‚æœè¿˜æ²¡ä¹°ï¼‰ï¼Œæ‰€ä»¥è¦ä»¥ edited_df ä¸ºä¸»
        
        # æ„é€ ä¸€ä¸ªå®Œæ•´çš„è®¡ç®—è¡¨
        df_calc = pd.merge(
            edited_df[['tag_name', 'target_percentage']], 
            current_portfolio[['tag_name', 'amount']], 
            on='tag_name', 
            how='left'
        )
        df_calc['amount'] = df_calc['amount'].fillna(0.0)
        
        # æ ¸å¿ƒè®¡ç®—
        df_calc['target_amount'] = total_asset_val * (df_calc['target_percentage'] / 100.0)
        df_calc['diff_amount'] = df_calc['target_amount'] - df_calc['amount']
        
        # åˆ†ç±»å»ºè®®
        to_buy = df_calc[df_calc['diff_amount'] > 100].sort_values('diff_amount', ascending=False) # å¿½ç•¥å°é¢å™ªéŸ³
        to_sell = df_calc[df_calc['diff_amount'] < -100].sort_values('diff_amount', ascending=True)
        
        col_buy, col_sell = st.columns(2)
        
        with col_buy:
            if not to_buy.empty:
                st.success("ğŸ”µ å»ºè®®ä¹°å…¥ / åŠ ä»“")
                for _, row in to_buy.iterrows():
                    st.markdown(f"**{row['tag_name']}**: éœ€ä¹°å…¥ **Â¥{row['diff_amount']:,.0f}**")
                    st.progress(min(1.0, row['amount'] / row['target_amount']) if row['target_amount']>0 else 0)
            else:
                st.write("âœ… æ— éœ€ä¹°å…¥")

        with col_sell:
            if not to_sell.empty:
                st.error("ğŸ”´ å»ºè®®å–å‡º / å‡ä»“")
                for _, row in to_sell.iterrows():
                    sell_val = abs(row['diff_amount'])
                    st.markdown(f"**{row['tag_name']}**: éœ€å–å‡º **Â¥{sell_val:,.0f}**")
                    # è¿›åº¦æ¡å±•ç¤ºè¶…é…ç¨‹åº¦
                    over_ratio = (row['amount'] - row['target_amount']) / row['target_amount'] if row['target_amount']>0 else 1
                    st.progress(min(1.0, over_ratio))
            else:
                st.write("âœ… æ— éœ€å–å‡º")

    conn.close()

def page_investment_notes():
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("ğŸ“’ æŠ•èµ„ç¬”è®°ä¸å¤ç›˜")
    st.caption("è®°å½•æ¯ä¸€æ¬¡å†³ç­–çš„æ€è€ƒï¼Œæ„å»ºè‡ªå·±çš„æŠ•èµ„ä½“ç³»ã€‚")
    
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    # --- çŠ¶æ€ç®¡ç† ---
    # æˆ‘ä»¬åªéœ€è¦è®°å½•å½“å‰æ­£åœ¨ç¼–è¾‘å“ªä¸€ä¸ª note_id
    if 'editing_note_id' not in st.session_state:
        st.session_state.editing_note_id = None

    # --- A. é¡¶éƒ¨ï¼šä»…ç”¨äºæ–°å»ºç¬”è®° ---
    # ä½¿ç”¨ expander æ”¶çº³ï¼Œæ˜¾å¾—é¡µé¢æ›´å¹²å‡€ï¼Œæƒ³å†™çš„æ—¶å€™å†ç‚¹å¼€
    with st.expander("âœï¸ å†™ä¸€ç¯‡æ–°ç¬”è®°", expanded=False):
        new_title = st.text_input("æ ‡é¢˜", placeholder="ä¾‹å¦‚ï¼šç¾è‚¡å¤§è·Œï¼ŒåŠ ä»“æœºä¼šï¼Ÿ", key="new_note_title")
        new_content = st.text_area("æ­£æ–‡", height=100, placeholder="è®°å½•ä½ çš„åˆ†æã€æƒ…ç»ªå’Œæ“ä½œè®¡åˆ’...", key="new_note_content")
        
        if st.button("ğŸš€ å‘å¸ƒç¬”è®°", type="primary"):
            if not new_title.strip():
                st.warning("æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
            else:
                try:
                    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    conn.execute('''
                        INSERT INTO investment_notes (user_id, title, content, created_at, updated_at) 
                        VALUES (?, ?, ?, ?, ?)
                    ''', (user_id, new_title, new_content, timestamp, timestamp))
                    conn.commit()
                    st.success("å‘å¸ƒæˆåŠŸï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"å‘å¸ƒå¤±è´¥: {e}")

    st.divider()

    # --- B. æ—¶é—´è½´å±•ç¤ºåŒº (å«åŸåœ°ç¼–è¾‘é€»è¾‘) ---
    st.subheader("â³ ç¬”è®°æ—¶é—´è½´")
    
    notes = pd.read_sql('''
        SELECT note_id, title, content, created_at, updated_at 
        FROM investment_notes 
        WHERE user_id = ? 
        ORDER BY created_at DESC
    ''', conn, params=(user_id,))

    if notes.empty:
        st.info("è¿˜æ²¡æœ‰ç¬”è®°ï¼Œå¿«å»å†™ç¬¬ä¸€ç¯‡å§ï¼")
    else:
        for index, note in notes.iterrows():
            note_id = note['note_id']
            
            # ä½¿ç”¨ container æ¨¡æ‹Ÿå¡ç‰‡
            with st.container(border=True):
                
                # === åˆ¤æ–­ï¼šå½“å‰æ˜¯å¦å¤„äºç¼–è¾‘æ¨¡å¼ ===
                if st.session_state.editing_note_id == note_id:
                    # >>>>> ç¼–è¾‘æ¨¡å¼ç•Œé¢ >>>>>
                    st.markdown("##### ğŸ“ ç¼–è¾‘ä¸­...")
                    
                    # è¾“å…¥æ¡† (é»˜è®¤å€¼ä¸ºå½“å‰ç¬”è®°å†…å®¹)
                    edit_title = st.text_input("æ ‡é¢˜", value=note['title'], key=f"edit_title_{note_id}")
                    edit_content = st.text_area("æ­£æ–‡", value=note['content'], height=150, key=f"edit_content_{note_id}")
                    
                    col_save, col_cancel = st.columns([1, 5])
                    with col_save:
                        if st.button("ğŸ’¾ ä¿å­˜", type="primary", key=f"save_{note_id}"):
                            if not edit_title.strip():
                                st.warning("æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
                            else:
                                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                conn.execute('''
                                    UPDATE investment_notes 
                                    SET title = ?, content = ?, updated_at = ? 
                                    WHERE note_id = ?
                                ''', (edit_title, edit_content, timestamp, note_id))
                                conn.commit()
                                # é€€å‡ºç¼–è¾‘æ¨¡å¼
                                st.session_state.editing_note_id = None
                                st.rerun()
                    
                    with col_cancel:
                        if st.button("âŒ å–æ¶ˆ", key=f"cancel_{note_id}"):
                            # é€€å‡ºç¼–è¾‘æ¨¡å¼ï¼Œä¸ä¿å­˜
                            st.session_state.editing_note_id = None
                            st.rerun()
                    # <<<<< ç¼–è¾‘æ¨¡å¼ç»“æŸ <<<<<

                else:
                    # >>>>> æµè§ˆæ¨¡å¼ç•Œé¢ >>>>>
                    # 1. æ ‡é¢˜è¡Œ
                    col_title, col_time = st.columns([3, 1])
                    with col_title:
                        st.markdown(f"**{note['title']}**")
                    with col_time:
                        t_str = pd.to_datetime(note['created_at']).strftime('%Y-%m-%d %H:%M')
                        st.caption(f"ğŸ“… {t_str}")

                    # 2. æ­£æ–‡ (å·²ä¿®å¤æ¢è¡Œæ˜¾ç¤ºé—®é¢˜)
                    st.markdown(note['content'].replace('\n', '  \n'))
                    
                    # 3. åº•éƒ¨æ“ä½œæ 
                    st.divider()
                    f_c1, f_c2, f_c3 = st.columns([4, 1, 1])
                    
                    with f_c1:
                        # æ˜¾ç¤ºæœ€åä¿®æ”¹æ—¶é—´
                        if note['updated_at'] != note['created_at']:
                            up_str = pd.to_datetime(note['updated_at']).strftime('%Y-%m-%d %H:%M')
                            st.caption(f"ğŸ“ ä¿®æ”¹äº: {up_str}")
                    
                    with f_c2:
                        # ç‚¹å‡»ç¼–è¾‘ï¼Œæ›´æ–° stateï¼Œè§¦å‘ rerunï¼Œä¸‹ä¸€æ¬¡æ¸²æŸ“å°±ä¼šè¿›å…¥ä¸Šé¢çš„ if åˆ†æ”¯
                        if st.button("âœï¸ ç¼–è¾‘", key=f"btn_edit_{note_id}"):
                            st.session_state.editing_note_id = note_id
                            st.rerun()
                    
                    with f_c3:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"btn_del_{note_id}"):
                            conn.execute('DELETE FROM investment_notes WHERE note_id = ?', (note_id,))
                            conn.commit()
                            st.success("å·²åˆ é™¤")
                            st.rerun()
                    # <<<<< æµè§ˆæ¨¡å¼ç»“æŸ <<<<<
    
    conn.close()

def page_fire_projection():
    import pandas as pd            # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    import plotly.graph_objects as go  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("ğŸ”¥ FIRE è´¢å¯Œè‡ªç”±å±•æœ› 2.0")
    st.caption("å¼•å…¥é€šèƒ€è°ƒèŠ‚ä¸é£é™©åŒºé—´ï¼Œè¿˜åŸæœ€çœŸå®çš„è´¢å¯Œè‡ªç”±ä¹‹è·¯ã€‚")
    
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()
    
    # --- 1. è·å–å½“å‰æ€»èµ„äº§ (èµ·ç‚¹) ---
    rates_map = get_latest_rates(conn)
    latest_date_row = conn.execute('SELECT MAX(date) as d FROM snapshots JOIN assets ON snapshots.asset_id = assets.asset_id WHERE assets.user_id = ?', (user_id,)).fetchone()
    
    current_total_assets_cny = 0.0
    start_year = datetime.now().year
    
    if latest_date_row and latest_date_row['d']:
        latest_date = latest_date_row['d']
        rows = conn.execute('''
            SELECT s.amount, a.currency
            FROM snapshots s
            JOIN assets a ON s.asset_id = a.asset_id
            WHERE a.user_id = ? AND s.date = ?
        ''', (user_id, latest_date)).fetchall()
        
        for row in rows:
            amt = row['amount']
            curr = row['currency']
            rate = 1.0 if curr == 'CNY' else rates_map.get(curr, 1.0)
            current_total_assets_cny += amt * rate
            
    conn.close()

    # --- 2. å‚æ•°è®¾ç½®åŒºåŸŸ ---
    with st.expander("ğŸ› ï¸ æ ¸å¿ƒå‚æ•°è®¾å®š", expanded=True):
        c1, c2, c3 = st.columns(3)
        with c1:
            base_amount_wan = st.number_input("å½“å‰æ€»èµ„äº§ (ä¸‡ CNY)", value=float(current_total_assets_cny) / 10000.0, step=1.0, format="%.2f")
            base_amount = base_amount_wan * 10000
            
            annual_addition_wan = st.number_input("æ¯å¹´å®šæŠ•/è¿½åŠ  (ä¸‡)", value=20.0, step=1.0)
            annual_addition = annual_addition_wan * 10000

        with c2:
            current_age = st.number_input("å½“å‰å¹´é¾„", value=28, step=1)
            
            annual_rate = st.number_input("é¢„æœŸå¹´åŒ–æ”¶ç›Šç‡ (%)", value=8.0, step=0.5, help="é•¿æœŸæ¥çœ‹ï¼Œæ ‡æ™®500çº¦ 8-10%")
            
        with c3:
            inflation_rate = st.number_input("é¢„ä¼°é€šèƒ€ç‡ (%)", value=3.0, step=0.1)
            target_monthly_expense = st.number_input("ç†æƒ³æœˆç”Ÿæ´»è´¹ (å…ƒ)", value=10000, step=1000)

    st.divider()

    # --- 3. 4% æ³•åˆ™ä»ªè¡¨ç›˜ ---
    safe_withdrawal_rate = 0.04
    monthly_passive_income = (base_amount * safe_withdrawal_rate) / 12
    coverage_ratio = (monthly_passive_income / target_monthly_expense) * 100
    fire_number = (target_monthly_expense * 12) / safe_withdrawal_rate
    
    kpi1, kpi2, kpi3 = st.columns(3)
    with kpi1:
        st.metric("å½“å‰æ¯æœˆè¢«åŠ¨æ”¶å…¥ (4%)", f"Â¥{monthly_passive_income:,.0f}", help="æŒ‰4%æ³•åˆ™æå–çš„æœˆå®‰å…¨æ”¶å…¥")
    with kpi2:
        st.metric("ç”Ÿæ´»è´¹è¦†ç›–ç‡", f"{coverage_ratio:.1f}%", delta=f"å·® {100-coverage_ratio:.1f}%" if coverage_ratio < 100 else "å·²è¾¾æˆï¼", delta_color="normal" if coverage_ratio < 100 else "inverse")
        st.progress(min(1.0, coverage_ratio / 100))
    with kpi3:
        st.metric("FIRE ç›®æ ‡é‡‘é¢", f"Â¥{fire_number/10000:.0f}ä¸‡", delta=f"å½“å‰: {base_amount/10000:.0f}ä¸‡")

    st.divider()

    # --- 4. å¤åˆ©ä¸é£é™©æ¨æ¼”è®¡ç®— ---
    years_to_project = 40
    projection_data = []
    
    curr_bal = base_amount
    curr_principal = base_amount
    
    # åˆå§‹å¹´ä»½æ•°æ®
    projection_data.append({
        "year": start_year, "age": current_age,
        "balance": curr_bal, "balance_real": curr_bal,
        "principal": curr_principal
    })

    for i in range(1, years_to_project + 1):
        # æ ¸å¿ƒå¤åˆ©å…¬å¼
        curr_bal = curr_bal * (1 + annual_rate / 100.0) + annual_addition
        curr_principal += annual_addition
        
        # çœŸå®è´­ä¹°åŠ› (å‰”é™¤é€šèƒ€)
        real_purchasing_power = curr_bal / ((1 + inflation_rate / 100.0) ** i)
        
        projection_data.append({
            "year": start_year + i, "age": current_age + i,
            "balance": curr_bal, "balance_real": real_purchasing_power,
            "principal": curr_principal
        })

    df_proj = pd.DataFrame(projection_data)
    # å•ä½æ¢ç®—ä¸ºâ€œä¸‡â€
    cols_to_convert = ['balance', 'balance_real', 'principal']
    for c in cols_to_convert: df_proj[f'{c}_w'] = df_proj[c] / 10000

    # --- 5. ç»˜å›¾ (Plotly) ---
    st.subheader("ğŸ“ˆ èµ„äº§æ¨æ¼”ï¼šåä¹‰ vs çœŸå®")
    
    fig = go.Figure()

    # A. åä¹‰æ€»èµ„äº§
    fig.add_trace(go.Scatter(
        x=df_proj['age'], y=df_proj['balance_w'],
        mode='lines',
        name='åä¹‰é¢„æœŸ',
        line=dict(color='#2E86C1', width=3),
        customdata=df_proj['year'],
        hovertemplate='<b>âš–ï¸ åä¹‰é¢„æœŸ</b><br>å¹´ä»½: %{customdata}<br>èµ„äº§: <b>%{y:.0f}ä¸‡</b><extra></extra>'
    ))

    # B. çœŸå®è´­ä¹°åŠ›
    fig.add_trace(go.Scatter(
        x=df_proj['age'], y=df_proj['balance_real_w'],
        mode='lines',
        name='çœŸå®è´­ä¹°åŠ› (å‰”é™¤é€šèƒ€)',
        line=dict(color='#E74C3C', width=3, dash='dash'),
        customdata=df_proj['year'],
        hovertemplate='<b>ğŸ” çœŸå®è´­ä¹°åŠ›</b><br>å¹´ä»½: %{customdata}<br>æŠ˜åˆç°å€¼: <b>%{y:.0f}ä¸‡</b><extra></extra>'
    ))

    # C. æŠ•å…¥æœ¬é‡‘
    fig.add_trace(go.Scatter(
        x=df_proj['age'], y=df_proj['principal_w'],
        mode='lines',
        name='æŠ•å…¥æœ¬é‡‘',
        line=dict(color='#95A5A6', width=2, dash='dot'),
        customdata=df_proj['year'],
        hovertemplate='ğŸŒ± ç´¯è®¡æœ¬é‡‘: %{y:.0f}ä¸‡<extra></extra>'
    ))

    fig.update_layout(
        xaxis_title="å¹´é¾„", yaxis_title="é‡‘é¢ (ä¸‡)",
        hovermode="x unified",
        legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01),
        height=500
    )
    st.plotly_chart(fig, use_container_width=True)

    # --- 6. å…³é”®æ•°æ®è§£è¯» ---
    # æ‰¾20å¹´åçš„æ•°æ®
    target_year_20 = df_proj.iloc[20]

    st.info(f"""
    **ğŸ’¡ æ·±åº¦è§£è¯» (20å¹´å / {int(target_year_20['year'])}å¹´)ï¼š**
    
    * **è´¦é¢å¯Œè´µ**ï¼šæŒ‰ç…§é¢„æœŸï¼Œ20å¹´åä½ çš„è´¦æˆ·é‡Œä¼šæœ‰ **{target_year_20['balance_w']:.0f}ä¸‡**ã€‚
    * **çœŸå®ç¼©æ°´**ï¼šä½†åœ¨ {inflation_rate}% çš„é€šèƒ€ä¸‹ï¼Œè¿™ç¬”é’±çš„è´­ä¹°åŠ›åªç›¸å½“äºä»Šå¤©çš„ **{target_year_20['balance_real_w']:.0f}ä¸‡**ã€‚
    * **å¯¹æŠ—é€šèƒ€**ï¼šåªè¦ã€åä¹‰é¢„æœŸã€‘é‚£æ¡è“çº¿è·‘èµ¢äº†ã€çœŸå®è´­ä¹°åŠ›ã€‘çº¢è™šçº¿ï¼Œå°±è¯´æ˜ä½ çš„è´¢å¯Œåœ¨å¢å€¼ã€‚
    """, icon="ğŸ§")

    # --- 7. æ•°æ®è¡¨ ---
    with st.expander("æŸ¥çœ‹è¯¦ç»†æ¨æ¼”æ•°æ®"):
        st.dataframe(
            df_proj[['age', 'year', 'balance_w', 'balance_real_w', 'principal_w']],
            column_config={
                "age": "å¹´é¾„",
                "year": "å¹´ä»½",
                "balance_w": st.column_config.NumberColumn("åä¹‰èµ„äº§ (ä¸‡)", format="%.0f"),
                "balance_real_w": st.column_config.NumberColumn("çœŸå®è´­ä¹°åŠ› (ä¸‡)", format="%.0f"),
                "principal_w": st.column_config.NumberColumn("ç´¯è®¡æœ¬é‡‘ (ä¸‡)", format="%.0f"),
            },
            hide_index=True,
            use_container_width=True
        )
  
# --- å¤‡ä»½æ ¸å¿ƒé€»è¾‘ ---
def send_email_backup(filepath, settings):
    """å‘é€å¸¦æœ‰æ•°æ®åº“é™„ä»¶çš„é‚®ä»¶ (ä¿®å¤ SSL å…³é—­æŠ¥é”™ç‰ˆ)"""
    if not settings['email_host'] or not settings['email_user'] or not settings['email_password']:
        return False, "é‚®ç®±é…ç½®ä¸å®Œæ•´"

    try:
        msg = MIMEMultipart()
        msg['Subject'] = f'ã€è‡ªåŠ¨å¤‡ä»½ã€‘èµ„äº§æ•°æ®å¤‡ä»½ - {datetime.now().strftime("%Y-%m-%d")}'
        msg['From'] = settings['email_user']
        msg['To'] = settings['email_to'] if settings['email_to'] else settings['email_user']
        
        # æ­£æ–‡
        body = "è¿™æ˜¯æ‚¨çš„ä¸ªäººèµ„äº§ç®¡ç†ç³»ç»Ÿæ•°æ®åº“è‡ªåŠ¨å¤‡ä»½ï¼Œè¯·å¦¥å–„ä¿ç®¡ã€‚\n\n"
        body += f"å¤‡ä»½æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        msg.attach(MIMEText(body, 'plain'))

        # é™„ä»¶
        filename = os.path.basename(filepath)
        with open(filepath, "rb") as f:
            part = MIMEApplication(f.read(), Name=filename)
            part['Content-Disposition'] = f'attachment; filename="{filename}"'
            msg.attach(part)

        # --- æ ¸å¿ƒä¿®æ”¹å¼€å§‹ï¼šæ‰‹åŠ¨ç®¡ç†è¿æ¥ï¼Œå¿½ç•¥é€€å‡ºé”™è¯¯ ---
        server = smtplib.SMTP_SSL(settings['email_host'], settings['email_port'])
        try:
            server.login(settings['email_user'], settings['email_password'])
            server.send_message(msg)
            
            # é‚®ä»¶å·²å‘é€æˆåŠŸï¼Œå°è¯•ç¤¼è²Œé€€å‡ºï¼Œä½†å¦‚æœæŠ¥é”™åˆ™å¿½ç•¥
            try:
                server.quit()
            except Exception:
                pass  # å¿½ç•¥ (-1, b'\x00\x00\x00') è¿™ç§é€€å‡ºé”™è¯¯
            
            return True, "é‚®ä»¶å‘é€æˆåŠŸ"
            
        except Exception as e:
            # åªæœ‰å‘é€è¿‡ç¨‹ä¸­çš„é”™è¯¯æ‰æ˜¯çœŸæ­£çš„å¤±è´¥
            return False, f"å‘é€ä¸­æ–­: {str(e)}"
        finally:
            # ç¡®ä¿è¿æ¥å…³é—­
            try:
                server.close()
            except Exception:
                pass
        # --- æ ¸å¿ƒä¿®æ”¹ç»“æŸ ---

    except Exception as e:
        return False, f"é‚®ä»¶å‡†å¤‡å¤±è´¥: {str(e)}"

def page_ai_advisor():
    import pandas as pd
    from datetime import datetime, timedelta
    
    st.header("ğŸ¤– AI æ™ºèƒ½æŠ•é¡¾åŠ©ç†")
    st.caption("ç”ŸæˆåŒ…å«æ¯æ—¥å‡€å€¼ã€ç»“æ„å˜åŒ–ã€æ ¸å¿ƒæŒä»“çš„æ·±åº¦ Promptï¼Œå‘é€ç»™ ChatGPT/Claude è¿›è¡Œä¸“ä¸šè¯Šæ–­ã€‚")
    
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()
    
    # --- 1. è·å–æ‰€æœ‰æœ‰æ•°æ®çš„æ—¥æœŸ (ç”¨äºæ™ºèƒ½æ¨æ–­é»˜è®¤æ—¶é—´) ---
    # æˆ‘ä»¬æŸ¥ my_fund_history è¡¨ï¼Œå› ä¸ºè¿™æ˜¯ç”ŸæˆæŠ¥å‘Šçš„æ•°æ®æº
    df_dates = pd.read_sql('SELECT DISTINCT date FROM my_fund_history WHERE user_id = ? ORDER BY date', conn, params=(user_id,))
    
    if df_dates.empty:
        st.warning("âš ï¸ æš‚æ— åŸºé‡‘å‡€å€¼æ•°æ®ã€‚è¯·å…ˆå»ã€æ•°æ®å½•å…¥ã€‘é¡µä¿å­˜è‡³å°‘ä¸¤å¤©çš„å¿«ç…§ã€‚")
        conn.close()
        return

    # è½¬æ¢ä¸º date å¯¹è±¡åˆ—è¡¨
    valid_dates = pd.to_datetime(df_dates['date']).dt.date.tolist()
    latest_date = valid_dates[-1] # åˆ—è¡¨ä¸­æœ€åä¸€ä¸ªå°±æ˜¯æœ€è¿‘çš„æ—¥æœŸ
    
    # === ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ™ºèƒ½è®¡ç®—é»˜è®¤å¼€å§‹æ—¥æœŸ ===
    # ç›®æ ‡ï¼šæ‰¾ 7 å¤©å‰çš„é‚£ä¸ªæ—¥æœŸ
    target_date = latest_date - timedelta(days=7)
    
    default_start = target_date # å…ˆç»™ä¸ªåˆå§‹å€¼ï¼Œä¸‹é¢ä¿®æ­£
    
    # é€»è¾‘ï¼š
    # 1. å°è¯•æ‰¾ <= target_date çš„æ—¥æœŸä¸­ï¼Œç¦» target_date æœ€è¿‘çš„ä¸€ä¸ª (å¾€å‰æ‰¾)
    candidates_past = [d for d in valid_dates if d <= target_date]
    
    if candidates_past:
        # å¦‚æœæœ‰ï¼Œå–æœ€åä¸€ä¸ª (å³æœ€æ¥è¿‘ target_date çš„è¿‡å»æ—¥æœŸ)
        default_start = candidates_past[-1]
    else:
        # 2. å¦‚æœå¾€å‰æ‰¾ä¸åˆ° (è¯´æ˜ç”¨æˆ·å¯èƒ½æ‰ç”¨äº†ä¸åˆ°7å¤©)ï¼Œé‚£å°±å¾€åæ‰¾
        # æ‰¾ > target_date ä¸” < latest_date çš„æ—¥æœŸ
        candidates_future = [d for d in valid_dates if d > target_date and d < latest_date]
        
        if candidates_future:
            # å–ç¬¬ä¸€ä¸ª (å³æœ€æ¥è¿‘ target_date çš„æœªæ¥æ—¥æœŸ)
            default_start = candidates_future[0]
        else:
            # 3. å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ° (è¯´æ˜ä¸€å…±å°±åªæœ‰ latest_date è¿™ä¸€å¤©æ•°æ®ï¼Œæˆ–è€…æ•°æ®éå¸¸ç¨€ç–)
            if len(valid_dates) > 1:
                # è‡³å°‘å–æœ€æ—©çš„é‚£ä¸€å¤©
                default_start = valid_dates[0]
            else:
                # çœŸå°±åªæœ‰ä¸€å¤©æ•°æ®ï¼Œé‚£å°±æ²¡åŠæ³•äº†
                default_start = latest_date

    # ==========================================

    # 2. è®¾ç½®åŒºåŸŸ
    with st.container(border=True):
        st.subheader("ğŸ› ï¸ ç”Ÿæˆé…ç½®")
        
        c1, c2 = st.columns(2)
        
        with c1:
            date_range = st.date_input(
                "1. é€‰æ‹©å¤ç›˜æ—¶é—´æ®µ",
                value=(default_start, latest_date), # ä½¿ç”¨è®¡ç®—å‡ºçš„æ™ºèƒ½æ—¥æœŸ
                max_value=latest_date,
                help="é»˜è®¤é€‰ä¸­æœ€è¿‘ä¸€æ¬¡å¿«ç…§çš„ä¸€å‘¨å‰ï¼ˆè‡ªåŠ¨ä¿®æ­£ä¸ºæœ‰æ•ˆæ—¥æœŸï¼‰"
            )
        
        with c2:
            # è·å–æ‰€æœ‰æ ‡ç­¾ç»„
            all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
            group_opts = ["æŒ‰å…·ä½“èµ„äº§"] + all_groups['tag_group'].tolist()
            
            selected_dim = st.selectbox(
                "2. é€‰æ‹©ç»“æ„åˆ†æç»´åº¦", 
                group_opts,
                index=0,
                help="AI å°†å¯¹æ¯”æœŸåˆå’ŒæœŸæœ«ï¼Œè¯¥ç»´åº¦ä¸‹å„åˆ†ç±»çš„èµ„é‡‘å æ¯”å˜åŒ–ã€‚"
            )

        st.info("ğŸ’¡ **æç¤º**ï¼šç³»ç»Ÿå°†æå–é€‰ä¸­æ—¶é—´æ®µå†…çš„**æ¯æ—¥å‡€å€¼èµ°åŠ¿**ã€**æœŸåˆ/æœŸæœ«æŒä»“ç»“æ„å¯¹æ¯”**ä»¥åŠ**æœŸæœ«æ ¸å¿ƒæŒä»“æ˜ç»†**ï¼Œç»„åˆæˆä¸“ä¸šçš„ Prompt å‘é€åˆ°ä½ çš„é‚®ç®±ã€‚")
        
        if st.button("ğŸš€ ç”Ÿæˆå¹¶å‘é€ AI Prompt åˆ°é‚®ç®±", type="primary"):
            # æ ¡éªŒæ—¥æœŸ
            if isinstance(date_range, tuple) and len(date_range) == 2:
                start_d, end_d = date_range
                if start_d >= end_d:
                    st.error("å¼€å§‹æ—¥æœŸå¿…é¡»æ—©äºç»“æŸæ—¥æœŸã€‚")
                elif start_d not in valid_dates or end_d not in valid_dates:
                    # è™½ç„¶ date_input é™åˆ¶äº† max_valueï¼Œä½†ç”¨æˆ·é€‰ä¸­é—´ç©ºæ¡£æœŸå¯èƒ½ä¼šå¯¼è‡´æŸ¥è¯¢ä¸ºç©º
                    # è¿™é‡Œåšä¸€ä¸ªè½¯æé†’ï¼Œå…¶å® generate å‡½æ•°é‡Œä¹Ÿæœ‰åˆ¤ç©ºå¤„ç†
                    st.warning("æ³¨æ„ï¼šæ‰€é€‰æ—¥æœŸå¦‚æœæ²¡æœ‰å¯¹åº”çš„å¿«ç…§æ•°æ®ï¼ŒAI å¯èƒ½æ— æ³•åˆ†æå‡†ç¡®ã€‚")
                    with st.spinner("æ­£åœ¨æå–æ¯æ—¥æ•°æ®ã€è®¡ç®—ç»“æ„å˜åŒ–ã€ç»„è£… Prompt..."):
                        s_str = start_d.strftime('%Y-%m-%d')
                        e_str = end_d.strftime('%Y-%m-%d')
                        success, msg = generate_and_send_ai_prompt(user_id, s_str, e_str, selected_dim)
                        if success:
                            st.success(f"âœ… {msg}")
                            st.balloons()
                        else:
                            st.error(f"âŒ {msg}")
                else:
                    with st.spinner("æ­£åœ¨æå–æ¯æ—¥æ•°æ®ã€è®¡ç®—ç»“æ„å˜åŒ–ã€ç»„è£… Prompt..."):
                        s_str = start_d.strftime('%Y-%m-%d')
                        e_str = end_d.strftime('%Y-%m-%d')
                        success, msg = generate_and_send_ai_prompt(user_id, s_str, e_str, selected_dim)
                        if success:
                            st.success(f"âœ… {msg}")
                            st.balloons()
                        else:
                            st.error(f"âŒ {msg}")
            else:
                st.error("è¯·é€‰æ‹©å®Œæ•´çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸã€‚")

    conn.close()

def generate_and_send_ai_prompt(user_id, start_date_str, end_date_str, dimension_group):
    """
    ç”Ÿæˆ AI é¡¾é—®æç¤ºè¯ (ä¸“ä¸šç‰ˆï¼šåŒ…å«æ¯æ—¥å‡€å€¼CSV + ç»“æ„å¯¹æ¯” + æ ¸å¿ƒæŒä»“)
    :param dimension_group: "æŒ‰å…·ä½“èµ„äº§" æˆ– å…·ä½“çš„æ ‡ç­¾ç»„åç§° (å¦‚ "èµ„äº§å¤§ç±»")
    """
    import pandas as pd
    import smtplib
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    
    conn = get_db_connection()
    
    # --- 1. è·å–ç³»ç»Ÿé‚®ç®±è®¾ç½® ---
    settings = conn.execute('SELECT * FROM system_settings WHERE id = 1').fetchone()
    if not settings['email_host']:
        conn.close()
        return False, "æœªé…ç½®é‚®ç®± SMTPï¼Œæ— æ³•å‘é€ã€‚"

    try:
        # --- 2. å‡†å¤‡æ¯æ—¥è¶‹åŠ¿æ•°æ® (Daily Trend) ---
        # ç›´æ¥ä» fund_history å–ï¼Œå› ä¸ºé‚£é‡Œæœ‰è®¡ç®—å¥½çš„å‡€å€¼ (NAV)
        sql_trend = '''
            SELECT date, total_assets, accumulated_profit, unit_nav 
            FROM my_fund_history 
            WHERE user_id = ? AND date BETWEEN ? AND ?
            ORDER BY date ASC
        '''
        df_trend = pd.read_sql(sql_trend, conn, params=(user_id, start_date_str, end_date_str))
        
        if df_trend.empty:
            return False, f"è¯¥æ—¶é—´æ®µ ({start_date_str} ~ {end_date_str}) å†…æ²¡æœ‰ç”Ÿæˆè¿‡å‡€å€¼å†å²æ•°æ®ï¼Œè¯·å…ˆç¡®ä¿å·²è¿›è¡Œè¿‡æ•°æ®å½•å…¥å’Œé‡ç®—ã€‚"
        
        # å°†æ¯æ—¥æ•°æ®è½¬æ¢ä¸º CSV æ ¼å¼å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿ AI è¯»å–
        # ä¸ºäº†èŠ‚çœ tokenï¼Œä¿ç•™ 2 ä½å°æ•°
        csv_trend_str = df_trend.to_csv(index=False, float_format='%.4f')

        # --- 3. å‡†å¤‡æœŸåˆ vs æœŸæœ« ç»“æ„å¯¹æ¯” (Structure Comparison) ---
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„ç»´åº¦ (dimension_group) è·å–æ•°æ®
        # æˆ‘ä»¬åˆ©ç”¨ get_cached_analytics_data è·å–å¿«ç…§æ•°æ®
        df_assets_all, df_tags_all = get_cached_analytics_data(user_id)
        
        # ç­›é€‰æ—¥æœŸ
        start_date = pd.to_datetime(start_date_str)
        end_date = pd.to_datetime(end_date_str)
        
        target_df = pd.DataFrame()
        group_col = ""
        
        if dimension_group == "æŒ‰å…·ä½“èµ„äº§":
            # ä½¿ç”¨ df_assets_all
            mask = df_assets_all['date'].isin([start_date, end_date])
            target_df = df_assets_all[mask].copy()
            group_col = "name"
        else:
            # ä½¿ç”¨ df_tags_all
            mask = (df_tags_all['date'].isin([start_date, end_date])) & (df_tags_all['tag_group'] == dimension_group)
            target_df = df_tags_all[mask].copy()
            group_col = "tag_name"

        structure_str = ""
        if target_df.empty:
            structure_str = "(è¯¥ç»´åº¦ä¸‹æš‚æ— æ•°æ®)"
        else:
            # é€è§†è¡¨ï¼šIndex=åç§°, Column=æ—¥æœŸ, Value=é‡‘é¢
            pivot = target_df.pivot_table(index=group_col, columns='date', values='amount', aggfunc='sum').fillna(0)
            
            # ç¡®ä¿åˆ—åå­˜åœ¨ï¼ˆé˜²æ­¢æŸä¸€æœŸå®Œå…¨æ²¡æ•°æ®ï¼‰
            if start_date not in pivot.columns: pivot[start_date] = 0.0
            if end_date not in pivot.columns: pivot[end_date] = 0.0
            
            # è®¡ç®—æ€»é¢ç”¨äºç®—å æ¯”
            total_start = pivot[start_date].sum()
            total_end = pivot[end_date].sum()
            
            # æ ¼å¼åŒ–è¾“å‡º
            lines = []
            # æŒ‰æœŸæœ«é‡‘é¢é™åºæ’
            pivot = pivot.sort_values(by=end_date, ascending=False)
            
            lines.append(f"| {group_col} | æœŸåˆé‡‘é¢ | æœŸåˆå æ¯” | æœŸæœ«é‡‘é¢ | æœŸæœ«å æ¯” | å˜åŠ¨é¢ |")
            lines.append(f"|---|---|---|---|---|---|")
            
            for name, row in pivot.iterrows():
                s_amt = row[start_date]
                e_amt = row[end_date]
                # å¿½ç•¥å¤ªå°çš„æ‚é¡¹ï¼Œå‡å°‘ token
                if s_amt < 100 and e_amt < 100: continue
                
                s_pct = (s_amt / total_start * 100) if total_start > 0 else 0
                e_pct = (e_amt / total_end * 100) if total_end > 0 else 0
                diff = e_amt - s_amt
                
                lines.append(f"| {name} | {s_amt:.0f} | {s_pct:.1f}% | {e_amt:.0f} | {e_pct:.1f}% | {diff:+.0f} |")
            
            structure_str = "\n".join(lines)

        # --- 4. æ ¸å¿ƒæŒä»“åˆ†æ (>0.5%) ---
        # ä»…é’ˆå¯¹ Period End Date
        top_holdings_str = ""
        mask_end = df_assets_all['date'] == end_date
        if not mask_end.any():
            top_holdings_str = "(æœŸæœ«æ— èµ„äº§æ•°æ®)"
        else:
            df_end_assets = df_assets_all[mask_end].copy()
            total_end_val = df_end_assets['amount'].sum()
            
            # è®¡ç®—å æ¯”
            df_end_assets['ratio'] = df_end_assets['amount'] / total_end_val
            # ç­›é€‰ > 0.5%
            key_assets = df_end_assets[df_end_assets['ratio'] > 0.005].sort_values('amount', ascending=False)
            
            lines = []
            lines.append(f"å½“å‰æ€»èµ„äº§: {total_end_val:,.2f}")
            lines.append("å æ¯”è¶…è¿‡ 0.5% çš„æ ¸å¿ƒèµ„äº§åˆ—è¡¨ï¼š")
            for _, row in key_assets.iterrows():
                curr_txt = f"({row['currency']})" if row['currency'] != 'CNY' else ""
                profit_txt = f"æµ®ç›ˆ {row['profit']:,.0f}" if row['profit'] > 0 else f"æµ®äº {row['profit']:,.0f}"
                lines.append(f"- **{row['name']}**{curr_txt}: Â¥{row['amount']:,.0f} (å æ¯” {row['ratio']*100:.2f}%) | {profit_txt}")
            
            top_holdings_str = "\n".join(lines)

        # --- 5. ç»„è£… Prompt (Prompt Engineering) ---
        prompt_content = f"""
===== AI æŠ•èµ„é¡¾é—®æç¤ºè¯ (è¯·å¤åˆ¶ä»¥ä¸‹å†…å®¹å‘é€ç»™ ChatGPT/Claude) =====

# Role / è§’è‰²è®¾å®š
**ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 20 å¹´ç»éªŒçš„ä¸“ä¸šåŸºé‡‘æŠ•èµ„é¡¾é—® (CIO çº§åˆ«)ã€‚**
ä½ çš„ä¸“é•¿æ˜¯åŸºäºè¯¦å®çš„æ•°æ®ï¼Œå¯¹ä¸ªäººæŠ•èµ„è€…çš„æŠ•èµ„ç»„åˆè¿›è¡Œ**å½’å› åˆ†æ**ã€**é£é™©è¯„ä¼°**å’Œ**ç­–ç•¥å»ºè®®**ã€‚
ä½ å³å…³æ³¨å®è§‚å‘¨æœŸçš„å½±å“ï¼Œä¹Ÿå…³æ³¨å¾®è§‚æŒä»“çš„ç»“æ„å¥åº·åº¦ã€‚ä½ çš„åˆ†æé£æ ¼å®¢è§‚ã€ç†æ€§ï¼Œä¸”å–„äºå‘ç°æ•°æ®èƒŒåçš„éšæ‚£æˆ–æœºä¼šã€‚

# Context / åˆ†æèƒŒæ™¯
- **åˆ†æå‘¨æœŸ**: {start_date_str} è‡³ {end_date_str}
- **ç»Ÿè®¡ç»´åº¦**: {dimension_group}

# Data Section / æŠ•èµ„ç»„åˆæ•°æ®

## 1. æ¯æ—¥å‡€å€¼ä¸æ”¶ç›Šè¶‹åŠ¿ (Daily Trend CSV)
*æ•°æ®åˆ—è¯´æ˜: Date(æ—¥æœŸ), TotalAssets(æ€»èµ„äº§), AccumulatedProfit(ç´¯è®¡æŒæœ‰æ”¶ç›Š), UnitNav(å•ä½å‡€å€¼)*
```csv
{csv_trend_str}

```

## 2. ç»“æ„å˜åŒ–å¯¹æ¯” (Structure Change)

*ç»´åº¦: {dimension_group} | å¯¹æ¯”: æœŸåˆ vs æœŸæœ«*
{structure_str}

## 3. æœŸæœ«æ ¸å¿ƒæŒä»“ (Key Holdings > 0.5%)

{top_holdings_str}

---

# Action Required / ä½ çš„ä»»åŠ¡

è¯·åŸºäºä¸Šè¿°æ•°æ®ï¼Œä¸ºæˆ‘ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„**ã€ŠæŠ•èµ„ç»„åˆå¤ç›˜æŠ¥å‘Šã€‹**ã€‚è¯·åŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼š

### ç¬¬ä¸€éƒ¨åˆ†ï¼šå‘¨æœŸè¡¨ç°ç»¼è¿°

1. **æ”¶ç›Šå½’å› **ï¼šç»“åˆ Daily Trend æ•°æ®ï¼Œåˆ†æè¿™æ®µæ—¶é—´å‡€å€¼æ³¢åŠ¨çš„ä¸»è¦åŸå› ã€‚æ˜¯åœ¨å“ªå‡ å¤©å‘ç”Ÿäº†å¤§å¹…å›æ’¤æˆ–ä¸Šæ¶¨ï¼Ÿè¿™å¯èƒ½ä¸å½“æ—¶çš„ä»€ä¹ˆå¸‚åœºå¤§äº‹ä»¶æœ‰å…³ï¼Ÿï¼ˆè¯·ç»“åˆä½ çš„äº’è”ç½‘çŸ¥è¯†æ£€ç´¢è¯¥æ—¶é—´æ®µçš„å¸‚åœºæ–°é—»ï¼‰
2. **é£é™©æŒ‡æ ‡**ï¼šåŸºäºå‡€å€¼æ•°æ®ï¼Œä¼°ç®—è¿™æ®µæ—¶é—´çš„æœ€å¤§å›æ’¤ (Max Drawdown) å’Œæ³¢åŠ¨æƒ…å†µã€‚

### ç¬¬äºŒéƒ¨åˆ†ï¼šç»“æ„ä¸ä»“ä½åˆ†æ

1. **è°ƒä»“è¯„ä»·**ï¼šåŸºäº Structure Change è¡¨æ ¼ï¼Œåˆ†ææˆ‘åœ¨è¿™æ®µæ—¶é—´çš„ä¸»è¦èµ„é‡‘æµå‘ã€‚æˆ‘åŠ ä»“äº†ä»€ä¹ˆï¼Ÿå‡ä»“äº†ä»€ä¹ˆï¼Ÿè¿™ç§ç»“æ„è°ƒæ•´æ˜¯å¦è®©ç»„åˆå˜å¾—æ›´æŠ—è·Œæˆ–æ›´æ¿€è¿›ï¼Ÿ
2. **æŒä»“é›†ä¸­åº¦**ï¼šåŸºäº Key Holdings åˆ—è¡¨ï¼Œç‚¹è¯„æˆ‘çš„æŒä»“é›†ä¸­åº¦é£é™©ã€‚æ˜¯å¦å­˜åœ¨å•ä¸€èµ„äº§å æ¯”è¿‡é«˜çš„é—®é¢˜ï¼Ÿ

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šæœªæ¥å»ºè®®

1. åŸºäºå½“å‰çš„å®è§‚ç¯å¢ƒå’Œæˆ‘çš„æŒä»“ç»“æ„ï¼Œç»™å‡º 1-3 æ¡å…·ä½“çš„è°ƒæ•´å»ºè®®ï¼ˆå¦‚ï¼šæ˜¯å¦éœ€è¦å¢åŠ å€ºåˆ¸å¯¹å†²ï¼Ÿæ˜¯å¦éœ€è¦æ­¢ç›ˆæŸç±»èµ„äº§ï¼Ÿï¼‰ã€‚

================================
"""
        # --- 6. å‘é€é‚®ä»¶ ---
        msg = MIMEMultipart()
        msg['Subject'] = f'ğŸ¤– AI æ·±åº¦æŠ•é¡¾ Prompt ({start_date_str} ~ {end_date_str})'
        msg['From'] = settings['email_user']
        msg['To'] = settings['email_to'] if settings['email_to'] else settings['email_user']
        
        body = "è¿™æ˜¯ä¸ºæ‚¨ç”Ÿæˆçš„ AI æŠ•é¡¾æç¤ºè¯ï¼ŒåŒ…å«äº†æ¯æ—¥å‡€å€¼æ•°æ®å’Œè¯¦ç»†æŒä»“ç»“æ„ã€‚\nè¯·å°†ä¸‹æ–¹å†…å®¹å®Œæ•´å¤åˆ¶ç»™ AI æ¨¡å‹ã€‚\n\n" + prompt_content
        msg.attach(MIMEText(body, 'plain'))

        server = smtplib.SMTP_SSL(settings['email_host'], settings['email_port'])
        server.login(settings['email_user'], settings['email_password'])
        server.send_message(msg)
        server.quit()
        
        return True, "Prompt å·²å‘é€è‡³é‚®ç®±ï¼"

    except Exception as e:
        import traceback
        traceback.print_exc()
        return False, f"ç”Ÿæˆå¤±è´¥: {str(e)}"
    finally:
        conn.close()

def perform_backup(manual=False):
    """æ‰§è¡Œå¤‡ä»½ï¼š1.æœ¬åœ°å¤åˆ¶ 2.å‘é€é‚®ä»¶ 3.æ›´æ–°æ—¶é—´"""
    conn = get_db_connection()
    settings = conn.execute('SELECT * FROM system_settings WHERE id = 1').fetchone()
    
    # 1. å‡†å¤‡ç›®å½•
    backup_dir = "backups"
    if not os.path.exists(backup_dir):
        os.makedirs(backup_dir)
        
    # 2. ç”Ÿæˆæœ¬åœ°å¤‡ä»½æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"asset_tracker_{timestamp}.db"
    backup_path = os.path.join(backup_dir, filename)
    
    try:
        # ä¸ºäº†é˜²æ­¢å¤åˆ¶æ—¶æ•°æ®åº“æ­£åœ¨å†™å…¥ï¼Œè™½ç„¶ sqlite å…è®¸è¯»æ—¶å¤åˆ¶ï¼Œä½†ç¨³å¦¥èµ·è§æˆ‘ä»¬ç”¨ connection çš„ backup API æˆ–è€…ç®€å• copy
        # ç®€å• copy å¯¹äºå•ç”¨æˆ·ç³»ç»Ÿé€šå¸¸è¶³å¤Ÿ
        shutil.copy2(DB_FILE, backup_path)
        
        log_msg = f"æœ¬åœ°å¤‡ä»½å·²ä¿å­˜: {filename}"
        email_status = "æœªé…ç½®é‚®ä»¶"
        
        # 3. å‘é€é‚®ä»¶
        if settings['email_host']:
            success, msg = send_email_backup(backup_path, settings)
            email_status = "é‚®ä»¶å·²å‘é€" if success else f"é‚®ä»¶å¤±è´¥: {msg}"
        
        # 4. æ›´æ–°ä¸Šæ¬¡å¤‡ä»½æ—¶é—´
        now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        conn.execute('UPDATE system_settings SET last_backup_at = ? WHERE id = 1', (now_str,))
        conn.commit()
        
        conn.close()
        return True, f"{log_msg} | {email_status}"
    
    except Exception as e:
        conn.close()
        return False, f"å¤‡ä»½å‡ºé”™: {e}"

def auto_backup_check():
    """åœ¨ App å¯åŠ¨/è¿è¡Œæ—¶è¢«åŠ¨æ£€æŸ¥æ˜¯å¦éœ€è¦å¤‡ä»½"""
    conn = get_db_connection()
    try:
        row = conn.execute('SELECT backup_frequency, last_backup_at FROM system_settings WHERE id = 1').fetchone()
        if not row: return

        freq = row['backup_frequency']
        last_at = row['last_backup_at']
        
        if freq == 'å…³é—­':
            return
            
        should_backup = False
        now = datetime.now()
        
        if not last_at:
            should_backup = True
        else:
            last_date = datetime.strptime(last_at, '%Y-%m-%d %H:%M:%S')
            delta = now - last_date
            
            if freq == 'æ¯å¤©' and delta.days >= 1:
                should_backup = True
            elif freq == 'æ¯å‘¨' and delta.days >= 7:
                should_backup = True
            elif freq == 'æ¯æœˆ' and delta.days >= 30:
                should_backup = True
        
        if should_backup:
            # æ‰§è¡Œå¤‡ä»½ (ä¸é˜»å¡ UI å¤ªä¹…ï¼Œä½¿ç”¨ toast æç¤º)
            st.toast("æ­£åœ¨åå°æ‰§è¡Œè‡ªåŠ¨å¤‡ä»½...", icon="â³")
            success, msg = perform_backup(manual=False)
            if success:
                st.toast(f"è‡ªåŠ¨å¤‡ä»½å®Œæˆï¼\n{msg}", icon="âœ…")
            else:
                st.error(f"è‡ªåŠ¨å¤‡ä»½å¤±è´¥: {msg}")
                
    except Exception as e:
        print(f"Auto backup check failed: {e}")
    finally:
        conn.close()

def page_settings():
    import pandas as pd
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®ä¸ç®¡ç†")
    conn = get_db_connection()
    
    # è¯»å–å½“å‰é…ç½®
    settings = conn.execute('SELECT * FROM system_settings WHERE id = 1').fetchone()
    
    tab1, tab2, tab3 = st.tabs(["ğŸ”„ å¤‡ä»½ç­–ç•¥ä¸é‚®ç®±", "ğŸ“‚ æœ¬åœ°å¤‡ä»½ç®¡ç†", "ğŸ‘¥ æˆå‘˜ç®¡ç†(å±é™©)"])
    
    # === Tab 1: ç­–ç•¥é…ç½® (ä¿æŒä¸å˜) ===
    with tab1:
        st.subheader("1. è‡ªåŠ¨å¤‡ä»½ç­–ç•¥")
        with st.form("settings_form"):
            new_freq = st.radio("å¤‡ä»½é¢‘ç‡", ["å…³é—­", "æ¯å¤©", "æ¯å‘¨", "æ¯æœˆ"], 
                              index=["å…³é—­", "æ¯å¤©", "æ¯å‘¨", "æ¯æœˆ"].index(settings['backup_frequency']),
                              horizontal=True)
            st.divider()
            st.subheader("2. é‚®ç®±æ¨é€è®¾ç½®")
            c1, c2 = st.columns(2)
            with c1:
                email_host = st.text_input("SMTP æœåŠ¡å™¨", value=settings['email_host'] or "")
                email_port = st.number_input("SMTP ç«¯å£", value=settings['email_port'] or 465)
            with c2:
                email_user = st.text_input("é‚®ç®±è´¦å·", value=settings['email_user'] or "")
                email_password = st.text_input("æˆæƒç /å¯†ç ", value=settings['email_password'] or "", type="password")
            email_to = st.text_input("æ¥æ”¶é‚®ç®±", value=settings['email_to'] or "")
            if st.form_submit_button("ğŸ’¾ ä¿å­˜é…ç½®"):
                conn.execute('''UPDATE system_settings SET backup_frequency=?, email_host=?, email_port=?, email_user=?, email_password=?, email_to=? WHERE id=1''', (new_freq, email_host, email_port, email_user, email_password, email_to))
                conn.commit()
                st.success("é…ç½®å·²ä¿å­˜ï¼")
                st.rerun()

    # === Tab 2: æœ¬åœ°ç®¡ç† (ä¿æŒä¸å˜) ===
    with tab2:
        st.subheader("ğŸ“‚ æœ¬åœ°å¤‡ä»½æ–‡ä»¶ç®¡ç†")
        if st.button("ğŸš€ ç«‹å³æ‰‹åŠ¨å¤‡ä»½"):
            success, msg = perform_backup(manual=True)
            if success: st.success(msg); st.rerun()
            else: st.error(msg)
        # ... (æ­¤å¤„çœç•¥éƒ¨åˆ†å±•ç¤ºä»£ç ï¼Œå‡è®¾ä½ å·²ç»æœ‰äº†) ...

    # === Tab 3: æˆå‘˜ç®¡ç† (ä¿®å¤ç‰ˆ) ===
    with tab3:
        st.subheader("ğŸ’€ å±é™©åŒºåŸŸï¼šåˆ é™¤æˆå‘˜")
        st.warning("æ³¨æ„ï¼šæ­¤æ“ä½œä¸å¯é€†ï¼å°†åˆ é™¤è¯¥æˆå‘˜åä¸‹çš„æ‰€æœ‰èµ„äº§ã€è®°å½•å’Œç¬”è®°ã€‚")
        
        # 1. è·å–æ‰€æœ‰ç”¨æˆ·
        all_users = conn.execute('SELECT user_id, username FROM users').fetchall()
        user_options = {u['username']: u['user_id'] for u in all_users}
        
        if not user_options:
            st.info("æš‚æ— ç”¨æˆ·ã€‚")
        else:
            # 2. é€‰æ‹©ç”¨æˆ·
            # æ³¨æ„ï¼šåŠ ä¸Š keyï¼Œé˜²æ­¢åˆ‡æ¢ tab æ—¶çŠ¶æ€ä¸¢å¤±
            target_username = st.selectbox(
                "é€‰æ‹©è¦ç§»é™¤çš„æˆå‘˜", 
                options=list(user_options.keys()),
                key="sel_user_to_del_fixed"
            )
            
            # --- æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨ checkbox è€Œä¸æ˜¯åµŒå¥— button ---
            # Checkbox æœ‰çŠ¶æ€ï¼Œå‹¾é€‰åä¸€ç›´ä¿æŒ Trueï¼Œç›´åˆ°ä½ å–æ¶ˆå‹¾é€‰
            confirm_mode = st.checkbox(f"ğŸ”“ è§£é”åˆ é™¤æŒ‰é’® (ç›®æ ‡: {target_username})", key="del_unlock_checkbox")
            
            if confirm_mode:
                st.error(f"âš ï¸ ä¸¥é‡è­¦å‘Šï¼šä½ ç¡®å®šè¦å½»åº•åˆ é™¤ ã€{target_username}ã€‘ å—ï¼Ÿ")
                st.write("è¯¥æ“ä½œä¼šè¿å¸¦åˆ é™¤ï¼šèµ„äº§è®°å½•ã€å®šæŠ•è®¡åˆ’ã€æ‰€æœ‰ç¬”è®°ã€‚æ•°æ®æ— æ³•æ¢å¤ï¼")
                
                # çœŸæ­£çš„æ‰§è¡ŒæŒ‰é’®
                if st.button("ğŸ§¨ ç¡®è®¤åˆ é™¤", type="primary", key="btn_real_delete"):
                    target_id = user_options[target_username]
                    
                    # æ‰§è¡Œåˆ é™¤
                    success, msg = delete_user_fully(target_id)
                    
                    if success:
                        st.toast(f"æˆå‘˜ {target_username} å·²è¢«ç§»é™¤ã€‚", icon="âœ…")
                        
                        # å¦‚æœåˆ çš„æ˜¯å½“å‰ç™»å½•çš„äººï¼Œæ¸…ç©º session
                        if 'user' in st.session_state and st.session_state.user and st.session_state.user['username'] == target_username:
                            st.session_state.user = None
                        
                        # ç¨å¾®ç­‰ä¸€ä¸‹è®© toast æ˜¾ç¤ºå®Œï¼Œç„¶åå¼ºåˆ¶åˆ·æ–°é¡µé¢
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error(msg)

    conn.close()

# ==============================================================================
# ğŸš€ ä¸»ç¨‹åºå…¥å£ (Main) - åŠ¨æ€è¯»å–ç”¨æˆ·ç‰ˆ
# ==============================================================================
def main():
    # 1. åŸºç¡€åˆå§‹åŒ–
    init_db()
    auto_backup_check()

    # --- æ”¹é€ æ ¸å¿ƒï¼šä¾§è¾¹æ ç”¨æˆ·åˆ‡æ¢å™¨ ---
    with st.sidebar:
        st.header("ä¸ªäººèµ„äº§ç®¡ç†ç³»ç»Ÿ")
        
        # 1. åŠ¨æ€è·å–æ•°æ®åº“é‡Œçš„æ‰€æœ‰ç”¨æˆ·
        existing_users = get_all_usernames()
        
        # 2. æ„é€ ä¸‹æ‹‰èœå•é€‰é¡¹ï¼šç°æœ‰ç”¨æˆ· + æ–°å¢é€‰é¡¹
        # å³ä½¿æ•°æ®åº“æ˜¯ç©ºçš„ï¼Œè‡³å°‘ä¼šæœ‰ä¸€ä¸ªâ€œæ–°å¢æˆå‘˜â€çš„é€‰é¡¹
        menu_options = existing_users + ["â• æ–°å¢æˆå‘˜..."]
        
        # 3. ç¡®å®šä¸‹æ‹‰æ¡†çš„é»˜è®¤é€‰ä¸­é¡¹
        # å¦‚æœå½“å‰ session é‡Œå·²ç»ç™»å½•äº†ç”¨æˆ·ï¼Œä¸”è¯¥ç”¨æˆ·åœ¨åˆ—è¡¨é‡Œï¼Œå°±é»˜è®¤é€‰ä¸­ä»–
        # å¦åˆ™é»˜è®¤é€‰åˆ—è¡¨ç¬¬ä¸€ä¸ª
        default_index = 0
        if 'user' in st.session_state and st.session_state.user:
            current_name = st.session_state.user['username']
            if current_name in existing_users:
                default_index = existing_users.index(current_name)
        
        # 4. æ˜¾ç¤ºä¸‹æ‹‰æ¡†
        selected_option = st.selectbox(
            "å½“å‰æˆå‘˜", 
            menu_options, 
            index=default_index,
            key="user_selector_dynamic"
        )

        # 5. åˆ†æ”¯é€»è¾‘ï¼šæ˜¯åˆ‡æ¢è€ç”¨æˆ·ï¼Œè¿˜æ˜¯åˆ›å»ºæ–°ç”¨æˆ·ï¼Ÿ
        if selected_option == "â• æ–°å¢æˆå‘˜...":
            st.info("ğŸ‘‹ æ¬¢è¿æ–°æˆå‘˜åŠ å…¥ï¼")
            new_username = st.text_input("è¯·è¾“å…¥ä½ çš„æ˜µç§°/åå­—", placeholder="ä¾‹å¦‚ï¼šå¥¶å¥¶")
            
            if st.button("ç¡®è®¤åˆ›å»ºå¹¶è¿›å…¥", type="primary"):
                if new_username.strip():
                    if new_username in existing_users:
                        st.error("è¿™ä¸ªåå­—å·²ç»å­˜åœ¨å•¦ï¼Œç›´æ¥åœ¨ä¸‹æ‹‰æ¡†é€‰å°±è¡Œã€‚")
                    else:
                        # è°ƒç”¨ä¹‹å‰çš„ get_or_create å‡½æ•°åˆ›å»ºæ–°ç”¨æˆ·
                        new_user = get_or_create_user_by_name(new_username)
                        st.session_state.user = new_user
                        st.success(f"æ¬¢è¿ {new_username}ï¼")
                        st.rerun() # åˆ·æ–°é¡µé¢ï¼Œè®©æ–°åå­—å‡ºç°åœ¨ä¸‹æ‹‰æ¡†é‡Œ
                else:
                    st.warning("åå­—ä¸èƒ½ä¸ºç©ºå“¦")
            
            # å¦‚æœæ­£åœ¨åˆ›å»ºæ–°ç”¨æˆ·ï¼Œå°±ä¸è¦æ˜¾ç¤ºä¸‹é¢çš„å¯¼èˆªæ äº†ï¼Œå¼ºåˆ¶æš‚åœ
            st.stop()
            
        else:
            # === é€‰ä¸­äº†ç°æœ‰ç”¨æˆ· ===
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢ session
            # å¦‚æœå½“å‰æ²¡ç™»å½•ï¼Œæˆ–è€…ç™»å½•çš„äººè·Ÿé€‰çš„äººä¸ä¸€æ ·ï¼Œå°±åˆ‡æ¢
            if 'user' not in st.session_state or st.session_state.user is None or st.session_state.user['username'] != selected_option:
                user_obj = get_or_create_user_by_name(selected_option) # è¿™é‡Œå…¶å®åªèµ·åˆ° get çš„ä½œç”¨
                st.session_state.user = user_obj
                st.toast(f"å·²åˆ‡æ¢åˆ°è´¦æˆ·: {selected_option}", icon="ğŸ‘‹")
                st.rerun()

        st.divider()

        # === ä»¥ä¸‹æ˜¯åŸæœ¬çš„å¯¼èˆªé€»è¾‘ (ä¿æŒä¸å˜) ===
        # åªæœ‰åœ¨é€‰ä¸­äº†æœ‰æ•ˆç”¨æˆ·åï¼Œæ‰ä¼šæ‰§è¡Œåˆ°è¿™é‡Œ
        
        # A. ç”¨æˆ·ä¿¡æ¯åŒº
        st.caption(f"æ­£åœ¨ç®¡ç† {st.session_state.user['username']} çš„èµ„äº§")
        
        # B. å¯¼èˆªèœå•
        nav_map = {
            "ğŸ“Š èµ„äº§çœ‹æ¿": "nav_dashboard",
            "ğŸ‘ AI æŠ•é¡¾": "nav_ai_advisor",  # ğŸ”¥ æ–°å¢è¿™ä¸€è¡Œ
            "ğŸ’° ç°é‡‘æµä¸æœ¬é‡‘": "nav_cashflow",
            "ğŸ“’ æŠ•èµ„ç¬”è®°": "nav_notes",
            "ğŸ¦ èµ„äº§ç®¡ç†": "nav_assets",
            "ğŸ“ æ•°æ®å½•å…¥": "nav_entry",
            "ğŸ“… å®šæŠ•è®¡åˆ’": "nav_plans",
            "âš–ï¸ æŠ•èµ„å†å¹³è¡¡": "nav_rebalance",
            "ğŸ”¥ FIREæ¨æ¼”": "nav_fire",
            "âš™ï¸ ç³»ç»Ÿè®¾ç½®": "nav_settings"
        }
        
        selected_label = st.radio("åŠŸèƒ½èœå•", list(nav_map.keys()))
        selected_key = nav_map[selected_label]
        
        # --- åœ¨ main() å‡½æ•°å†…éƒ¨ï¼Œä¾§è¾¹æ é€»è¾‘ä¹‹å ---

        # å¦‚æœæ˜¯ demo è´¦å·ï¼Œæ˜¾ç¤ºå…¨å±€è­¦å‘Š
        if 'user' in st.session_state and st.session_state.user and st.session_state.user['username'] == 'demo':
            st.warning("âš ï¸ **æ¼”ç¤ºæ¨¡å¼ (Demo Mode)**ï¼šå½“å‰å±•ç¤ºæ•°æ®å‡ä¸º AI éšæœºç”Ÿæˆçš„è™šæ‹Ÿæ ·æœ¬ï¼Œä»…ä¾›åŠŸèƒ½æ¼”ç¤ºï¼ŒéçœŸå®èµ„äº§ã€‚", icon="ğŸ¤–")
            # ç”šè‡³å¯ä»¥æä¸ªä¾§è¾¹æ çš„æ°”æ³¡
            st.sidebar.info("å½“å‰å¤„äº Demo æ¼”ç¤ºæ¨¡å¼")

        if IS_RASPBERRY_PI:
            st.divider()
            if st.button("ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ•°æ®"):
                st.cache_data.clear()
                st.toast("ç¼“å­˜å·²æ¸…é™¤ï¼Œæ­£åœ¨é‡æ–°åŠ è½½...", icon="ğŸš€")
                st.rerun()

    # === é¡µé¢è·¯ç”±åˆ†å‘ (ä¿æŒä¸å˜) ===
    if selected_key == "nav_dashboard":
        page_dashboard()
    elif selected_key == "nav_cashflow":
        page_cashflow()
    elif selected_key == "nav_ai_advisor": # ğŸ”¥ æ–°å¢åˆ†æ”¯
        page_ai_advisor()
    elif selected_key == "nav_notes":
        page_investment_notes()
    elif selected_key == "nav_assets":
        page_assets_tags()
    elif selected_key == "nav_entry":
        page_data_entry()
    elif selected_key == "nav_plans":
        page_investment_plans()
    elif selected_key == "nav_fire":
        page_fire_projection()
    elif selected_key == "nav_settings":
        page_settings()
    elif selected_key == "nav_rebalance":
        page_rebalance()

if __name__ == '__main__':
    main()