import streamlit as st
import sqlite3
from datetime import datetime
import hashlib
import os
import shutil
from pathlib import Path
import re
import calendar # ç”¨äºå¤„ç†æœˆä»½å¤©æ•°
# åœ¨ app.py å¤´éƒ¨å¼•å…¥
from streamlit import cache_data  # å¦‚æœä¹‹å‰æ²¡å¼•
# âŒ åˆ é™¤æˆ–æ³¨é‡Šæ‰è¿™äº›è¡Œï¼š
#import pandas as pd
#import plotly.express as px
#import numpy as np
#import plotly.graph_objects as go
from datetime import timedelta
import uuid
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication

# ğŸ”¥ ä¿®æ”¹è¿™é‡Œï¼šæ™ºèƒ½åˆ¤æ–­æ•°æ®åº“è·¯å¾„
# å¦‚æœç³»ç»Ÿé‡Œæœ‰ /share è¿™ä¸ªæ–‡ä»¶å¤¹ï¼Œè¯´æ˜æ˜¯åœ¨ HA é‡Œï¼Œå°±æŠŠæ•°æ®åº“å­˜é‚£é‡Œ
if os.path.exists('/share'):
    DB_FILE = '/share/asset_tracker.db'
else:
    # å¦åˆ™ï¼ˆåœ¨ç”µè„‘å¼€å‘æ—¶ï¼‰å­˜å½“å‰ç›®å½•
    DB_FILE = 'asset_tracker.db'
    
# --- å…¼å®¹æ€§ä¿®å¤ ---
# æŸäº›æ—§ç‰ˆåº“å¯èƒ½è¿˜åœ¨æ‰¾ np.bool8ï¼Œè¿™é‡Œåšä¸€ä¸ªç®€å•çš„æ˜ å°„é˜²æ­¢æŠ¥é”™
#if not hasattr(np, 'bool8'):
#    np.bool8 = np.bool_

# --- é…ç½® ---
st.set_page_config(
    page_title="ä¸ªäººèµ„äº§ç®¡ç†ç³»ç»Ÿ",
    page_icon="ğŸ’¼", # ç›´æ¥å†™æ­» Emojiï¼Œä¸è¦åŠ è½½å›¾ç‰‡äº†
    layout="wide"
)

DB_FILE = 'asset_tracker.db'

# --- æ•°æ®åº“å·¥å…·å‡½æ•° ---
def get_db_connection():
    conn = sqlite3.connect(DB_FILE)
    conn.row_factory = sqlite3.Row
    return conn

def get_all_usernames():
    """è·å–æ•°æ®åº“ä¸­æ‰€æœ‰å·²æ³¨å†Œçš„ç”¨æˆ·ååˆ—è¡¨"""
    conn = get_db_connection()
    try:
        users = conn.execute('SELECT username FROM users').fetchall()
        # å°†ç»“æœè½¬æ¢ä¸ºçº¯å­—ç¬¦ä¸²åˆ—è¡¨ ['çˆ¸çˆ¸', 'å¦ˆå¦ˆ', 'å­©å­']
        return [u['username'] for u in users]
    except Exception:
        return []
    finally:
        conn.close()

def init_db():
    """ç¡®ä¿æ•°æ®åº“è¡¨å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    # è¿™é‡Œç›´æ¥å¤ç”¨ä½ æä¾›çš„ init_db.py çš„é€»è¾‘ï¼Œä¸ºèŠ‚çœç¯‡å¹…ï¼Œä»…åšæ£€æŸ¥
    if not os.path.exists(DB_FILE):
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå»ºè®®å…ˆè¿è¡Œ init_db.py æˆ–åœ¨è¿™é‡Œå†™å®Œæ•´çš„å»ºè¡¨é€»è¾‘
        st.error("æ•°æ®åº“æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè¿è¡Œ init_db.py åˆå§‹åŒ–æ•°æ®åº“ï¼")
        st.stop()

# --- æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½è¡¨æ ¼åŒæ­¥ ---
def save_changes_to_db(edited_df, original_df, table_name, id_col, user_id, fixed_cols=None):
    """
    å¯¹æ¯”ç¼–è¾‘å‰åçš„æ•°æ®ï¼Œè‡ªåŠ¨å¤„ç†æ–°å¢ã€ä¿®æ”¹ã€åˆ é™¤
    :param edited_df: ç¼–è¾‘åçš„ DataFrame
    :param original_df: åŸå§‹ä»æ•°æ®åº“è¯»å‡ºçš„ DataFrame
    :param table_name: æ•°æ®åº“è¡¨å
    :param id_col: ä¸»é”®åˆ—å (å¦‚ 'asset_id')
    :param user_id: å½“å‰ç”¨æˆ·ID
    :param fixed_cols: éœ€è¦åœ¨æ’å…¥/æ›´æ–°æ—¶å¼ºåˆ¶å›ºå®šçš„åˆ— (å¦‚ {'user_id': 1})
    """
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # 1. å¤„ç†åˆ é™¤
        # åŸè¡¨ä¸­å­˜åœ¨ï¼Œä½†ç¼–è¾‘åè¡¨ä¸­ä¸å­˜åœ¨çš„ IDï¼Œå°±æ˜¯è¢«åˆ é™¤çš„
        if not original_df.empty and not edited_df.empty:
            orig_ids = set(original_df[id_col].dropna().astype(int))
            new_ids = set(edited_df[id_col].dropna().astype(int))
            deleted_ids = orig_ids - new_ids
        elif not original_df.empty and edited_df.empty:
            deleted_ids = set(original_df[id_col].dropna().astype(int))
        else:
            deleted_ids = set()

        for del_id in deleted_ids:
            # çº§è”åˆ é™¤å¤„ç†ï¼ˆç®€å•ç²—æš´ç‰ˆï¼‰
            if table_name == 'assets':
                cursor.execute('DELETE FROM snapshots WHERE asset_id = ?', (del_id,))
                cursor.execute('DELETE FROM asset_tag_map WHERE asset_id = ?', (del_id,))
            elif table_name == 'tags':
                cursor.execute('DELETE FROM asset_tag_map WHERE tag_id = ?', (del_id,))
            
            cursor.execute(f'DELETE FROM {table_name} WHERE {id_col} = ? AND user_id = ?', (del_id, user_id))

        # 2. å¤„ç†æ–°å¢å’Œä¿®æ”¹
        for index, row in edited_df.iterrows():
            # å‡†å¤‡æ•°æ®å­—å…¸
            data = row.to_dict()
            if fixed_cols:
                data.update(fixed_cols)
            
            # å¦‚æœ ID ä¸ºç©ºæˆ– NaNï¼Œè§†ä¸ºæ–°å¢
            if pd.isna(row[id_col]) or row[id_col] == 0:
                # æ„å»º INSERT è¯­å¥
                cols = [k for k in data.keys() if k != id_col and k != 'created_at'] # æ’é™¤è‡ªå¢IDå’Œæ—¶é—´
                placeholders = ', '.join(['?'] * len(cols))
                col_names = ', '.join(cols)
                values = [data[c] for c in cols]
                
                query = f"INSERT INTO {table_name} ({col_names}) VALUES ({placeholders})"
                cursor.execute(query, values)
            
            # å¦‚æœ ID å­˜åœ¨ä¸”åœ¨åŸå§‹ ID é›†åˆä¸­ï¼Œè§†ä¸ºä¿®æ”¹
            elif row[id_col] in (original_df[id_col].values if not original_df.empty else []):
                # æ£€æŸ¥æ•°æ®æ˜¯å¦çœŸçš„å˜äº†ï¼ˆç®€åŒ–èµ·è§ï¼Œè¿™é‡Œç›´æ¥ Updateï¼Œæ€§èƒ½æŸè€—å¯å¿½ç•¥ï¼‰
                cols = [k for k in data.keys() if k != id_col and k != 'created_at']
                set_clause = ', '.join([f"{c} = ?" for c in cols])
                values = [data[c] for c in cols]
                values.append(row[id_col]) # Where clause value
                values.append(user_id)     # Where clause user_id
                
                query = f"UPDATE {table_name} SET {set_clause} WHERE {id_col} = ? AND user_id = ?"
                cursor.execute(query, values)

        conn.commit()
        st.success("æ•°æ®å·²æˆåŠŸåŒæ­¥ï¼")
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
        return False
    finally:
        conn.close()

# --- æ ¸å¿ƒé€»è¾‘ï¼šçº§è”åˆ é™¤ç”¨æˆ·æ‰€æœ‰æ•°æ® ---
def delete_user_fully(target_user_id):
    """
    å½»åº•åˆ é™¤ä¸€ä¸ªç”¨æˆ·åŠå…¶åä¸‹æ‰€æœ‰æ•°æ®ã€‚
    é¡ºåºå¾ˆé‡è¦ï¼šå…ˆåˆ å­è¡¨ï¼ˆå¿«ç…§ã€å…³è”ï¼‰ï¼Œå†åˆ ä¸»è¡¨ï¼ˆèµ„äº§ï¼‰ï¼Œæœ€ååˆ ç”¨æˆ·ã€‚
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    try:
        # 1. è·å–è¯¥ç”¨æˆ·æ‰€æœ‰çš„ asset_idï¼Œä»¥ä¾¿åˆ é™¤å¿«ç…§å’Œæ ‡ç­¾å…³è”
        assets = conn.execute('SELECT asset_id FROM assets WHERE user_id = ?', (target_user_id,)).fetchall()
        asset_ids = [str(row['asset_id']) for row in assets]
        
        if asset_ids:
            # SQL IN è¯­æ³•éœ€è¦å ä½ç¬¦
            placeholders = ','.join(['?'] * len(asset_ids))
            
            # åˆ é™¤ snapshots (å…³è” asset_id)
            cursor.execute(f'DELETE FROM snapshots WHERE asset_id IN ({placeholders})', asset_ids)
            
            # åˆ é™¤ asset_tag_map (å…³è” asset_id)
            cursor.execute(f'DELETE FROM asset_tag_map WHERE asset_id IN ({placeholders})', asset_ids)

        # 2. åˆ é™¤å±äºè¯¥ç”¨æˆ·çš„ç›´æ¥æ•°æ®è¡¨
        tables_with_userid = [
            'assets',           # èµ„äº§è¡¨
            'tags',             # æ ‡ç­¾è¡¨
            'cashflows',        # ç°é‡‘æµ
            'investment_plans', # å®šæŠ•è®¡åˆ’
            'investment_notes', # ç¬”è®°
            'monthly_profits',  # æœˆåº¦æ”¶ç›Š
            'monthly_reviews',  # æœˆåº¦å¤ç›˜
            'rebalance_targets',# å†å¹³è¡¡ç›®æ ‡
            'user_sessions'     # ä¼šè¯è®°å½•
        ]
        
        for table in tables_with_userid:
            cursor.execute(f'DELETE FROM {table} WHERE user_id = ?', (target_user_id,))

        # 3. æœ€ååˆ é™¤ç”¨æˆ·æœ¬èº«
        cursor.execute('DELETE FROM users WHERE user_id = ?', (target_user_id,))
        
        conn.commit()
        return True, "åˆ é™¤æˆåŠŸ"
    except Exception as e:
        conn.rollback()
        return False, f"åˆ é™¤å¤±è´¥: {str(e)}"
    finally:
        conn.close()

# --- é¡µé¢æ¨¡å— ---
# --- ç®€åŒ–ç‰ˆç”¨æˆ·ç®¡ç† (æ— å¯†ç æ¨¡å¼) ---
def get_or_create_user_by_name(username):
    """
    æ ¹æ®åå­—ç›´æ¥è·å–ç”¨æˆ·ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºã€‚
    ä¸å†æ ¡éªŒå¯†ç ï¼Œä¸»æ‰“ä¸€ä¸ªå®¶åº­å†…éƒ¨äº’ä¿¡ã€‚
    """
    conn = get_db_connection()
    try:
        # 1. å°è¯•æŸ¥æ‰¾ç”¨æˆ·
        user = conn.execute('SELECT * FROM users WHERE username = ?', (username,)).fetchone()
        
        if user:
            return dict(user)
        else:
            # 2. å¦‚æœä¸å­˜åœ¨ï¼Œè‡ªåŠ¨æ³¨å†Œä¸€ä¸ª (å¯†ç ç•™ç©ºå³å¯ï¼Œåæ­£ä¸æŸ¥äº†)
            # æ³¨æ„ï¼šè¿™é‡Œç»™ä¸€ä¸ªé»˜è®¤åçš„ dummy å¯†ç å“ˆå¸Œï¼Œé˜²æ­¢æ•°æ®åº“éç©ºçº¦æŸæŠ¥é”™
            dummy_hash = hashlib.sha256("123456".encode()).hexdigest() 
            cursor = conn.execute('INSERT INTO users (username, password_hash) VALUES (?, ?)', 
                                 (username, dummy_hash))
            user_id = cursor.lastrowid
            conn.commit()
            
            # è¿”å›æ–°åˆ›å»ºçš„ç”¨æˆ·
            return {'user_id': user_id, 'username': username}
    except Exception as e:
        st.error(f"ç”¨æˆ·è·å–å¤±è´¥: {e}")
        return None
    finally:
        conn.close()

# âŒ åˆ é™¤æˆ–æ³¨é‡Šæ‰åŸæ¥çš„: hash_password, verify_user, create_user, create_session, get_user_from_token
# âŒ åˆ é™¤æˆ–æ³¨é‡Šæ‰åŸæ¥çš„: page_login å‡½æ•°

def page_assets_tags():
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("èµ„äº§ä¸æ ‡ç­¾ç®¡ç†")
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()
    
    # --- å…¬å…±ç­›é€‰é€»è¾‘ (å°è£…åœ¨è¿™é‡Œä»¥ä¾¿å¤ç”¨) ---
    def apply_advanced_filters(df, context_key):
        """
        df: å¿…é¡»åŒ…å« asset_id, name, code åˆ—
        è¿”å›: ç­›é€‰åçš„ df
        """
        with st.expander("ğŸ” é«˜çº§ç­›é€‰ (æ”¯æŒæŸ¥æ‰¾æœªåˆ†ç±»èµ„äº§)", expanded=False):
            c1, c2, c3 = st.columns([2, 1, 2])
            
            # 1. å…³é”®å­—æœç´¢
            with c1:
                kw = st.text_input("1. å…³é”®å­—æœç´¢", placeholder="èµ„äº§åæˆ–ä»£ç ...", key=f"kw_{context_key}")
            
            # 2. æ ‡ç­¾ç»„é€‰æ‹©
            # è·å–æ‰€æœ‰æ ‡ç­¾ç»„
            all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
            groups_list = ["(ä¸ç­›é€‰)"] + all_groups['tag_group'].tolist()
            
            with c2:
                sel_group = st.selectbox("2. é€‰æ‹©æ ‡ç­¾ç»„", groups_list, key=f"grp_{context_key}")
            
            # 3. æ ‡ç­¾åé€‰æ‹© (æ ¹æ®ç»„åŠ¨æ€å˜åŒ–)
            selected_tag_names = []
            if sel_group != "(ä¸ç­›é€‰)":
                # è·å–è¯¥ç»„ä¸‹çš„æ‰€æœ‰æ ‡ç­¾
                tags_in_group = pd.read_sql("SELECT tag_name FROM tags WHERE user_id = ? AND tag_group = ?", 
                                          conn, params=(user_id, sel_group))
                # â˜…â˜…â˜… æ ¸å¿ƒåŠŸèƒ½ï¼šæ·»åŠ ã€æ— æ ‡ç­¾ã€‘é€‰é¡¹ â˜…â˜…â˜…
                options = ["ã€æ— æ­¤æ ‡ç­¾ã€‘"] + tags_in_group['tag_name'].tolist()
                
                with c3:
                    selected_tag_names = st.multiselect(
                        f"3. ç­›é€‰ '{sel_group}' ä¸‹çš„çŠ¶æ€", 
                        options=options,
                        key=f"tag_{context_key}",
                        placeholder="ç•™ç©ºåˆ™æ˜¾ç¤ºå…¨éƒ¨"
                    )
        
        # --- å¼€å§‹æ‰§è¡Œç­›é€‰ ---
        filtered_ids = df['asset_id'].tolist()
        
        # A. å…³é”®å­—è¿‡æ»¤
        if kw:
            df = df[df['name'].str.contains(kw, case=False) | df['code'].str.contains(kw, case=False, na=False)]
            filtered_ids = df['asset_id'].tolist()
            
        # B. æ ‡ç­¾è¿‡æ»¤ (æ ¸å¿ƒé€»è¾‘)
        if sel_group != "(ä¸ç­›é€‰)" and selected_tag_names:
            # 1. æ‰¾å‡ºåœ¨è¯¥ç»„ä¸‹ï¼Œæ‹¥æœ‰ç‰¹å®šæ ‡ç­¾çš„èµ„äº§ID
            # å…ˆæŸ¥å‡ºæ‰€æœ‰æ‰“è¿‡è¯¥ç»„æ ‡ç­¾çš„æ˜ å°„å…³ç³»
            sql_labeled = '''
                SELECT atm.asset_id, t.tag_name 
                FROM asset_tag_map atm
                JOIN tags t ON atm.tag_id = t.tag_id
                WHERE t.user_id = ? AND t.tag_group = ?
            '''
            df_labeled = pd.read_sql(sql_labeled, conn, params=(user_id, sel_group))
            
            target_ids = set()
            
            # æƒ…å†µ1: ç”¨æˆ·é€‰äº† ã€æ— æ­¤æ ‡ç­¾ã€‘
            if "ã€æ— æ­¤æ ‡ç­¾ã€‘" in selected_tag_names:
                # åœ¨è¯¥ç»„ä¸‹æœ‰è®°å½•çš„èµ„äº§ID
                ids_with_tags = set(df_labeled['asset_id'].unique())
                # å½“å‰ä¸Šä¸‹æ–‡æ‰€æœ‰èµ„äº§ID
                all_current_ids = set(df['asset_id'].unique())
                # å·®é›† = æ²¡æœ‰è¯¥ç»„æ ‡ç­¾çš„èµ„äº§
                ids_without_tags = all_current_ids - ids_with_tags
                target_ids.update(ids_without_tags)
            
            # æƒ…å†µ2: ç”¨æˆ·é€‰äº†å…·ä½“çš„æ ‡ç­¾ (å¦‚ "é«˜é£é™©")
            real_tags = [t for t in selected_tag_names if t != "ã€æ— æ­¤æ ‡ç­¾ã€‘"]
            if real_tags:
                ids_with_specific_tags = set(df_labeled[df_labeled['tag_name'].isin(real_tags)]['asset_id'])
                target_ids.update(ids_with_specific_tags)
            
            # å–äº¤é›†ï¼šæ—¢æ»¡è¶³å…³é”®å­—ï¼Œåˆæ»¡è¶³æ ‡ç­¾æ¡ä»¶
            df = df[df['asset_id'].isin(target_ids)]
            
        return df

    tab1, tab2, tab3 = st.tabs(["1. èµ„äº§åˆ—è¡¨", "2. æ ‡ç­¾å®šä¹‰", "3. å…³è”æ‰“æ ‡"])
    
    # 1. èµ„äº§ç®¡ç†
    with tab1:
        # --- ä¿®æ”¹ç‚¹: SQL æŸ¥è¯¢å¢åŠ  currency ---
        assets_df = pd.read_sql(
            'SELECT asset_id, name, code, type, currency, remarks FROM assets WHERE user_id = ?', 
            conn, params=(user_id,)
        )
        
        # åº”ç”¨ç­›é€‰ (ä¿æŒä¸å˜)
        assets_df = apply_advanced_filters(assets_df, "tab1")
        
        st.caption(f"å…±æ˜¾ç¤º {len(assets_df)} æ¡èµ„äº§")
        
        # --- ä¿®æ”¹ç‚¹: é…ç½® currency åˆ— ---
        edited_assets = st.data_editor(
            assets_df,
            num_rows="dynamic",
            column_config={
                "asset_id": st.column_config.NumberColumn("ID", disabled=True),
                "name": st.column_config.TextColumn("èµ„äº§åç§°", required=True),
                "code": "ä»£ç ",
                "type": st.column_config.SelectboxColumn("å¤§ç±»", options=["åŸºé‡‘", "è‚¡ç¥¨", "å€ºåˆ¸", "ç°é‡‘", "å…¶ä»–"]),
                # æ–°å¢å¸ç§é€‰æ‹©
                "currency": st.column_config.SelectboxColumn(
                    "å¸ç§", 
                    options=["CNY", "USD", "HKD", "JPY", "EUR", "GBP", "BTC"],
                    required=True,
                    default="CNY",
                    width="small"
                ),
                "remarks": st.column_config.TextColumn("å¤‡æ³¨", width="medium")
            },
            key="editor_assets",
            use_container_width=True
        )
        
        if st.button("ğŸ’¾ ä¿å­˜èµ„äº§å˜åŠ¨", type="primary"):
            if save_changes_to_db(edited_assets, assets_df, 'assets', 'asset_id', user_id, fixed_cols={'user_id': user_id}):
                st.rerun()
    
    # 2. æ ‡ç­¾ç®¡ç† (ä¸éœ€è¦ç­›é€‰ï¼Œé€»è¾‘ä¸å˜)
    with tab2:
        tags_df = pd.read_sql('SELECT tag_id, tag_group, tag_name FROM tags WHERE user_id = ?', conn, params=(user_id,))
        edited_tags = st.data_editor(
            tags_df,
            num_rows="dynamic",
            column_config={
                "tag_id": st.column_config.NumberColumn("ID", disabled=True),
                "tag_group": st.column_config.TextColumn("æ ‡ç­¾ç»„", required=True),
                "tag_name": st.column_config.TextColumn("æ ‡ç­¾å", required=True)
            },
            key="editor_tags",
            use_container_width=True
        )
        if st.button("ğŸ’¾ ä¿å­˜æ ‡ç­¾å˜åŠ¨", type="primary"):
            if save_changes_to_db(edited_tags, tags_df, 'tags', 'tag_id', user_id, fixed_cols={'user_id': user_id}):
                st.rerun()

    # 3. å…³è”æ‰“æ ‡ (çº§è”ç­›é€‰ + å…¨é€‰æ”¯æŒ)
    with tab3:
        st.write("### ğŸ·ï¸ æ‰¹é‡èµ„äº§æ‰“æ ‡")
        
        # --- A. å‡†å¤‡èµ„äº§åˆ—è¡¨æ•°æ® ---
        df_assets_tags = pd.read_sql('''
            SELECT 
                a.asset_id, 
                a.name, 
                a.code, 
                GROUP_CONCAT(t.tag_group || '-' || t.tag_name, ', ') as "å½“å‰æ ‡ç­¾"
            FROM assets a
            LEFT JOIN asset_tag_map atm ON a.asset_id = atm.asset_id
            LEFT JOIN tags t ON atm.tag_id = t.tag_id
            WHERE a.user_id = ?
            GROUP BY a.asset_id
        ''', conn, params=(user_id,))
        
        # åˆå§‹åŒ–é€‰æ‹©åˆ—ï¼ˆé»˜è®¤ä¸º Falseï¼Œåç»­å¯èƒ½ä¼šè¢«å…¨é€‰æŒ‰é’®è¦†ç›–ï¼‰
        df_assets_tags.insert(0, "é€‰æ‹©", False)

        # --- B. åº”ç”¨é«˜çº§ç­›é€‰ ---
        df_filtered = apply_advanced_filters(df_assets_tags, "tab3")
        
        # --- C. å…¨é€‰/åé€‰ æ§åˆ¶åŒº (æ–°å¢) ---
        # å¼•å…¥ session state æ¥æ§åˆ¶ data_editor çš„é‡ç½®
        if 'tag_batch_version' not in st.session_state:
            st.session_state.tag_batch_version = 0
        if 'tag_batch_default_val' not in st.session_state:
            st.session_state.tag_batch_default_val = False

        c_info, c_btn1, c_btn2 = st.columns([3, 1, 1])
        with c_info:
             st.caption(f"å½“å‰ç­›é€‰ç»“æœ: {len(df_filtered)} ä¸ªèµ„äº§")
        
        with c_btn1:
            if st.button("âœ… å…¨é€‰å½“å‰", key="btn_sel_all", help="é€‰ä¸­å½“å‰åˆ—è¡¨ä¸­çš„æ‰€æœ‰èµ„äº§", use_container_width=True):
                st.session_state.tag_batch_default_val = True
                st.session_state.tag_batch_version += 1 # å¼ºåˆ¶æ›´æ–° keyï¼Œè§¦å‘è¡¨æ ¼é‡ç»˜
                st.rerun()
        
        with c_btn2:
            if st.button("â¬œ å–æ¶ˆå…¨é€‰", key="btn_sel_none", help="å–æ¶ˆæ‰€æœ‰å‹¾é€‰", use_container_width=True):
                st.session_state.tag_batch_default_val = False
                st.session_state.tag_batch_version += 1
                st.rerun()

        # æ ¹æ®æŒ‰é’®çŠ¶æ€ï¼Œå¼ºåˆ¶è®¾ç½®æŸä¸€åˆ—çš„å€¼
        df_filtered["é€‰æ‹©"] = st.session_state.tag_batch_default_val

        # --- D. è¡¨æ ¼æ˜¾ç¤º ---
        # å…³é”®ç‚¹ï¼škey åŒ…å«äº† versionã€‚ä¸€æ—¦ version å˜äº†ï¼ŒStreamlit ä¼šè®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„è¡¨æ ¼ï¼Œ
        # ä»è€Œä¸¢å¼ƒä¹‹å‰çš„ç¼–è¾‘çŠ¶æ€ï¼Œé‡æ–°åŠ è½½ df_filtered (ä¹Ÿå°±æ˜¯æˆ‘ä»¬åˆšè®¾ä¸º True çš„é‚£äº›æ•°æ®)
        unique_key = f"tag_editor_{len(df_filtered)}_{st.session_state.tag_batch_version}"
        
        edited_df = st.data_editor(
            df_filtered,
            column_config={
                "é€‰æ‹©": st.column_config.CheckboxColumn("âœ…", default=False),
                "asset_id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
                "name": st.column_config.TextColumn("èµ„äº§åç§°", disabled=True),
                "code": st.column_config.TextColumn("ä»£ç ", disabled=True),
                "å½“å‰æ ‡ç­¾": st.column_config.TextColumn("å½“å‰æ ‡ç­¾", disabled=True, width="large"),
            },
            hide_index=True,
            use_container_width=True,
            key=unique_key
        )
        
        # --- E. æ“ä½œåŒºåŸŸ (çº§è”æ ‡ç­¾é€‰æ‹©) ---
        st.divider()
        st.markdown("##### ğŸ› ï¸ æ‰¹é‡æ“ä½œ")
        
        col_actions, col_submit = st.columns([3, 1])
        
        with col_actions:
            all_tags_data = conn.execute('SELECT tag_id, tag_group, tag_name FROM tags WHERE user_id = ? ORDER BY tag_group, tag_name', (user_id,)).fetchall()
            
            if not all_tags_data:
                st.warning("æš‚æ— æ ‡ç­¾ï¼Œè¯·å…ˆå»ã€æ ‡ç­¾å®šä¹‰ã€‘é¡µç­¾æ·»åŠ ã€‚")
                selected_tags_to_apply = []
                action_mode = "â• æ·»åŠ "
            else:
                all_groups = sorted(list(set([t['tag_group'] for t in all_tags_data])))
                
                # [ç¬¬ä¸€çº§] æ ‡ç­¾ç»„
                filter_groups = st.multiselect(
                    "1. å…ˆç­›é€‰æ ‡ç­¾ç»„", 
                    options=all_groups,
                    placeholder="ç•™ç©ºåˆ™æ˜¾ç¤ºå…¨éƒ¨æ ‡ç­¾...",
                    key="tag_action_group_filter"
                )
                
                # [ç¬¬äºŒçº§] å…·ä½“æ ‡ç­¾
                if filter_groups:
                    available_tags = [t for t in all_tags_data if t['tag_group'] in filter_groups]
                else:
                    available_tags = all_tags_data
                
                tag_options = {t['tag_id']: f"ã€{t['tag_group']}ã€‘{t['tag_name']}" for t in available_tags}
                
                selected_tags_to_apply = st.multiselect(
                    f"2. é€‰æ‹©è¦åº”ç”¨çš„æ ‡ç­¾ (å¯é€‰ {len(available_tags)} ä¸ª)", 
                    options=tag_options.keys(), 
                    format_func=lambda x: tag_options[x],
                    placeholder="å¯å¤šé€‰...",
                    key="tag_action_final_select"
                )
                
                action_mode = st.radio("3. æ“ä½œæ¨¡å¼", ["â• æ·»åŠ  (ä¿ç•™å·²æœ‰)", "ğŸ”„ è¦†ç›– (æ¸…é™¤æ—§æ ‡)", "â– ç§»é™¤ (ä»…åˆ é€‰ä¸­)"], horizontal=True)

        with col_submit:
            st.write(" ")
            st.write(" ")
            st.write(" ")
            if st.button("ğŸš€ æ‰§è¡Œæ›´æ–°", type="primary", use_container_width=True):
                # ç»Ÿè®¡æœ‰å¤šå°‘è¡Œè¢«é€‰ä¸­äº†
                selected_assets = edited_df[edited_df["é€‰æ‹©"] == True]["asset_id"].tolist()
                
                if not selected_assets:
                    st.warning("è¯·åœ¨è¡¨æ ¼å·¦ä¾§å‹¾é€‰è‡³å°‘ä¸€ä¸ªèµ„äº§ï¼")
                elif not selected_tags_to_apply:
                    st.warning("è¯·é€‰æ‹©è¦æ“ä½œçš„æ ‡ç­¾ï¼")
                else:
                    try:
                        cursor = conn.cursor()
                        if "è¦†ç›–" in action_mode:
                            placeholders = ','.join(['?'] * len(selected_assets))
                            cursor.execute(f'DELETE FROM asset_tag_map WHERE asset_id IN ({placeholders})', selected_assets)
                            for aid in selected_assets:
                                for tid in selected_tags_to_apply:
                                    cursor.execute('INSERT INTO asset_tag_map (asset_id, tag_id) VALUES (?, ?)', (aid, tid))
                                    
                        elif "æ·»åŠ " in action_mode:
                            for aid in selected_assets:
                                for tid in selected_tags_to_apply:
                                    cursor.execute('INSERT OR IGNORE INTO asset_tag_map (asset_id, tag_id) VALUES (?, ?)', (aid, tid))
                                    
                        elif "ç§»é™¤" in action_mode:
                            for aid in selected_assets:
                                for tid in selected_tags_to_apply:
                                    cursor.execute('DELETE FROM asset_tag_map WHERE asset_id = ? AND tag_id = ?', (aid, tid))
                                    
                        conn.commit()
                        st.success(f"âœ… æˆåŠŸæ›´æ–° {len(selected_assets)} ä¸ªèµ„äº§ï¼")
                        
                        # æ›´æ–°åï¼Œæˆ‘ä»¬é‡ç½®ä¸€ä¸‹å…¨é€‰çŠ¶æ€ï¼Œé˜²æ­¢è¯¯æ“ä½œ
                        st.session_state.tag_batch_default_val = False
                        st.session_state.tag_batch_version += 1
                        
                        import time
                        time.sleep(0.5)
                        st.rerun()
                    except Exception as e:
                        conn.rollback()
                        st.error(str(e))
    conn.close()

def page_data_entry():
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("ğŸ“ æ¯æ—¥èµ„äº§å¿«ç…§å½•å…¥")
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()
    
    # æ—¥æœŸé€‰æ‹©
    col_date, _ = st.columns([1, 2])
    with col_date:
        date = st.date_input("é€‰æ‹©å¿«ç…§æ—¥æœŸ", datetime.now())
        str_date = date.strftime('%Y-%m-%d')

    # 1. å‡†å¤‡åŸºç¡€æ•°æ® (åŒ…å«å¸ç§)
    assets = pd.read_sql('SELECT asset_id, name, code, currency FROM assets WHERE user_id = ?', conn, params=(user_id,))
    
    if assets.empty:
        st.warning("æš‚æ— èµ„äº§ï¼Œè¯·å…ˆå»ã€èµ„äº§ä¸æ ‡ç­¾ç®¡ç†ã€‘æ·»åŠ èµ„äº§ã€‚")
        conn.close()
        return

    # --- 2. æ±‡ç‡å½•å…¥åŒº (ä¿æŒä¸å˜) ---
    if 'currency' in assets.columns:
        unique_currencies = assets['currency'].unique().tolist()
        foreign_currencies = [c for c in unique_currencies if c and c != 'CNY']
    else:
        foreign_currencies = []
    
    if foreign_currencies:
        with st.expander(f"ğŸ’± è®¾ç½®å½“æ—¥æ±‡ç‡ ({str_date})", expanded=True):
            st.caption("æ£€æµ‹åˆ°æ‚¨æŒæœ‰å¤–å¸èµ„äº§ï¼Œè¯·ç¡®è®¤å½“æ—¥æ±‡ç‡ï¼ˆå¯¹äººæ°‘å¸ï¼‰ï¼š")
            saved_rates = pd.read_sql("SELECT currency, rate FROM exchange_rates WHERE date = ?", conn, params=(str_date,))
            saved_rate_map = dict(zip(saved_rates['currency'], saved_rates['rate']))
            cols = st.columns(len(foreign_currencies) + 1)
            rates_to_save = {}
            for i, curr in enumerate(foreign_currencies):
                default_val = saved_rate_map.get(curr, 1.0)
                with cols[i]:
                    r = st.number_input(f"{curr} â¡ï¸ CNY", value=float(default_val), format="%.4f", key=f"rate_{curr}_{str_date}")
                    rates_to_save[curr] = r
            with cols[-1]:
                st.write(""); st.write("") 
                if st.button("ğŸ’¾ ä¿å­˜æ±‡ç‡", type="secondary"):
                    try:
                        for curr, rate in rates_to_save.items():
                            conn.execute("INSERT OR REPLACE INTO exchange_rates (date, currency, rate) VALUES (?, ?, ?)", (str_date, curr, rate))
                        conn.commit()
                        st.toast("æ±‡ç‡å·²æ›´æ–°", icon="ğŸ’±")
                    except Exception as e: st.error(f"æ±‡ç‡ä¿å­˜å¤±è´¥: {e}")

    # --- 3. ç­›é€‰ä¸æ’åºå·¥å…· (å‡çº§ç‰ˆ) ---
    with st.expander("ğŸ” ç­›é€‰ä¸æ’åºå·¥å…·", expanded=True):
        # ç¬¬ä¸€è¡Œï¼šæ ¸å¿ƒç­›é€‰
        c1, c2, c3 = st.columns([2, 1, 2])
        with c1:
            kw = st.text_input("å…³é”®å­—æœç´¢", placeholder="åç§°/ä»£ç ")
        with c2:
            # ğŸ”¥ æ–°å¢ï¼šéšè—å·²æ¸…ä»“å¼€å…³ (é»˜è®¤å¼€å¯)
            hide_cleared = st.checkbox("ğŸ™ˆ éšè—å·²æ¸…ä»“èµ„äº§", value=True, help="å‹¾é€‰åï¼Œä¸Šæ¬¡è®°å½•ä¸ºã€å·²æ¸…ä»“ã€‘çš„èµ„äº§å°†ä¸ä¼šæ˜¾ç¤ºåœ¨ä¸‹æ–¹")
        with c3:
            all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
            grp_list = ["(ä¸ç­›é€‰)"] + all_groups['tag_group'].tolist()
            sel_group = st.selectbox("æ ‡ç­¾ç»„", grp_list)
            
        # ç¬¬äºŒè¡Œï¼šæ ‡ç­¾ç»†åˆ†ä¸æ’åº
        s1, s2 = st.columns([2, 2])
        with s1:
            sel_tags = []
            if sel_group != "(ä¸ç­›é€‰)":
                t_df = pd.read_sql("SELECT tag_name FROM tags WHERE user_id=? AND tag_group=?", conn, params=(user_id, sel_group))
                opts = ["ã€æ— æ­¤æ ‡ç­¾ã€‘"] + t_df['tag_name'].tolist()
                sel_tags = st.multiselect("æ ‡ç­¾å", opts)
        with s2:
            sort_option = st.radio("æ’åºä¾æ®", ["é»˜è®¤ (ID)", "ğŸ’° æ€»é‡‘é¢ (é«˜â†’ä½)", "ğŸ’° æ€»é‡‘é¢ (ä½â†’é«˜)", "ğŸ“ˆ æŒæœ‰æ”¶ç›Š (é«˜â†’ä½)"], horizontal=True)

    # --- 4. æ•°æ®é¢„å¤„ç†ï¼šè·å–â€œæ¸…ä»“çŠ¶æ€â€ ---
    # æˆ‘ä»¬éœ€è¦çŸ¥é“æ¯ä¸ªèµ„äº§â€œæœ€è¿‘ä¸€æ¬¡â€çš„çŠ¶æ€æ˜¯ä»€ä¹ˆ
    # ä½¿ç”¨ SQL çª—å£å‡½æ•°æˆ–åˆ†ç»„å–æœ€å¤§æ—¥æœŸæ¥è·å–æ¯ä¸ªèµ„äº§æœ€æ–°çš„ is_cleared çŠ¶æ€
    # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šä¸ç®¡ä½ é€‰å“ªå¤©å½•å…¥ï¼Œæˆ‘ä»¬éƒ½å‚è€ƒè¯¥èµ„äº§â€œä¹Ÿå°±æ˜¯æ•°æ®åº“é‡Œæœ€æ–°çš„ä¸€æ¡è®°å½•â€çš„çŠ¶æ€
    
    # å…ˆæŠŠèµ„äº§IDåˆ—è¡¨æ‹¿å‡ºæ¥
    all_asset_ids = tuple(assets['asset_id'].tolist())
    if len(all_asset_ids) == 1: str_ids = f"({all_asset_ids[0]})"
    else: str_ids = str(all_asset_ids)
    
    # æŸ¥å‡ºæ¯ä¸ªèµ„äº§æœ€è¿‘ä¸€æ¬¡å¿«ç…§çš„ is_cleared çŠ¶æ€
    # æ³¨æ„ï¼šæˆ‘ä»¬è¦æŸ¥çš„æ˜¯â€œå†å²è®°å½•â€ï¼Œæ‰€ä»¥ä¸é™åˆ¶æ—¥æœŸï¼Œç›´æ¥æ‰¾æœ€æ–°çš„
    last_status_df = pd.read_sql(f'''
        SELECT asset_id, is_cleared 
        FROM snapshots 
        WHERE asset_id IN {str_ids}
        ORDER BY date DESC
    ''', conn)
    # å»é‡ä¿ç•™æ¯ä¸ª asset_id çš„ç¬¬ä¸€æ¡ï¼ˆä¹Ÿå°±æ˜¯æœ€æ–°çš„ï¼‰
    last_status_df = last_status_df.drop_duplicates(subset=['asset_id'])
    
    # å°†æœ€æ–°çŠ¶æ€åˆå¹¶å› assets è¡¨
    assets = pd.merge(assets, last_status_df, on='asset_id', how='left')
    # å¦‚æœä»¥å‰æ²¡è®°å½•ï¼Œé»˜è®¤ä¸º 0 (æœªæ¸…ä»“)
    assets['is_cleared'] = assets['is_cleared'].fillna(0).astype(bool)

    # --- 5. æ‰§è¡Œç­›é€‰ ---
    filtered_df = assets.copy()
    
    # A. éšè—å·²æ¸…ä»“é€»è¾‘ (æ ¸å¿ƒåŠŸèƒ½)
    if hide_cleared:
        # åªä¿ç•™ is_cleared == False çš„ (å³æœªæ¸…ä»“çš„)
        filtered_df = filtered_df[filtered_df['is_cleared'] == False]
    
    # B. å…³é”®å­—
    if kw:
        filtered_df = filtered_df[filtered_df['name'].str.contains(kw, case=False) | filtered_df['code'].str.contains(kw, case=False, na=False)]
    
    # C. æ ‡ç­¾ (é€»è¾‘ä¸å˜)
    if sel_group != "(ä¸ç­›é€‰)" and sel_tags:
        sql_labeled = '''SELECT atm.asset_id, t.tag_name FROM asset_tag_map atm JOIN tags t ON atm.tag_id = t.tag_id WHERE t.user_id = ? AND t.tag_group = ?'''
        df_labeled = pd.read_sql(sql_labeled, conn, params=(user_id, sel_group))
        target_ids = set()
        current_ids = set(filtered_df['asset_id'])
        if "ã€æ— æ­¤æ ‡ç­¾ã€‘" in sel_tags: target_ids.update(current_ids - set(df_labeled['asset_id']))
        real_tags = [t for t in sel_tags if t != "ã€æ— æ­¤æ ‡ç­¾ã€‘"]
        if real_tags: target_ids.update(set(df_labeled[df_labeled['tag_name'].isin(real_tags)]['asset_id']))
        filtered_df = filtered_df[filtered_df['asset_id'].isin(target_ids)]

    # --- 6. å‡†å¤‡ç¼–è¾‘è¡¨æ ¼ ---
    if filtered_df.empty:
        st.info("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„èµ„äº§ (å¯èƒ½éƒ½è¢«éšè—äº†ï¼Œå°è¯•å–æ¶ˆå‹¾é€‰'éšè—å·²æ¸…ä»“')ã€‚")
    else:
        final_ids = tuple(filtered_df['asset_id'].tolist())
        if len(final_ids) == 1: q_ids = f"({final_ids[0]})"
        else: q_ids = str(final_ids)
        
        # è·å–ã€é€‰ä¸­æ—¥æœŸã€‘çš„å¿«ç…§æ•°æ®
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è¿˜è¦å– is_clearedï¼Œä»¥ä¾¿å›æ˜¾å½“å¤©çš„æ•°æ®
        snap_query = f'''SELECT asset_id, amount, profit, cost, yield_rate, is_cleared 
                         FROM snapshots WHERE date = ? AND asset_id IN {q_ids}'''
        
        current_snapshots = pd.read_sql(snap_query, conn, params=(str_date,))
        
        # åˆå¹¶ï¼šèµ„äº§åŸºç¡€ä¿¡æ¯ + å½“æ—¥å¿«ç…§ä¿¡æ¯
        # æ³¨æ„ï¼šè¿™é‡Œæœ‰ä¸¤ä¸ª is_clearedã€‚
        # assets è¡¨é‡Œçš„ is_cleared æ˜¯â€œå†å²æœ€æ–°çŠ¶æ€â€(ç”¨äºç­›é€‰)ï¼Œ
        # current_snapshots è¡¨é‡Œçš„ is_cleared æ˜¯â€œå½“å¤©å·²ä¿å­˜çš„çŠ¶æ€â€(ç”¨äºç¼–è¾‘)ã€‚
        # æˆ‘ä»¬ä¼˜å…ˆä½¿ç”¨â€œå½“å¤©å·²ä¿å­˜çš„çŠ¶æ€â€ï¼Œå¦‚æœå½“å¤©è¿˜æ²¡å­˜ï¼Œé»˜è®¤ä½¿ç”¨â€œå†å²æœ€æ–°çŠ¶æ€â€æ¥å¡«å……ï¼ˆè¿™å°±æ˜¯æ‰€è°“çš„ç»§æ‰¿ï¼ï¼‰
        
        merged = pd.merge(filtered_df, current_snapshots, on='asset_id', how='left', suffixes=('_last', '_today'))
        
        # å¡«å……æ•°å€¼
        merged['amount'] = merged['amount'].fillna(0.0)
        merged['profit'] = merged['profit'].fillna(0.0)
        merged['yield_rate'] = merged['yield_rate'].fillna(0.0)
        
        # æ ¸å¿ƒç»§æ‰¿é€»è¾‘ï¼š
        # å¦‚æœ _today æ˜¯ NaN (è¯´æ˜ä»Šå¤©è¿˜æ²¡å¡«)ï¼Œå°±ç”¨ _last (ä¸Šæ¬¡çš„çŠ¶æ€)
        # å¦‚æœ _today æœ‰å€¼ï¼Œå°±ç”¨ _today
        merged['is_cleared'] = merged['is_cleared_today'].combine_first(merged['is_cleared_last'])
        # ç¡®ä¿æ˜¯å¸ƒå°”å€¼
        merged['is_cleared'] = merged['is_cleared'].astype(bool)

        # æ’åº
        if "æ€»é‡‘é¢ (é«˜â†’ä½)" in sort_option: merged = merged.sort_values(by='amount', ascending=False)
        elif "æ€»é‡‘é¢ (ä½â†’é«˜)" in sort_option: merged = merged.sort_values(by='amount', ascending=True)
        elif "æŒæœ‰æ”¶ç›Š (é«˜â†’ä½)" in sort_option: merged = merged.sort_values(by='profit', ascending=False)
        
        # --- 7. æ˜¾ç¤ºè¡¨æ ¼ ---
        st.caption(f"å½“å‰æ˜¾ç¤º: {len(merged)} æ¡ | ğŸ’¡ å‹¾é€‰ã€ğŸã€‘åˆ—è¡¨ç¤ºå·²æ¸…ä»“ï¼Œä¸‹æ¬¡å½•å…¥æ—¶ä¼šè‡ªåŠ¨éšè—")

        col_cfg = {
            "asset_id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
            "name": st.column_config.TextColumn("èµ„äº§åç§°", disabled=True),
            "code": st.column_config.TextColumn("ä»£ç ", disabled=True),
            "amount": st.column_config.NumberColumn("ğŸ’° å¸‚å€¼ (åŸå¸)", format="%.2f", required=True),
            "profit": st.column_config.NumberColumn("ğŸ“ˆ æ”¶ç›Š (åŸå¸)", format="%.2f", required=True),
            "cost": st.column_config.NumberColumn("æœ¬é‡‘", disabled=True, format="%.2f"),
            "yield_rate": st.column_config.NumberColumn("æ”¶ç›Šç‡", disabled=True, format="%.2f%%"),
            # ğŸ”¥ æ–°å¢åˆ—é…ç½®
            "is_cleared": st.column_config.CheckboxColumn("ğŸ æ¸…ä»“?", help="å‹¾é€‰åè¡¨ç¤ºè¯¥èµ„äº§å·²æ¸…ä»“"),
        }
        if 'currency' in merged.columns:
            col_cfg["currency"] = st.column_config.TextColumn("å¸", disabled=True, width="small")

        edited_snapshot = st.data_editor(
            merged,
            column_config=col_cfg,
            hide_index=True,
            use_container_width=True,
            # è¿™é‡Œçš„ key å¾ˆé‡è¦ï¼ŒåŠ ä¸Š hide_cleared çŠ¶æ€ï¼Œç¡®ä¿åˆ‡æ¢ç­›é€‰æ—¶è¡¨æ ¼é‡ç»˜
            key=f"entry_{str_date}_{kw}_{hide_cleared}_{sort_option}"
        )

        # --- 8. ä¿å­˜é€»è¾‘ ---
        if st.button("ğŸ’¾ ä¿å­˜å½“å‰æ•°æ®", type="primary"):
            try:
                c = 0
                for _, row in edited_snapshot.iterrows():
                    amt = float(row['amount'])
                    prof = float(row['profit'])
                    # å¦‚æœç”¨æˆ·å‹¾é€‰äº†æ¸…ä»“ï¼Œé€šå¸¸é‡‘é¢åº”è¯¥æ˜¯0ï¼Œä½†æˆ‘ä»¬ä¸å¼ºåˆ¶æ”¹å†™ï¼Œä¿ç•™ç”¨æˆ·è¾“å…¥
                    is_clr = 1 if row['is_cleared'] else 0
                    
                    cost = amt - prof
                    y_rate = (prof / cost * 100) if cost != 0 else 0.0
                    
                    # æ’å…¥æˆ–æ›´æ–°ï¼ŒåŒ…å« is_cleared
                    conn.execute('''
                        INSERT INTO snapshots (asset_id, date, amount, profit, cost, yield_rate, is_cleared) 
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                        ON CONFLICT(asset_id, date) DO UPDATE SET 
                        amount=excluded.amount, profit=excluded.profit, 
                        cost=excluded.cost, yield_rate=excluded.yield_rate,
                        is_cleared=excluded.is_cleared
                    ''', (row['asset_id'], str_date, amt, prof, cost, y_rate, is_clr))
                    c += 1
                conn.commit()
                st.cache_data.clear()
                st.success(f"å·²ä¿å­˜ {c} æ¡è®°å½•ï¼")
                # ç¨å¾®å»¶è¿Ÿä¸€ä¸‹è‡ªåŠ¨åˆ·æ–°ï¼Œè®©ç”¨æˆ·çœ‹åˆ°æˆåŠŸæç¤º
                import time
                time.sleep(0.5)
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")

        # --- [æ’å…¥ä½ç½®å¼€å§‹] ---
        st.write("")
        st.write("")
        st.divider()
        
        # 9. åˆ é™¤/é‡ç½®å½“æ—¥æ•°æ® (æ–°å¢åŠŸèƒ½)
        # å…ˆæ£€æŸ¥ä¸€ä¸‹å½“å¤©æœ‰æ²¡æœ‰æ•°æ®ï¼Œæœ‰æ•°æ®æ‰æ˜¾ç¤ºåˆ é™¤æŒ‰é’®
        # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šæŸ¥è¯¢ user_id ä¸‹ï¼Œæ—¥æœŸä¸º str_date çš„æ‰€æœ‰å¿«ç…§æ•°é‡
        exist_count = conn.execute('''
            SELECT COUNT(*) FROM snapshots s
            JOIN assets a ON s.asset_id = a.asset_id
            WHERE s.date = ? AND a.user_id = ?
        ''', (str_date, user_id)).fetchone()[0]

        if exist_count > 0:
            with st.expander(f"ğŸ—‘ï¸ åˆ é™¤/é‡ç½® ã€{str_date}ã€‘ çš„æ•°æ®", expanded=False):
                st.warning(f"è­¦å‘Šï¼šæ£€æµ‹åˆ° {str_date} å·²æœ‰ {exist_count} æ¡èµ„äº§è®°å½•ã€‚")
                st.info("å¦‚æœä½ æ˜¯ä¸å°å¿ƒå½•é”™æ—¥æœŸï¼ˆä¾‹å¦‚æŠŠæ˜¨å¤©çš„å½•æˆäº†ä»Šå¤©ï¼‰ï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¯ä»¥å½»åº•æ¸…é™¤ä»Šæ—¥è®°å½•ã€‚æ¸…é™¤åï¼Œçœ‹æ¿å°†ä¸ä¼šæŠŠä»Šå¤©ç®—ä½œ 0ï¼Œè€Œæ˜¯ç›´æ¥è·³è¿‡ä»Šå¤©ã€‚")
                
                # åŒé‡ç¡®è®¤æŒ‰é’®ï¼ˆé˜²æ­¢è¯¯è§¦ï¼‰
                col_del_1, col_del_2 = st.columns([1, 4])
                with col_del_1:
                    if st.button("ğŸ§¨ ç¡®è®¤å½»åº•åˆ é™¤", type="primary", key="btn_delete_daily"):
                        try:
                            # æ‰§è¡Œåˆ é™¤æ“ä½œ
                            # é€»è¾‘ï¼šåˆ é™¤ snapshots è¡¨ä¸­ï¼Œå±äºè¯¥ç”¨æˆ·ä¸”æ—¥æœŸä¸ºé€‰å®šæ—¥æœŸçš„æ‰€æœ‰è®°å½•
                            conn.execute('''
                                DELETE FROM snapshots 
                                WHERE date = ? 
                                AND asset_id IN (SELECT asset_id FROM assets WHERE user_id = ?)
                            ''', (str_date, user_id))
                            
                            conn.commit()
                            st.success(f"å·²æˆåŠŸåˆ é™¤ {str_date} çš„æ‰€æœ‰è®°å½•ï¼")
                            
                            # ç¨å¾®åœé¡¿ä¸€ä¸‹è®©ç”¨æˆ·çœ‹åˆ°æç¤ºï¼Œç„¶ååˆ·æ–°é¡µé¢
                            import time
                            time.sleep(1)
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"åˆ é™¤å¤±è´¥: {e}")
        else:
            # å¦‚æœå½“å¤©æ²¡æ•°æ®ï¼Œæ˜¾ç¤ºä¸€ä¸ªç°è‰²çš„æç¤º
            st.caption(f"ğŸ“… å½“å‰æ—¥æœŸ {str_date} æš‚æ— å½•å…¥æ•°æ®ï¼Œæ— éœ€åˆ é™¤ã€‚")
        # --- [æ’å…¥ä½ç½®ç»“æŸ] ---
    conn.close()


def page_cashflow():
    import pandas as pd
    import plotly.express as px
    
    st.header("ğŸ’° ç°é‡‘æµä¸æœ¬é‡‘å½’é›†")
    st.caption("â€œæ¨¡ç³Šè®°è´¦æ³•â€æ ¸å¿ƒï¼šåªè®°å¤§é¢è¿›å‡ºï¼Œå€’æ¨æœ¬é‡‘æŠ•å…¥ã€‚")
    
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    # --- 1. é¡¶éƒ¨ï¼šæç®€å½•å…¥åŒº ---
    with st.container(border=True):
        st.subheader("â• æ–°å¢è®°å½•")
        c1, c2, c3, c4, c5 = st.columns([2, 2, 2, 3, 1])
        
        with c1:
            record_date = st.date_input("æ—¥æœŸ", datetime.now(), key="cf_date")
        
        with c2:
            flow_type = st.selectbox("ç±»å‹", ["ğŸ“¥ æ”¶å…¥ (æŠ•å…¥æœ¬é‡‘)", "ğŸ“¤ æ”¯å‡º (æ¶ˆè€—æœ¬é‡‘)"], key="cf_type")
            
        with c3:
            amount = st.number_input("é‡‘é¢", min_value=0.0, step=1000.0, format="%.2f", key="cf_amt")
            
        with c4:
            # æ ¹æ®ç±»å‹åŠ¨æ€æ”¹å˜å»ºè®®é€‰é¡¹
            if "æ”¶å…¥" in flow_type:
                options = ["å·¥èµ„/å¥–é‡‘", "ç†è´¢èµå›", "å…¶ä»–æ”¶å…¥"]
            else:
                options = ["ä¿¡ç”¨å¡/èŠ±å‘—è´¦å•", "æˆ¿è´·/æˆ¿ç§Ÿ", "å¤§é¢è½¬è´¦", "å…¶ä»–å¤§é¢æ”¯å‡º"]
            category = st.selectbox("ç±»åˆ« (å¯ç¼–è¾‘)", options, key="cf_cat") # ä¹Ÿå¯ä»¥ç”¨ text_input + suggestions
            
        with c5:
            st.write("")
            st.write("")
            if st.button("ğŸ’¾ è®°ä¸€ç¬”", type="primary", use_container_width=True):
                if amount > 0:
                    real_type = "æ”¶å…¥" if "æ”¶å…¥" in flow_type else "æ”¯å‡º"
                    conn.execute('''
                        INSERT INTO cashflows (user_id, date, type, amount, category, created_at)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (user_id, record_date.strftime('%Y-%m-%d'), real_type, amount, category, datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
                    conn.commit()
                    st.success("å·²è®°å½•")
                    import time
                    time.sleep(0.5)
                    st.rerun()
                else:
                    st.warning("é‡‘é¢éœ€å¤§äº0")

    # --- 2. ä¸­éƒ¨ï¼šå¹´åº¦ç»Ÿè®¡å¡ç‰‡ ---
    current_year = datetime.now().year
    df_cf = pd.read_sql('''
        SELECT id, date, type, amount, category, note 
        FROM cashflows 
        WHERE user_id = ? 
        ORDER BY date DESC
    ''', conn, params=(user_id,))
    
    if not df_cf.empty:
        df_cf['date'] = pd.to_datetime(df_cf['date'])
        df_cf['year'] = df_cf['date'].dt.year
        
        # æœ¬å¹´åº¦ç»Ÿè®¡
        df_this_year = df_cf[df_cf['year'] == current_year]
        income_year = df_this_year[df_this_year['type'] == 'æ”¶å…¥']['amount'].sum()
        expense_year = df_this_year[df_this_year['type'] == 'æ”¯å‡º']['amount'].sum()
        net_input = income_year - expense_year
        
        st.divider()
        st.markdown(f"### ğŸ“… {current_year} å¹´åº¦æœ¬é‡‘æŠ•å…¥æ¦‚è§ˆ")
        k1, k2, k3 = st.columns(3)
        k1.metric("ğŸ“¥ æœ¬å¹´ç´¯è®¡å¤§é¢æ”¶å…¥", f"Â¥{income_year:,.2f}")
        k2.metric("ğŸ“¤ æœ¬å¹´ç´¯è®¡å¤§é¢æ”¯å‡º", f"Â¥{expense_year:,.2f}")
        k3.metric("ğŸŒ± æœ¬å¹´å‡€æŠ•å…¥æœ¬é‡‘", f"Â¥{net_input:,.2f}", 
                 delta="è¿™æ˜¯ä½ çš„åŠªåŠ›å­˜ä¸‹çš„é’±" if net_input > 0 else "æœ¬é‡‘æ­£åœ¨æµå‡º",
                 delta_color="normal" if net_input > 0 else "inverse")

    # --- 3. åº•éƒ¨ï¼šæ•°æ®ç®¡ç† (DataEditor) ---
    st.divider()
    st.subheader("ğŸ“‹ å†å²æ˜ç»†ç®¡ç†")
    
    if not df_cf.empty:
        # ä¸ºäº† DataEditor æ˜¾ç¤ºå‹å¥½ï¼Œåšä¸€ç‚¹å¤„ç†
        df_display = df_cf[['id', 'date', 'type', 'amount', 'category', 'note']].copy()
        df_display['date'] = df_display['date'].dt.date
        
        edited_df = st.data_editor(
            df_display,
            column_config={
                "id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
                "date": st.column_config.DateColumn("æ—¥æœŸ", format="YYYY-MM-DD"),
                "type": st.column_config.SelectboxColumn("ç±»å‹", options=["æ”¶å…¥", "æ”¯å‡º"], required=True),
                "amount": st.column_config.NumberColumn("é‡‘é¢", format="%.2f", min_value=0),
                "category": st.column_config.TextColumn("ç±»åˆ«"),
                "note": st.column_config.TextColumn("å¤‡æ³¨"),
            },
            use_container_width=True,
            num_rows="dynamic",
            key="cf_editor"
        )
        
        if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹ (æ”¯æŒåˆ é™¤)", type="secondary"):
            # å¤ç”¨ä½ çš„ save_changes_to_db é€»è¾‘ï¼Œæˆ–è€…ç®€å•å†™ä¸ªå¤„ç†
            # è¿™é‡Œç®€å•å†™ä¸ªå¤„ç† ID çš„é€»è¾‘
            try:
                # 1. æ‰¾å‡ºè¢«åˆ é™¤çš„
                orig_ids = set(df_cf['id'].tolist())
                new_ids = set(edited_df['id'].dropna().tolist())
                del_ids = orig_ids - new_ids
                
                for did in del_ids:
                    conn.execute("DELETE FROM cashflows WHERE id = ?", (did,))
                
                # 2. æ›´æ–°/æ–°å¢
                for index, row in edited_df.iterrows():
                    if pd.isna(row['id']): # æ–°å¢
                         conn.execute("INSERT INTO cashflows (user_id, date, type, amount, category, note) VALUES (?,?,?,?,?,?)",
                                      (user_id, row['date'], row['type'], row['amount'], row['category'], row['note']))
                    elif row['id'] in new_ids: # ä¿®æ”¹
                         conn.execute("UPDATE cashflows SET date=?, type=?, amount=?, category=?, note=? WHERE id=?",
                                      (row['date'], row['type'], row['amount'], row['category'], row['note'], row['id']))
                
                conn.commit()
                st.success("æ›´æ–°æˆåŠŸ")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
    else:
        st.info("æš‚æ— è®°å½•ï¼Œè¯·åœ¨ä¸Šæ–¹æ·»åŠ ã€‚")

    conn.close()

def get_latest_rates(conn):
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    """è·å–ç³»ç»Ÿä¸­æ¯ç§è´§å¸æœ€æ–°çš„æ±‡ç‡ (å¯¹CNY)"""
    # æŒ‰æ—¥æœŸé™åºæ’ï¼Œå»é‡å–ç¬¬ä¸€ä¸ª
    df = pd.read_sql("SELECT currency, rate, date FROM exchange_rates ORDER BY date DESC", conn)
    if df.empty:
        return {}
    # drop_duplicates é»˜è®¤ä¿ç•™ç¬¬ä¸€ä¸ªï¼Œä¹Ÿå°±æ˜¯æœ€æ–°çš„
    return df.drop_duplicates(subset=['currency']).set_index('currency')['rate'].to_dict()


# ==============================================================================
# ğŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šæ™ºèƒ½ç¼“å­˜åˆ†æå‡½æ•° (PCå®æ—¶ç®— / æ ‘è“æ´¾å­˜ç¡¬ç›˜)
# ==============================================================================

# 1. å®šä¹‰ç¯å¢ƒä¸ç­–ç•¥
IS_RASPBERRY_PI = os.path.exists('/share') # å¤ç”¨ä½ ä¹‹å‰çš„åˆ¤æ–­é€»è¾‘

if IS_RASPBERRY_PI:
    # ğŸ“ æ ‘è“æ´¾æ¨¡å¼ï¼šç¡¬ç›˜æŒä¹…åŒ–ï¼Œæ°¸ä¸è¿‡æœŸ (é™¤éæ‰‹åŠ¨ç‚¹åˆ·æ–°)
    # è¿™æ ·é‡å¯ Streamlit åä¾ç„¶ç§’å¼€
    CACHE_PARAMS = {
        "persist": "disk", 
        "ttl": None, 
        "show_spinner": "æ­£åœ¨ä»ç¡¬ç›˜è¯»å–å†å²æ•°æ® (æ ‘è“æ´¾æ¨¡å¼)..."
    }
else:
    # ğŸ’» PC å¼€å‘æ¨¡å¼ï¼šttl=0 ç­‰äºä¸ç¼“å­˜/ç«‹å³è¿‡æœŸ
    # æ¯æ¬¡åˆ·æ–°éƒ½é‡æ–°è®¡ç®—ï¼Œæ–¹ä¾¿ä½ è°ƒè¯•ä»£ç æˆ–æ•°æ®
    CACHE_PARAMS = {
        "persist": None, 
        "ttl": 0, 
        "show_spinner": "æ­£åœ¨å®æ—¶è®¡ç®— (PCå¼€å‘æ¨¡å¼)..."
    }

# 2. åº”ç”¨åŠ¨æ€å‚æ•°
@st.cache_data(**CACHE_PARAMS)
def get_cached_analytics_data(user_id):
    """
    æ›¿ä»£åŸæ¥çš„ process_analytics_dataï¼Œå¢åŠ äº†æ™ºèƒ½ç¼“å­˜æœºåˆ¶
    """
    # å»¶è¿ŸåŠ è½½é‡å‹åº“
    import pandas as pd
    import sqlite3
    
    # å‡½æ•°å†…éƒ¨å»ºç«‹è¿æ¥ (å› ä¸ºè¿æ¥å¯¹è±¡ä¸èƒ½è¢«ç¼“å­˜)
    local_conn = sqlite3.connect(DB_FILE)
    
    try:
        # --- åŸæœ‰é€»è¾‘å¼€å§‹ ---
        # 1. è·å–åŸºç¡€æ•°æ®
        df_raw = pd.read_sql('''
            SELECT s.date, s.asset_id, s.amount, s.profit, s.cost, s.yield_rate, a.name, a.currency, a.type
            FROM snapshots s
            JOIN assets a ON s.asset_id = a.asset_id
            WHERE a.user_id = ?
        ''', local_conn, params=(user_id,))

        if df_raw.empty:
            return None, None

        df_raw['date'] = pd.to_datetime(df_raw['date'])
        
        # 2. è·å–æ±‡ç‡è¡¨
        df_rates = pd.read_sql("SELECT date, currency, rate FROM exchange_rates", local_conn)
        df_rates['date'] = pd.to_datetime(df_rates['date'])
        
        # 3. æ±‡ç‡åŒ¹é…ä¸æŠ˜ç®—
        df_merged = pd.merge(df_raw, df_rates, on=['date', 'currency'], how='left')
        
        df_merged['rate'] = df_merged.apply(
            lambda row: 1.0 if row['currency'] == 'CNY' else row['rate'], axis=1
        )
        df_merged['rate'] = df_merged['rate'].fillna(1.0)
        
        df_merged['amount_cny'] = df_merged['amount'] * df_merged['rate']
        df_merged['profit_cny'] = df_merged['profit'] * df_merged['rate']
        df_merged['cost_cny'] = df_merged['cost'] * df_merged['rate']
        
        # 4. è·å–æ ‡ç­¾ (ğŸ”¥ æ¢å¤å…¨é‡æŸ¥è¯¢ï¼Œä¸åœ¨è¿™é‡Œå‰”é™¤ï¼Œä»¥å…å½±å“å…¶ä»–å›¾è¡¨)
        df_tags = pd.read_sql('''
            SELECT t.tag_group, t.tag_name, atm.asset_id
            FROM tags t
            JOIN asset_tag_map atm ON t.tag_id = atm.tag_id
            WHERE t.user_id = ?
        ''', local_conn, params=(user_id,))

        # --- ğŸ”¥ å‡†å¤‡å·¥ä½œï¼šè·å–â€œå·²æ¸…ä»“â€èµ„äº§ ID é›†åˆ ---
        # ä»…ç”¨äºä¸‹æ–¹çš„å®Œæ•´æ€§æ ¡éªŒé€»è¾‘
        cleared_assets_set = set()
        status_df = pd.read_sql('SELECT asset_id, is_cleared FROM snapshots ORDER BY date DESC', local_conn)
        if not status_df.empty:
            # è¿™é‡Œçš„ drop_duplicates ä¼šä¿ç•™æ¯ä¸ª asset_id çš„æœ€æ–°ä¸€æ¡è®°å½•
            latest_status = status_df.drop_duplicates(subset=['asset_id'])
            # æ‹¿åˆ°æ‰€æœ‰æœ€æ–°çŠ¶æ€ä¸º 1 (å·²æ¸…ä»“) çš„ ID
            cleared_assets_set = set(latest_status[latest_status['is_cleared'] == 1]['asset_id'].tolist())

        # 5. æ ‡ç­¾èšåˆè®¡ç®—
        tag_analytics = []
        if not df_tags.empty:
            merged_tags = pd.merge(df_merged, df_tags, on='asset_id', how='inner')
            
            # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šé¢„å…ˆè®¡ç®—æ¯ä¸ªæ ‡ç­¾ç»„ä¸‹ã€ç†è®ºä¸Šåº”è¯¥æœ‰å“ªäº›èµ„äº§ IDã€‘
            # å˜æˆå­—å…¸ï¼š{ ('èµ„äº§å¤§ç±»', 'åŸºé‡‘'): {1, 2, 3}, ... }
            tag_expected_ids_map = df_tags.groupby(['tag_group', 'tag_name'])['asset_id'].apply(set).to_dict()
            
            grouped = merged_tags.groupby(['date', 'tag_group', 'tag_name'])
            
            for name, group in grouped:
                date, tag_group, tag_name = name
                total_amount = group['amount_cny'].sum()
                total_profit = group['profit_cny'].sum()
                total_cost = group['cost_cny'].sum()
                weighted_yield = (total_profit / total_cost * 100) if total_cost != 0 else 0.0
                
                # --- ğŸ”¥ å¾®è°ƒåçš„æ ¡éªŒé€»è¾‘ ---
                # 1. ç†è®ºåº”æœ‰çš„èµ„äº§ ID é›†åˆ
                expected_ids = tag_expected_ids_map.get((tag_group, tag_name), set())
                # 2. å®é™…å½“æ—¥å½•å…¥çš„èµ„äº§ ID é›†åˆ
                current_ids = set(group['asset_id'])
                
                # 3. è®¡ç®—ç¼ºå¤±çš„ ID
                missing_ids = expected_ids - current_ids
                
                # 4. å…³é”®ä¸€æ­¥ï¼šä»ç¼ºå¤±åå•ä¸­ï¼Œå‰”é™¤æ‰é‚£äº›â€œå·²æ¸…ä»“â€çš„
                # å¦‚æœç¼ºå¤±çš„èµ„äº§æœ¬æ¥å°±æ˜¯å·²æ¸…ä»“çš„ï¼Œé‚£å°±ä¸ç®—ç¼ºå¤±
                real_missing_ids = missing_ids - cleared_assets_set
                
                tag_analytics.append({
                    'date': date, 'tag_group': tag_group, 'tag_name': tag_name,
                    'amount': total_amount, 'profit': total_profit, 'cost': total_cost,
                    'yield_rate': weighted_yield, 
                    # åªæœ‰å½“ã€çœŸæ­£ã€‘ç¼ºå¤±çš„æ•°é‡ä¸º 0 æ—¶ï¼Œæ‰ç®—å®Œæ•´
                    'is_complete': len(real_missing_ids) == 0,
                    'missing_count': len(real_missing_ids)
                })
                
        df_tags_agg = pd.DataFrame(tag_analytics)
        
        # æ„é€ è¿”å›
        df_final_assets = df_merged.copy()
        df_final_assets['amount'] = df_final_assets['amount_cny']
        df_final_assets['profit'] = df_final_assets['profit_cny']
        df_final_assets['cost'] = df_final_assets['cost_cny']
        
        return df_final_assets, df_tags_agg
        
    finally:
        local_conn.close()

# --- æ–°ç‰ˆçœ‹æ¿é¡µé¢ ---
def page_dashboard():
    # ğŸ‘‡ è¿™é‡Œè¦åŠ ä¸€å¤§å †
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    import numpy as np
    
    # è¡¥ä¸æŒªåˆ°è¿™é‡Œ
    if not hasattr(np, 'bool8'):
        np.bool8 = np.bool_
    st.header("ğŸ“Š æ·±åº¦èµ„äº§é€è§†")
    user_id = st.session_state.user['user_id']
    
    #conn = get_db_connection()
    ## å¤„ç†æ•°æ®
    #df_assets, df_tags = process_analytics_data(conn, user_id)
    #conn.close()

    df_assets, df_tags = get_cached_analytics_data(user_id)

    if df_assets is None or df_assets.empty:
        st.info("ğŸ‘‹ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆå‰å¾€ã€æ•°æ®å½•å…¥ã€‘é¡µé¢æ·»åŠ èµ„äº§å¿«ç…§ã€‚")
        return

# === ğŸ”¥ æ–°å¢ï¼šAI æŠ•é¡¾å…¥å£ ===
    with st.expander("ğŸ¤– AI æ™ºèƒ½æŠ•é¡¾ (ç¦»çº¿ç‰ˆ)", expanded=False):
        c_ai_1, c_ai_2 = st.columns([3, 1])
        with c_ai_1:
            st.markdown("""
            **åŠŸèƒ½è¯´æ˜**ï¼šé€‰æ‹©ä¸€ä¸ª **å¤ç›˜å‘¨æœŸ**ï¼Œç³»ç»Ÿå°†è®¡ç®—è¯¥æœŸé—´çš„èµ„äº§å˜åŠ¨ã€æœ€å¤§å›æ’¤å’ŒæœŸæœ«æŒä»“ç»“æ„ï¼Œç”Ÿæˆä¸“ä¸šçš„æç¤ºè¯å‘é€ç»™æ‚¨ã€‚
            """)
            
            ac1, ac2 = st.columns(2)
            
            # è·å–æ•°æ®ä¸­çš„æœ€æ—©å’Œæœ€æ™šæ—¥æœŸ
            min_db_date = df_assets['date'].min().date()
            max_db_date = df_assets['date'].max().date()
            
            with ac1:
                # ğŸ”¥ æ”¹ä¸ºæ—¥æœŸèŒƒå›´é€‰æ‹©å™¨
                ai_date_range = st.date_input(
                    "ğŸ“… é€‰æ‹©å¤ç›˜å‘¨æœŸ (å¼€å§‹ - ç»“æŸ)",
                    value=(min_db_date, max_db_date),
                    min_value=min_db_date,
                    max_value=max_db_date,
                    help="è¯·é€‰æ‹©å¼€å§‹æ—¥æœŸå’Œç»“æŸæ—¥æœŸ"
                )
            
            with ac2:
                ai_tag_groups = []
                if df_tags is not None and not df_tags.empty:
                    ai_tag_groups = df_tags['tag_group'].unique().tolist()
                
                selected_ai_group = st.selectbox("ğŸ“Š åˆ†æç»´åº¦", options=ai_tag_groups, index=0) if ai_tag_groups else "é»˜è®¤"

        with c_ai_2:
            st.write(""); st.write("") 
            # æ£€æŸ¥æ˜¯å¦é€‰äº†ä¸¤ä¸ªæ—¥æœŸ
            is_range_valid = isinstance(ai_date_range, tuple) and len(ai_date_range) == 2
            
            if st.button("ğŸ“§ å‘é€ Prompt", type="primary", use_container_width=True, disabled=(not ai_tag_groups or not is_range_valid)):
                if is_range_valid:
                    start_d, end_d = ai_date_range
                    with st.spinner("æ­£åœ¨ç”Ÿæˆåˆ†æ..."):
                        success, msg = generate_and_send_ai_prompt(
                            user_id, 
                            selected_ai_group, 
                            start_d.strftime('%Y-%m-%d'), 
                            end_d.strftime('%Y-%m-%d')
                        )
                        if success: st.success(msg)
                        else: st.error(msg)
                else:
                    st.warning("è¯·åœ¨æ—¥å†ä¸­é€‰æ‹©å®Œæ•´çš„ã€å¼€å§‹ã€‘å’Œã€ç»“æŸã€‘ä¸¤ä¸ªæ—¥æœŸã€‚")

    st.divider()
    # å…¨å±€æ—¥æœŸèŒƒå›´
    min_date = df_assets['date'].min().date()
    max_date = df_assets['date'].max().date()
    
    st.caption(f"æ•°æ®ç»Ÿè®¡èŒƒå›´ï¼š{min_date} ~ {max_date}")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ è¶‹åŠ¿åˆ†æ", "ğŸ° æ¯æ—¥é€è§†", "âš ï¸ æ•°æ®æ ¡éªŒ", "ğŸ† å¹´åº¦è´¢å¯Œå¤ç›˜"])
    
    # === TAB 1: è¶‹åŠ¿åˆ†æ (ä¼˜åŒ–ç‰ˆï¼šç½®é¡¶æ°´ä½ç›‘æ§) ===
    with tab1:
        st.subheader("ğŸ’° èµ„äº§å‡€å€¼èµ°åŠ¿")

       # =========================================================
        # ğŸŒŠ 0. å…¨å±€é£é™©ä¸æ°´ä½ç›‘æ§ (ç½®é¡¶)
        # é€»è¾‘è¯´æ˜ï¼š
        # 1. èµ„äº§ã€å›æ’¤ -> å–å†³äºã€æ€»èµ„äº§ã€‘(Snapshot Amount)
        # 2. ç´¯è®¡æ”¶ç›Š   -> å–å†³äºã€çœŸå®æ”¶ç›Šã€‘(Snapshot Amount - Cashflow Principal)
        # =========================================================
        
        # 1. å‡†å¤‡åŸºç¡€èµ„äº§æ•°æ® (æŒ‰æ—¥æœŸèšåˆ)
        daily_monitor = df_assets.groupby('date')[['amount']].sum().reset_index().sort_values('date')
        
        if not daily_monitor.empty:
            # --- A. å‡†å¤‡çœŸå®æœ¬é‡‘ (ä» Cashflows è®¡ç®—) ---
            conn_temp = get_db_connection()
            df_cf = pd.read_sql("SELECT date, type, amount FROM cashflows WHERE user_id = ?", conn_temp, params=(user_id,))
            conn_temp.close()
            
            # é»˜è®¤ä¸º 0 (å¦‚æœæ²¡æœ‰ç°é‡‘æµè®°å½•)
            daily_monitor['final_principal'] = 0.0
            
            if not df_cf.empty:
                df_cf['date'] = pd.to_datetime(df_cf['date'])
                # æ”¶å…¥=+ï¼Œæ”¯å‡º=-
                df_cf['net_flow'] = df_cf.apply(lambda x: x['amount'] if x['type'] == 'æ”¶å…¥' else -x['amount'], axis=1)
                
                # è®¡ç®—ç´¯è®¡å‡€æŠ•å…¥
                df_principal = df_cf.groupby('date')['net_flow'].sum().sort_index().cumsum().reset_index()
                df_principal.rename(columns={'net_flow': 'cumulative_principal'}, inplace=True)
                
                # åˆå¹¶ï¼šæ‰¾åˆ°æ¯ä¸€å¤©èµ„äº§å¯¹åº”çš„æœ€æ–°æœ¬é‡‘
                daily_monitor = pd.merge_asof(daily_monitor, df_principal, on='date', direction='backward')
                daily_monitor['final_principal'] = daily_monitor['cumulative_principal'].fillna(0)
            
            # --- B. è®¡ç®—æ ¸å¿ƒåºåˆ— ---
            # åºåˆ—1: æ€»èµ„äº§ (ç”¨äºè®¡ç®—æ°´ä½ã€å›æ’¤)
            asset_series = daily_monitor.set_index('date')['amount']
            
            # åºåˆ—2: çœŸå®ç´¯è®¡æ”¶ç›Š (ç”¨äºè®¡ç®—æ”¶ç›Šåˆ›æ–°é«˜) = æ€»èµ„äº§ - ç°é‡‘æµæœ¬é‡‘
            # æ³¨æ„ï¼šè¿™é‡Œä¸å†ä½¿ç”¨å¿«ç…§é‡Œçš„ profitï¼Œè€Œæ˜¯å®æ—¶é‡ç®—
            monitor_profit_series = asset_series - daily_monitor.set_index('date')['final_principal']

            # --- C. è®¡ç®—å…­å¤§æŒ‡æ ‡ ---
            
            # 1. èµ„äº§æŒ‡æ ‡
            curr_asset = asset_series.iloc[-1]
            ath_asset = asset_series.max()
            
            # 2. å›æ’¤æŒ‡æ ‡ (åŸºäºæ€»èµ„äº§)
            rolling_max = asset_series.cummax()
            drawdown_amt = rolling_max - asset_series
            drawdown_pct = (drawdown_amt / rolling_max * 100).fillna(0.0)
            
            curr_dd_pct = drawdown_pct.iloc[-1]
            curr_dd_amt = drawdown_amt.iloc[-1]
            max_dd_pct = drawdown_pct.max()
            max_dd_amt = drawdown_amt.max()
            
            # 3. æ”¶ç›ŠæŒ‡æ ‡ (åŸºäºçœŸå®æ”¶ç›Š)
            curr_profit = monitor_profit_series.iloc[-1]
            ath_profit = monitor_profit_series.max() # å†å²æœ€é«˜ç´¯è®¡æ”¶ç›Š

            # --- D. ç•Œé¢å±•ç¤º ---
            with st.container():
                m1, m2, m3, m4, m5, m6 = st.columns(6)
                
                # 1. å½“å‰æ€»èµ„äº§
                m1.metric("å½“å‰æ€»èµ„äº§", f"Â¥{curr_asset/10000:,.2f}ä¸‡")
                
                # 2. å†å²æœ€é«˜ (ATH)
                m2.metric("å†å²æœ€é«˜ (ATH)", f"Â¥{ath_asset/10000:,.2f}ä¸‡", 
                          delta=f"è·é«˜ç‚¹ -{(ath_asset-curr_asset)/10000:.2f}ä¸‡" if curr_asset < ath_asset else "åˆ›æ–°é«˜!",
                          delta_color="inverse")
                
                # 3. å½“å‰å›æ’¤
                m3.metric("å½“å‰æ€»èµ„äº§å›æ’¤", f"{curr_dd_pct:.2f}%", 
                          delta=f"-Â¥{curr_dd_amt:,.0f}", 
                          delta_color="inverse")
                
                # 4. å†å²æœ€å¤§å›æ’¤
                m4.metric("å†å²æœ€å¤§å›æ’¤", f"{max_dd_pct:.2f}%", 
                          delta=f"-Â¥{max_dd_amt:,.0f}",
                          delta_color="inverse")

                # 5. å½“å‰ç´¯è®¡æ”¶ç›Š (ä¿®æ­£ç‰ˆ)
                m5.metric("å½“å‰ç´¯è®¡æ”¶ç›Š", f"Â¥{curr_profit/10000:,.2f}ä¸‡",
                          delta_color="normal" if curr_profit > 0 else "inverse")
                
                # 6. å†å²æœ€é«˜æ”¶ç›Š (ä¿®æ­£ç‰ˆ)
                m6.metric("å†å²æœ€é«˜æ”¶ç›Š", f"Â¥{ath_profit/10000:,.2f}ä¸‡",
                          help="å†å²ä¸Šã€æ€»èµ„äº§ - æœ¬é‡‘ã€‘å·®å€¼çš„æœ€å¤§å€¼")
                
            st.divider()

        # =========================================================
        # ğŸ“‰ 1. è§†å›¾æ¨¡å¼é€‰æ‹© & å›¾è¡¨ç»˜åˆ¶
        # =========================================================
        
        chart_mode = st.radio(
            "ğŸ“‰ ç»Ÿè®¡å£å¾„", 
            [
                "1. æ€»èµ„äº§æ¨¡å¼", 
                "2. å‰”é™¤ç°é‡‘ (ä»…çœ‹æŠ•èµ„ä»“ä½)",
                "3. æŠ•å…¥æœ¬é‡‘/æ”¶ç›Šæ¨¡å¼"
            ], 
            horizontal=True,
            help="â‘ æ€»èµ„äº§æ¨¡å¼: å…¨å£å¾„ç»Ÿè®¡\nâ‘¡å‰”é™¤ç°é‡‘: åªçœ‹æ³¢åŠ¨èµ„äº§\nâ‘¢æ”¶ç›Šæ¨¡å¼: é‡ç‚¹ç›‘æ§ã€ç´¯è®¡æ”¶ç›Šã€‘çš„åˆ›æ–°é«˜ä¸å›æ’¤æƒ…å†µ"
        )
        
        # å‡†å¤‡ç”»å¸ƒ
        fig_total = go.Figure()
        
        # ... (ä»¥ä¸‹ç»˜å›¾é€»è¾‘ä¿æŒä¸å˜ï¼Œä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œç›´æ¥å¤ç”¨ä¹‹å‰çš„é€»è¾‘) ...
        # =========================================================
        # æ¨¡å¼ 3ï¼šè´¦æˆ·å…¨è²Œ (åŸºäº Cashflow ç®—æœ¬é‡‘)
        # =========================================================
        if "3." in chart_mode:
            # A. å‡†å¤‡èµ„äº§æ€»é¢
            daily_assets = df_assets.groupby('date')[['amount']].sum().reset_index().sort_values('date')
            
            # B. å‡†å¤‡æœ¬é‡‘ (Cashflows)
            conn_temp = get_db_connection()
            df_cf = pd.read_sql("SELECT date, type, amount FROM cashflows WHERE user_id = ?", conn_temp, params=(user_id,))
            conn_temp.close()
            
            use_cf_data = False
            if not df_cf.empty:
                df_cf['date'] = pd.to_datetime(df_cf['date'])
                df_cf['net_flow'] = df_cf.apply(lambda x: x['amount'] if x['type'] == 'æ”¶å…¥' else -x['amount'], axis=1)
                df_principal = df_cf.groupby('date')['net_flow'].sum().sort_index().cumsum().reset_index()
                df_principal.rename(columns={'net_flow': 'cumulative_principal'}, inplace=True)
                daily_assets = pd.merge_asof(daily_assets, df_principal, on='date', direction='backward')
                daily_assets['final_principal'] = daily_assets['cumulative_principal'].fillna(0)
                use_cf_data = True
            else:
                st.warning("âš ï¸ æš‚æ— ç°é‡‘æµï¼Œé™çº§ä½¿ç”¨ Cost å­—æ®µã€‚")
                temp_group = df_assets.groupby('date')['cost'].sum().reset_index()
                daily_assets = pd.merge(daily_assets, temp_group, on='date', how='left')
                daily_assets['final_principal'] = daily_assets['cost']

            # C. è®¡ç®—å…³é”®æŒ‡æ ‡
            daily_assets['profit'] = daily_assets['amount'] - daily_assets['final_principal']
            
            # D. ç»˜å›¾
            daily_assets['p_w'] = daily_assets['final_principal'] / 10000
            daily_assets['a_w'] = daily_assets['amount'] / 10000
            daily_assets['prof_w'] = daily_assets['profit'] / 10000
            
            fig_total.add_trace(go.Scatter(x=daily_assets['date'], y=daily_assets['a_w'], name='æ€»èµ„äº§', mode='lines',fill='tozeroy', line=dict(color='#2E86C1', width=3), hovertemplate='æ€»èµ„äº§: %{y:.2f}ä¸‡<extra></extra>'))
            fig_total.add_trace(go.Scatter(x=daily_assets['date'], y=daily_assets['p_w'], name='æŠ•å…¥æœ¬é‡‘', mode='lines', line=dict(color='#95A5A6', width=2), hovertemplate='æœ¬é‡‘: %{y:.2f}ä¸‡<extra></extra>'))
            fig_total.add_trace(go.Scatter(x=daily_assets['date'], y=daily_assets['prof_w'], name='ç´¯è®¡æ”¶ç›Š', mode='lines', line=dict(color='#27AE60', width=2, dash='dot'), hovertemplate='æ”¶ç›Š: %{y:.2f}ä¸‡<extra></extra>'))

        # =========================================================
        # æ¨¡å¼ 1 & 2ï¼šç»å…¸è§†å›¾ (è¡¥å……äº†æ”¶ç›Šé‡‘é¢æ›²çº¿)
        # =========================================================
        else:
            plot_df = df_assets.copy()
            
            # ç‰¹æ®Šå¤„ç†ï¼šå‰”é™¤ç°é‡‘
            if "2." in chart_mode:
                if 'type' in plot_df.columns:
                    plot_df = plot_df[plot_df['type'] != 'ç°é‡‘']
                else:
                    st.error("æ•°æ®åº“ç¼ºå°‘ type å­—æ®µã€‚")

            # èšåˆ
            daily_simple = plot_df.groupby('date')[['amount', 'profit', 'cost']].sum().reset_index().sort_values('date')
            
            # è®¡ç®—ç»˜å›¾æ•°æ®
            daily_simple['yield_rate'] = daily_simple.apply(lambda row: (row['profit'] / row['cost'] * 100) if row['cost'] != 0 else 0.0, axis=1)
            daily_simple['amt_w'] = daily_simple['amount'] / 10000
            daily_simple['prof_w'] = daily_simple['profit'] / 10000  # ğŸ”¥ æ–°å¢ï¼šæ”¶ç›Šé‡‘é¢(ä¸‡)
            
            # ç»˜å›¾
            line_color = '#2E86C1'
            
            # 1. èµ„äº§å¸‚å€¼ (é¢ç§¯å›¾)
            fig_total.add_trace(go.Scatter(
                x=daily_simple['date'], y=daily_simple['amt_w'], 
                name="èµ„äº§å¸‚å€¼", mode='lines', fill='tozeroy', 
                line=dict(color=line_color, width=2), 
                hovertemplate='å¸‚å€¼: %{y:.2f}ä¸‡<extra></extra>'
            ))
            
            # 2. æŒæœ‰æ”¶ç›Š (ç»¿è‰²è™šçº¿) -> ğŸ”¥ è¿™å°±æ˜¯ä½ æƒ³è¦è¡¥å……çš„
            fig_total.add_trace(go.Scatter(
                x=daily_simple['date'], y=daily_simple['prof_w'], 
                name='æŒæœ‰æ”¶ç›Š', mode='lines', 
                line=dict(color='#27AE60', width=2, dash='dot'), 
                hovertemplate='æ”¶ç›Š: %{y:.2f}ä¸‡<extra></extra>'
            ))
            
            # 3. æ”¶ç›Šç‡ (å³è½´ï¼Œçº¢è‰²è™šçº¿)
            fig_total.add_trace(go.Scatter(
                x=daily_simple['date'], y=daily_simple['yield_rate'], 
                name='æ”¶ç›Šç‡', mode='lines', 
                line=dict(color='#E74C3C', width=1, dash='dot'), #ç¨å¾®è°ƒç»†ä¸€ç‚¹åŒºåˆ†
                yaxis='y2', 
                hovertemplate='æ”¶ç›Šç‡: %{y:.2f}%<extra></extra>'
            ))
            
            # é…ç½®åŒè½´
            fig_total.update_layout(
                yaxis2=dict(
                    title=dict(text="æ”¶ç›Šç‡ (%)", font=dict(color="#E74C3C")), 
                    tickfont=dict(color="#E74C3C"), 
                    overlaying='y', 
                    side='right'
                )
            )
        # --- å›¾è¡¨å¸ƒå±€ä¸å¯¼å‡º ---
        fig_total.update_layout(
            hovermode="x unified",
            yaxis=dict(title="é‡‘é¢ (ä¸‡å…ƒ)"),
            # x=0, xanchor="left" è¡¨ç¤ºå·¦å¯¹é½ï¼›y=1.02 è¡¨ç¤ºåœ¨å›¾è¡¨ä¸Šæ–¹ä¸€ç‚¹ç‚¹
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0),
            margin=dict(l=0, r=0, t=30, b=0) # ç¨å¾®å¢åŠ é¡¶éƒ¨ t çš„ç•™ç™½ï¼Œé˜²æ­¢é¡¶åˆ°å¤´
        )
        st.plotly_chart(fig_total, use_container_width=True)

        st.download_button(
            label=f"ğŸ“¥ å¯¼å‡ºæ•°æ®", 
            data=pd.DataFrame().to_csv().encode('utf-8-sig'), 
            file_name=f'trend_export.csv', 
            mime='text/csv'
        )

        st.divider()

        # --- 3. ç»“æ„åŒ–è¶‹åŠ¿è¯¦ç»†å¯¹æ¯” ---
        st.subheader("ğŸ“Š ç»“æ„åŒ–è¶‹åŠ¿è¯¦ç»†å¯¹æ¯”")
        
        c1, c2, c3 = st.columns([1, 1, 2])
        with c1:
            view_mode = st.radio("åˆ†æç»´åº¦", ["æŒ‰å…·ä½“èµ„äº§", "æŒ‰æ ‡ç­¾ç»„"], horizontal=True, key="trend_view")
        with c2:
            metric_type = st.selectbox("ç”»å›¾æŒ‡æ ‡ (Yè½´)", ["æ€»é‡‘é¢ (Amount)", "æŒæœ‰æ”¶ç›Š (Profit)", "æ”¶ç›Šç‡ (Yield %)", "å æ¯” (Share %)"], key="trend_metric")
        with c3:
            tooltip_extras = st.multiselect("ğŸ–±ï¸ æ‚¬åœæ˜¾ç¤ºé¢å¤–æŒ‡æ ‡", ["æ€»é‡‘é¢", "æŒæœ‰æ”¶ç›Š", "æœ¬é‡‘", "æ”¶ç›Šç‡", "å æ¯”"], default=["å æ¯”", "æŒæœ‰æ”¶ç›Š", "æ”¶ç›Šç‡"], key="trend_tooltip")

        plot_df = None
        color_col = ""
        
        
        if view_mode == "æŒ‰å…·ä½“èµ„äº§":
            plot_df = df_assets.copy()
            color_col = "name"
            
            # --- ğŸ”¥ å‡çº§ç‰ˆç­›é€‰å™¨ (å…³é”®å­— + æ ‡ç­¾ç»„è”åŠ¨) ---
            st.markdown("##### ğŸ” èµ„äº§ç²¾å‡†ç­›é€‰")
            
            # 1. å¸ƒå±€ï¼šä¸‰åˆ—ç­›é€‰ (å…³é”®å­— | æ ‡ç­¾ç»„ | æ ‡ç­¾å)
            f_col1, f_col2, f_col3 = st.columns([2, 2, 2])
            
            with f_col1:
                # 1. å…³é”®å­—è¾“å…¥
                filter_kw = st.text_input("1. å…³é”®å­— (åç§°/ä»£ç )", placeholder="æœè‚¡ç¥¨ã€åŸºé‡‘...", key="trend_kw")
            
            # å‡†å¤‡æ ‡ç­¾æ•°æ® (éœ€è¦ä¸´æ—¶è¿æ¥æŸ¥ä¸€ä¸‹æœ€æ–°çš„æ ‡ç­¾å…³ç³»)
            conn_temp = get_db_connection()
            try:
                # æŸ¥å‡ºæ‰€æœ‰æ ‡ç­¾åŠå…¶å…³è”çš„èµ„äº§ID
                df_tag_map = pd.read_sql('''
                    SELECT t.tag_group, t.tag_name, atm.asset_id 
                    FROM tags t
                    JOIN asset_tag_map atm ON t.tag_id = atm.tag_id
                    WHERE t.user_id = ?
                ''', conn_temp, params=(user_id,))
            finally:
                conn_temp.close()

            with f_col2:
                # 2. æ ‡ç­¾ç»„é€‰æ‹©
                if not df_tag_map.empty:
                    all_groups = sorted(df_tag_map['tag_group'].unique().tolist())
                    sel_filter_group = st.selectbox("2. ç­›é€‰æ ‡ç­¾ç»„", ["(å…¨éƒ¨)"] + all_groups, key="trend_f_group")
                else:
                    sel_filter_group = "(å…¨éƒ¨)"
                    st.selectbox("2. ç­›é€‰æ ‡ç­¾ç»„", ["(æ— æ ‡ç­¾æ•°æ®)"], disabled=True, key="trend_f_group_empty")
                    
            with f_col3:
                # 3. æ ‡ç­¾åé€‰æ‹© (æ ¹æ®é€‰ä¸­çš„ç»„åŠ¨æ€å˜åŒ–)
                if sel_filter_group != "(å…¨éƒ¨)" and not df_tag_map.empty:
                    available_tags = sorted(df_tag_map[df_tag_map['tag_group'] == sel_filter_group]['tag_name'].unique().tolist())
                    sel_filter_tag = st.selectbox("3. ç­›é€‰æ ‡ç­¾å", ["(å…¨éƒ¨)"] + available_tags, key="trend_f_tag")
                else:
                    sel_filter_tag = "(å…¨éƒ¨)"
                    st.selectbox("3. ç­›é€‰æ ‡ç­¾å", ["(å…ˆé€‰æ ‡ç­¾ç»„)"], disabled=True, key="trend_f_tag_disabled")

            # --- 2. æ‰§è¡Œç­›é€‰é€»è¾‘ (æ±‚äº¤é›†ï¼šAND å…³ç³») ---
            # åˆå§‹å€™é€‰æ± ï¼šæ‰€æœ‰å†å²å‡ºç°è¿‡çš„èµ„äº§ID
            valid_asset_ids = set(plot_df['asset_id'].unique())

            # A. æ ‡ç­¾ç­›é€‰
            if sel_filter_group != "(å…¨éƒ¨)" and not df_tag_map.empty:
                # æ‰¾å‡ºç¬¦åˆç»„çš„èµ„äº§ID
                target_map = df_tag_map[df_tag_map['tag_group'] == sel_filter_group]
                if sel_filter_tag != "(å…¨éƒ¨)":
                    target_map = target_map[target_map['tag_name'] == sel_filter_tag]
                
                tag_matched_ids = set(target_map['asset_id'])
                # æ±‚äº¤é›†ï¼šæ—¢è¦åœ¨å†å²æ•°æ®é‡Œï¼Œåˆå¾—ç¬¦åˆæ ‡ç­¾
                valid_asset_ids = valid_asset_ids.intersection(tag_matched_ids)
            
            # B. å…³é”®å­—ç­›é€‰
            if filter_kw:
                # ä» plot_df ä¸­æ‰¾åŒ¹é… Name æˆ– Code çš„
                kw_matched = plot_df[
                    plot_df['name'].str.contains(filter_kw, case=False) | 
                    plot_df['code'].str.contains(filter_kw, case=False, na=False)
                ]
                kw_matched_ids = set(kw_matched['asset_id'])
                # æ±‚äº¤é›†ï¼šå¿…é¡»åŒæ—¶ä¹Ÿæ»¡è¶³å…³é”®å­—
                valid_asset_ids = valid_asset_ids.intersection(kw_matched_ids)
                
            # --- 3. ç”Ÿæˆæœ€ç»ˆå€™é€‰é¡¹ ---
            # ä»…æå–ç¬¦åˆæ¡ä»¶çš„èµ„äº§åç§°ä¾›é€‰æ‹©
            asset_meta = plot_df[['asset_id', 'name']].drop_duplicates()
            asset_meta = asset_meta[asset_meta['asset_id'].isin(valid_asset_ids)]
            available_names = sorted(asset_meta['name'].unique().tolist())
            
            if not available_names:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆä¸Šè¿°æ¡ä»¶çš„èµ„äº§ï¼Œè¯·è°ƒæ•´ç­›é€‰ã€‚")
                plot_df = pd.DataFrame() # ç©ºè¡¨é˜²æŠ¥é”™
            else:
                # 4. æœ€ç»ˆé€‰æ‹©æ¡† (Options æ˜¯ç»è¿‡å±‚å±‚ç­›é€‰åçš„ç»“æœ)
                selected_assets = st.multiselect(
                    f"4. å‹¾é€‰è¦å¯¹æ¯”çš„èµ„äº§ (ç­›é€‰åå¯é€‰ {len(available_names)} ä¸ª)",
                    options=available_names,
                    placeholder="ç•™ç©ºåˆ™æ˜¾ç¤ºç­›é€‰å‡ºçš„ã€æ‰€æœ‰ã€‘èµ„äº§...",
                    key="trend_final_select"
                )
                
                # é€»è¾‘ï¼š
                # å¦‚æœå‹¾é€‰äº†ç‰¹å®šèµ„äº§ -> åªçœ‹å‹¾é€‰çš„
                # å¦‚æœç•™ç©º -> æ˜¾ç¤ºç¬¦åˆå‰é¢ç­›é€‰æ¡ä»¶çš„æ‰€æœ‰èµ„äº§ (æ¯”å¦‚çœ‹äº†æ‰€æœ‰â€œç¾è‚¡â€)
                if selected_assets:
                    plot_df = plot_df[plot_df['name'].isin(selected_assets)]
                else:
                    plot_df = plot_df[plot_df['asset_id'].isin(valid_asset_ids)]
                
        else: 
            if df_tags is None or df_tags.empty:
                st.warning("æš‚æ— æ ‡ç­¾æ•°æ®ã€‚")
            else:
                groups = df_tags['tag_group'].unique()
                selected_group = st.selectbox("é€‰æ‹©æ ‡ç­¾åˆ†ç»„", groups, key="trend_group")
                plot_df = df_tags[df_tags['tag_group'] == selected_group].copy()
                color_col = "tag_name"

        if plot_df is not None:
            # é¢„è®¡ç®—ç»˜å›¾å­—æ®µ
            plot_df['amt_w'] = plot_df['amount'] / 10000
            plot_df['prof_w'] = plot_df['profit'] / 10000
            plot_df['cost_w'] = plot_df['cost'] / 10000
            daily_sums = plot_df.groupby('date')['amount'].transform('sum')
            plot_df['share'] = (plot_df['amount'] / daily_sums * 100).fillna(0)

            # å†³å®š Y è½´
            y_col, y_unit, y_title = "amt_w", "w", "é‡‘é¢ (ä¸‡)"
            if metric_type.startswith("æŒæœ‰æ”¶ç›Š"): y_col, y_unit, y_title = "prof_w", "w", "æ”¶ç›Š (ä¸‡)"
            elif metric_type.startswith("æ”¶ç›Šç‡"): y_col, y_unit, y_title = "yield_rate", "%", "æ”¶ç›Šç‡ (%)"
            elif metric_type.startswith("å æ¯”"): y_col, y_unit, y_title = "share", "%", "å æ¯” (%)"

            # ç»˜å›¾
            custom_data_cols = ['amt_w', 'prof_w', 'cost_w', 'yield_rate', 'share']
            fig = px.line(plot_df, x='date', y=y_col, color=color_col, markers=True, custom_data=custom_data_cols)
            
            # å®šåˆ¶ tooltip
            hover_html = f"<b>%{{fullData.name}}</b>: <b>{metric_type.split(' ')[0]}:%{{y:.2f}}{y_unit}</b>"
            extra_info = []
            if "æ€»é‡‘é¢" in tooltip_extras: extra_info.append("ğŸ’°%{customdata[0]:.2f}w")
            if "æŒæœ‰æ”¶ç›Š" in tooltip_extras: extra_info.append("ğŸ“ˆ%{customdata[1]:.2f}w")
            if "æœ¬é‡‘" in tooltip_extras: extra_info.append("ğŸŒ±%{customdata[2]:.2f}w")
            if "æ”¶ç›Šç‡" in tooltip_extras: extra_info.append("ğŸš€%{customdata[3]:.1f}%")
            if "å æ¯”" in tooltip_extras: extra_info.append("ğŸ°%{customdata[4]:.1f}%")
            if extra_info: hover_html += "<br>" + "   ".join(extra_info)
            hover_html += "<extra></extra>"
            
            fig.update_traces(hovertemplate=hover_html)
            fig.update_layout(hovermode="x unified", yaxis_title=y_title, legend_title_text="")
            st.plotly_chart(fig, use_container_width=True)

            csv_struct = plot_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(label=f"ğŸ“¥ å¯¼å‡ºå½“å‰ç­›é€‰æ•°æ® ({view_mode})", data=csv_struct, file_name=f'trend_structure.csv', mime='text/csv')

            # =========================================================
            # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šåˆ†ç»„æŸ±çŠ¶å›¾å¯¹æ¯” (ç¾åŒ– Tooltip ç‰ˆ)
            # =========================================================
            st.divider()
            st.subheader("ä¸¤æœŸæ•°æ®æ¨ªå‘æ¯”å¯¹")
            st.caption(f"å¯¹æ¯”ç»´åº¦ï¼š**{view_mode}** | ç›´è§‚å±•ç¤ºä¸¤ä¸ªæ—¶é—´ç‚¹çš„æ•°å€¼å˜åŒ–")
            # è·å–æœ‰æ•ˆæ—¥æœŸèŒƒå›´ä¾›ç»„ä»¶é™åˆ¶
            valid_min = plot_df['date'].min().date()
            valid_max = plot_df['date'].max().date()
            
            with st.container():
                dc1, dc2, dc3 = st.columns([2, 2, 3])
                with dc1:
                    # ğŸ”¥ æ”¹ä¸º date_input
                    d1_input = st.date_input("ğŸ“… æ—¥æœŸ A (æ—§)", value=valid_min, min_value=valid_min, max_value=valid_max, key="diff_d1")
                with dc2:
                    # ğŸ”¥ æ”¹ä¸º date_input
                    d2_input = st.date_input("ğŸ“… æ—¥æœŸ B (æ–°)", value=valid_max, min_value=valid_min, max_value=valid_max, key="diff_d2")
                with dc3:
                    diff_metric = st.radio("å¯¹æ¯”æŒ‡æ ‡", ["æ€»é‡‘é¢ (Amount)", "æŒæœ‰æ”¶ç›Š (Profit)", "æ”¶ç›Šç‡ (Yield %)", "å æ¯” (Share %)"], horizontal=True)

            # è½¬æ¢ input ä¸º datetime ä»¥ä¾¿å’Œ dataframe æ¯”è¾ƒ
            d1_ts = pd.Timestamp(d1_input)
            d2_ts = pd.Timestamp(d2_input)

            # æ£€æŸ¥æ‰€é€‰æ—¥æœŸæ˜¯å¦æœ‰æ•°æ®
            has_d1 = not plot_df[plot_df['date'] == d1_ts].empty
            has_d2 = not plot_df[plot_df['date'] == d2_ts].empty

            if d1_ts == d2_ts:
                st.info("è¯·é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æ—¥æœŸã€‚")
            elif not has_d1 or not has_d2:
                st.warning(f"æ‰€é€‰æ—¥æœŸæ— æ•°æ®ã€‚è¯·ç¡®ä¿é€‰ä¸­çš„æ—¥æœŸ ({d1_input} æˆ– {d2_input}) æœ‰èµ„äº§å¿«ç…§è®°å½•ã€‚")
            else:
                # ... (åŸæ¥çš„ç»˜å›¾é€»è¾‘å®Œå…¨ä¸ç”¨åŠ¨ï¼Œåªéœ€è¦æŠŠåŸæ¥çš„ d1, d2 å˜é‡æ›¿æ¢æˆ d1_ts, d2_ts) ...
                if "æ€»é‡‘é¢" in diff_metric: val_col = "amount"; unit_suffix = "å…ƒ"
                elif "æŒæœ‰æ”¶ç›Š" in diff_metric: val_col = "profit"; unit_suffix = "å…ƒ"
                elif "æ”¶ç›Šç‡" in diff_metric: val_col = "yield_rate"; unit_suffix = "%"
                elif "å æ¯”" in diff_metric: val_col = "share"; unit_suffix = "%"

                df_d1 = plot_df[plot_df['date'] == d1_ts].copy() # ä½¿ç”¨ ts
                df_d1['Period'] = d1_ts.strftime('%Y-%m-%d')
                
                df_d2 = plot_df[plot_df['date'] == d2_ts].copy() # ä½¿ç”¨ ts
                df_d2['Period'] = d2_ts.strftime('%Y-%m-%d')
                
                df_viz = pd.concat([df_d1, df_d2], ignore_index=True)
                
                # ... (åç»­ç»˜å›¾ä»£ç ä¿æŒä¸å˜ï¼Œç›´åˆ° Tab 2) ...
                rank_order = df_d2.sort_values(val_col, ascending=False)[color_col].tolist()
                fig_compare = px.bar(
                    df_viz, x=color_col, y=val_col, color='Period', barmode='group', 
                    title=f"{diff_metric} å¯¹æ¯”: {d1_ts.strftime('%m-%d')} vs {d2_ts.strftime('%m-%d')}",
                    category_orders={color_col: rank_order}, text_auto='.2s' if unit_suffix == "å…ƒ" else '.2f'
                )
                # ... (Tooltip ä»£ç ä¸å˜) ...
                metric_label = diff_metric.split(' ')[0]
                if unit_suffix == "å…ƒ":
                    hover_template = f"<b>%{{x}}</b><br>ğŸ“… %{{fullData.name}}<br>{metric_label}: <b>Â¥%{{y:,.2f}}</b><extra></extra>"
                else:
                    hover_template = f"<b>%{{x}}</b><br>ğŸ“… %{{fullData.name}}<br>{metric_label}: <b>%{{y:.2f}}%</b><extra></extra>"
                fig_compare.update_traces(hovertemplate=hover_template)
                fig_compare.update_layout(yaxis_title=diff_metric, xaxis_title="", legend_title_text="", hovermode="x unified")
                st.plotly_chart(fig_compare, use_container_width=True)

                with st.expander(f"æŸ¥çœ‹ {diff_metric} å…·ä½“å˜åŠ¨æ•°å€¼"):
                    df_pivot = df_viz.pivot(index=color_col, columns='Period', values=val_col).reset_index()
                    d1_str = d1_ts.strftime('%Y-%m-%d')
                    d2_str = d2_ts.strftime('%Y-%m-%d')
                    df_pivot = df_pivot.fillna(0)
                    df_pivot['å˜åŠ¨é‡'] = df_pivot[d2_str] - df_pivot[d1_str]
                    df_pivot = df_pivot.sort_values(d2_str, ascending=False)
                    st.dataframe(df_pivot, hide_index=True, use_container_width=True)

    # === TAB 2: æ¯æ—¥é€è§† (å·²å‡çº§ä¸ºæ—¥å†ç»„ä»¶) ===
    with tab2:
        st.subheader("ğŸ° æ¯æ—¥èµ„äº§å¿«ç…§åˆ†æ")
        
        # 1. é¡¶éƒ¨æ§åˆ¶æ 
        control_c1, control_c2 = st.columns(2)
        with control_c1:
            # è·å–æ•°æ®ä¸­çš„æ—¥æœŸèŒƒå›´ï¼Œé™åˆ¶æ—¥å†é€‰æ‹©å™¨çš„ä¸Šä¸‹é™
            default_date = df_assets['date'].max().date()
            min_date = df_assets['date'].min().date()
            
            # ğŸ”¥ ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨ date_input æ—¥å†ç»„ä»¶
            selected_date_input = st.date_input(
                "ğŸ“… é€‰æ‹©è¦æŸ¥çœ‹çš„æ—¥æœŸ", 
                value=default_date,
                min_value=min_date,
                max_value=default_date,
                help="ç‚¹å‡»å³ä¾§æ—¥å†å›¾æ ‡é€‰æ‹©æ—¥æœŸ"
            )
            # å…³é”®ï¼šå°† date ç±»å‹è½¬ä¸º pandas çš„ Timestampï¼Œå¦åˆ™è·Ÿæ•°æ®åº“çš„æ—¶é—´æ ¼å¼å¯¹ä¸ä¸Š
            selected_date = pd.Timestamp(selected_date_input)
        
        with control_c2:
            # ç»´åº¦é€‰æ‹©å™¨
            tag_groups = list(df_tags['tag_group'].unique()) if (df_tags is not None and not df_tags.empty) else []
            dim_options = ["æŒ‰å…·ä½“èµ„äº§"] + tag_groups
            selected_dim = st.selectbox("ğŸ” åˆ†æç»´åº¦ (ç­›é€‰æ ‡ç­¾ç»„)", dim_options)

        st.divider()

        # 2. æ•°æ®å‡†å¤‡ä¸æ ¡éªŒ
        # æ£€æŸ¥é€‰ä¸­çš„è¿™ä¸€å¤©åˆ°åº•æœ‰æ²¡æœ‰æ•°æ®
        if selected_dim == "æŒ‰å…·ä½“èµ„äº§":
            # ç­›é€‰ assets è¡¨
            day_data = df_assets[df_assets['date'] == selected_date].copy()
            name_col = 'name'
        else:
            # ç­›é€‰ tags è¡¨
            if df_tags is None:
                day_data = pd.DataFrame()
            else:
                day_data = df_tags[
                    (df_tags['date'] == selected_date) & 
                    (df_tags['tag_group'] == selected_dim)
                ].copy()
                name_col = 'tag_name'

        # 3. å¦‚æœå½“å¤©æ— æ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºï¼›æœ‰æ•°æ®åˆ™æ˜¾ç¤ºå›¾è¡¨
        if day_data.empty:
            st.warning(f"ğŸ“… {selected_date_input} å½“å¤©æ²¡æœ‰å½•å…¥æ•°æ®ã€‚è¯·å°è¯•é€‰æ‹©å…¶ä»–æ—¥æœŸã€‚")
        else:
            # --- é¢„è®¡ç®—è¾…åŠ©åˆ— (ç”¨äº Tooltip æ˜¾ç¤º 'ä¸‡') ---
            day_data['amount_w'] = day_data['amount'] / 10000
            day_data['profit_w'] = day_data['profit'] / 10000

            # --- A. æ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡ ---
            day_total_amt = day_data['amount'].sum()
            day_total_profit = day_data['profit'].sum()
            
            m1, m2, m3 = st.columns(3)
            with m1:
                st.metric("å½“æ—¥æ€»èµ„äº§", f"Â¥{day_total_amt/10000:,.2f}ä¸‡")
            with m2:
                st.metric("å½“æ—¥æŒæœ‰æ”¶ç›Š", f"Â¥{day_total_profit/10000:,.2f}ä¸‡", 
                          delta_color="normal" if day_total_profit >= 0 else "inverse")
            with m3:
                # è®¡ç®—å½“å¤©çš„ç»¼åˆæ”¶ç›Šç‡
                # é€»è¾‘ï¼šæ”¶ç›Š / (æ€»èµ„äº§ - æ”¶ç›Š) = æ”¶ç›Š / æœ¬é‡‘
                total_cost = day_total_amt - day_total_profit
                if total_cost != 0:
                     total_yield = (day_total_profit / total_cost) * 100
                     m3.metric("å½“æ—¥ç»¼åˆæ”¶ç›Šç‡", f"{total_yield:.2f}%")
                else:
                     m3.metric("å½“æ—¥ç»¼åˆæ”¶ç›Šç‡", "0.00%")

            # --- B. é¥¼å›¾åŒºåŸŸ ---
            chart_c1, chart_c2 = st.columns(2)
            
            # é¥¼å›¾ 1: æ€»é‡‘é¢å æ¯”
            with chart_c1:
                fig_pie_amt = px.pie(
                    day_data, 
                    values='amount', 
                    names=name_col, 
                    title=f"ã€æ€»é‡‘é¢ã€‘å æ¯” ({selected_dim})", 
                    hole=0.4,
                    custom_data=['amount_w'] # ä¼ å…¥ä¸‡å•ä½æ•°æ®
                )
                fig_pie_amt.update_traces(
                    textposition='inside', 
                    textinfo='percent+label',
                    hovertemplate='<b>%{label}</b>: ğŸ’°%{customdata[0]:.2f}ä¸‡ (ğŸ°%{percent})<extra></extra>'
                )
                st.plotly_chart(fig_pie_amt, use_container_width=True)
            
            # é¥¼å›¾ 2: æ”¶ç›Šè´¡çŒ®å æ¯”
            with chart_c2:
                # åªæœ‰å½“å­˜åœ¨æ­£æ”¶ç›Šæ—¶æ‰ç”»è¿™ä¸ªå›¾ï¼Œå¦åˆ™å…¨æ˜¯è´Ÿçš„ç”»é¥¼å›¾å¾ˆæ€ª
                if (day_data['profit'] > 0).any():
                    # åªå±•ç¤ºèµšé’±çš„éƒ¨åˆ†ï¼Œæˆ–è€…å…¨éƒ¨å±•ç¤ºï¼ˆçœ‹ä¸ªäººå–œå¥½ï¼Œè¿™é‡Œé€»è¾‘æ˜¯å…¨éƒ¨ï¼‰
                    # ä¸ºäº†é¥¼å›¾å¥½çœ‹ï¼Œé€šå¸¸åªç”»æ­£å€¼ã€‚å¦‚æœæƒ³çœ‹äºæŸï¼Œå»ºè®®çœ‹ä¸‹é¢çš„è¡¨æ ¼ã€‚
                    pos_profit_data = day_data[day_data['profit'] > 0]
                    if not pos_profit_data.empty:
                        fig_pie_prof = px.pie(
                            pos_profit_data, 
                            values='profit', 
                            names=name_col, 
                            title=f"ã€æ­£æ”¶ç›Šã€‘è´¡çŒ®å æ¯” ({selected_dim})", 
                            hole=0.4,
                            custom_data=['profit_w']
                        )
                        fig_pie_prof.update_traces(
                            textposition='inside', 
                            textinfo='percent+label',
                            hovertemplate='<b>%{label}</b>: ğŸ“ˆ%{customdata[0]:.2f}ä¸‡ (ğŸ°%{percent})<extra></extra>'
                        )
                        st.plotly_chart(fig_pie_prof, use_container_width=True)
                    else:
                        st.info("å½“æ—¥æ— æ­£æ”¶ç›Šèµ„äº§ã€‚")
                else:
                    st.info("å½“æ—¥æ‰€æœ‰èµ„äº§å‡ä¸ºè´Ÿæ”¶ç›Šæˆ–é›¶æ”¶ç›Šï¼Œæš‚ä¸å±•ç¤ºè´¡çŒ®å›¾ã€‚")

            # --- C. è¯¦ç»†æ•°æ®è¡¨æ ¼ ---
            st.subheader(f"ğŸ“‹ è¯¦ç»†æ•°æ®æ¸…å•")
            
            # æ•´ç†æ˜¾ç¤ºåˆ—
            display_cols = [name_col, 'amount', 'profit', 'yield_rate']
            if 'cost' in day_data.columns: 
                display_cols.insert(2, 'cost')
            
            show_df = day_data[display_cols].copy()
            show_df = show_df.sort_values('amount', ascending=False)
            
            st.dataframe(
                show_df,
                column_config={
                    name_col: "åç§°/æ ‡ç­¾",
                    "amount": st.column_config.NumberColumn("æ€»é‡‘é¢ (Â¥)", format="%.2f"),
                    "cost": st.column_config.NumberColumn("æœ¬é‡‘ (Â¥)", format="%.2f"),
                    "profit": st.column_config.NumberColumn("æŒæœ‰æ”¶ç›Š (Â¥)", format="%.2f"),
                    "yield_rate": st.column_config.NumberColumn("æ”¶ç›Šç‡", format="%.2f%%"),
                },
                use_container_width=True,
                hide_index=True
            )

    # === TAB 3 (ä¿æŒä¸å˜) ===
    with tab3:
        st.subheader("âš ï¸ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
        if df_tags is not None and not df_tags.empty:
            incomplete_df = df_tags[df_tags['is_complete'] == False].copy()
            if not incomplete_df.empty:
                st.error(f"å‘ç° {len(incomplete_df)} æ¡èšåˆè®°å½•æ•°æ®ç¼ºå¤±ï¼")
                incomplete_df['date'] = incomplete_df['date'].dt.date
                st.dataframe(incomplete_df[['date', 'tag_group', 'tag_name', 'missing_count']])
            else:
                st.success("ğŸ‰ æ•°æ®å®Œæ•´ã€‚")
        else:
            st.write("æš‚æ— æ ‡ç­¾æ•°æ®ã€‚")

    # === TAB 4: å¹´åº¦è´¢å¯Œå¤ç›˜ (æ ¸å¿ƒè”åŠ¨åŠŸèƒ½) ===
    with tab4:
        st.subheader("ğŸ† å¹´åº¦è´¢å¯Œå½’å› åˆ†æ")
        st.caption("ä¸Šå¸è§†è§’ï¼šä½ çš„é’±åˆ°åº•æ˜¯ã€èµšã€‘æ¥çš„ï¼Œè¿˜æ˜¯ã€å­˜ã€‘æ¥çš„ï¼Ÿ")
        
        # --- 1. æ•°æ®å‡†å¤‡ ---
        # A. è·å–æ¯å¹´çš„èµ„äº§å¢é‡ (Asset Delta)
        # é€»è¾‘ï¼šå–æ¯å¹´æœ€åä¸€å¤©çš„æ€»èµ„äº§ - ä¸Šä¸€å¹´æœ€åä¸€å¤©çš„æ€»èµ„äº§
        
        # ä¸ºäº†å‡†ç¡®ï¼Œæˆ‘ä»¬æŒ‰å¹´åˆ†ç»„ï¼Œå– max(date)
        df_assets['year'] = df_assets['date'].dt.year
        
       # --- âœ… ä¼˜åŒ–åçš„ä»£ç  (ç¡®ä¿å…ˆç®—å‡ºå½“å¤©çš„æ€»é’±æ•°) ---
        # 1. å…ˆç®—å‡ºæ¯å¤©çš„æ€»èµ„äº§
        daily_sum = df_assets.groupby('date')['amount'].sum().reset_index()
        daily_sum['year'] = daily_sum['date'].dt.year
        
        # 2. å†å–æ¯å¹´çš„æœ€åä¸€å¤©
        yearly_end = daily_sum.sort_values('date').groupby('year').last().reset_index()
        yearly_end.rename(columns={'amount': 'end_amount'}, inplace=True)
        
        # è®¡ç®—æ¯å¹´çš„å¢é‡
        # å…ˆè·å–æ•´ä¸ªæ•°æ®æœ€æ—©æ—¥æœŸä¹‹å‰çš„åˆå§‹çŠ¶æ€ï¼ˆå‡è®¾ä¸º0ï¼Œæˆ–è€…ç”¨æˆ·å½•å…¥çš„ç¬¬ä¸€ç¬”å°±æ˜¯åˆå§‹ï¼‰
        # è¿™é‡Œç”¨ shift ç®€å•è®¡ç®—ï¼šä»Šå¹´çš„å¢é‡ = ä»Šå¹´åº• - å»å¹´åº•
        yearly_end['prev_amount'] = yearly_end['end_amount'].shift(1).fillna(0) # ç¬¬ä¸€å¹´é»˜è®¤å¢é‡å°±æ˜¯å¹´åº•ä½™é¢ï¼ˆå‡è®¾ä»0å¼€å§‹ï¼‰ï¼Œè¿™å¯èƒ½ä¸å‡†ï¼Œä½†å¯¹äºè¶‹åŠ¿åˆ†æå¯ä»¥æ¥å—
        yearly_end['asset_delta'] = yearly_end['end_amount'] - yearly_end['prev_amount']
        conn = get_db_connection()  # <--- åŠ ä¸Šè¿™ä¸€è¡Œ
        # B. è·å–æ¯å¹´çš„å‡€æŠ•å…¥ (Net Input)
        df_cf = pd.read_sql("SELECT date, type, amount FROM cashflows WHERE user_id = ?", conn, params=(user_id,))
        if df_cf.empty:
            st.warning("âš ï¸ æš‚æ— ç°é‡‘æµè®°å½•ï¼Œæ— æ³•è®¡ç®—æœ¬é‡‘æŠ•å…¥ã€‚è¯·å…ˆå»ã€ç°é‡‘æµä¸æœ¬é‡‘å½’é›†ã€‘é¡µé¢å½•å…¥å·¥èµ„å’Œè´¦å•ã€‚")
            yearly_cf = pd.DataFrame(columns=['year', 'net_input'])
        else:
            df_cf['date'] = pd.to_datetime(df_cf['date'])
            df_cf['year'] = df_cf['date'].dt.year
            # æ”¶å…¥è®°æ­£ï¼Œæ”¯å‡ºè®°è´Ÿ
            df_cf['signed_amount'] = df_cf.apply(lambda x: x['amount'] if x['type'] == 'æ”¶å…¥' else -x['amount'], axis=1)
            yearly_cf = df_cf.groupby('year')['signed_amount'].sum().reset_index()
            yearly_cf.rename(columns={'signed_amount': 'net_input'}, inplace=True)
            
        # C. åˆå¹¶æ•°æ®
        df_attribution = pd.merge(yearly_end, yearly_cf, on='year', how='left')
        df_attribution['net_input'] = df_attribution['net_input'].fillna(0)
        
        # D. è®¡ç®—å¸‚åœºæ”¶ç›Š (Market Alpha)
        # å…¬å¼ï¼šå¸‚åœºæ”¶ç›Š = èµ„äº§å¢é‡ - å‡€æŠ•å…¥
        df_attribution['market_alpha'] = df_attribution['asset_delta'] - df_attribution['net_input']
        
        # å•ä½æ¢ç®— (ä¸‡)
        for c in ['end_amount', 'asset_delta', 'net_input', 'market_alpha']:
            df_attribution[f'{c}_w'] = df_attribution[c] / 10000

        # --- 2. ç»˜å›¾ (å †å æŸ±çŠ¶å›¾) ---
        if not df_attribution.empty:
            # è½¬æ¢æ ¼å¼é€‚é… Plotly
            # æˆ‘ä»¬éœ€è¦æŠŠ data å˜é•¿ï¼šYear, Type, Value
            viz_data = []
            for _, row in df_attribution.iterrows():
                # 1. å‡€æŠ•å…¥æŸ±å­
                viz_data.append({
                    'Year': str(int(row['year'])),
                    'Type': 'ğŸŒ± å‡€æŠ•å…¥æœ¬é‡‘ (å·¥èµ„ç»“ä½™)',
                    'Value': row['net_input_w'],
                    'RawValue': row['net_input'],
                    'Color': '#3498DB' # è“è‰²
                })
                # 2. å¸‚åœºæ”¶ç›ŠæŸ±å­
                viz_data.append({
                    'Year': str(int(row['year'])),
                    'Type': 'ğŸš€ å¸‚åœºæŠ•èµ„æ”¶ç›Š (Alpha)',
                    'Value': row['market_alpha_w'],
                    'RawValue': row['market_alpha'],
                    'Color': '#E74C3C' if row['market_alpha'] < 0 else '#2ECC71' # ç»¿èµšçº¢äº
                })
                
            df_viz = pd.DataFrame(viz_data)
            
            # ä½¿ç”¨ Graph Objects ç”»å›¾ä»¥è·å¾—æœ€å¤§è‡ªç”±åº¦ (ç›¸å¯¹æ¨¡å¼)
            fig = go.Figure()
            
            # åˆ†ç»„å¤„ç†ä¸åŒ Type
            for t in df_viz['Type'].unique():
                subset = df_viz[df_viz['Type'] == t]
                fig.add_trace(go.Bar(
                    x=subset['Year'],
                    y=subset['Value'],
                    name=t,
                    marker_color=subset['Color'],
                    text=subset['Value'].apply(lambda x: f"{x:+.1f}w"),
                    textposition='auto',
                    hovertemplate='<b>%{x}å¹´ - %{data.name}</b><br>é‡‘é¢: %{y:.2f}ä¸‡<extra></extra>'
                ))
            
            # å åŠ ä¸€æ¡â€œæ€»èµ„äº§å¢é‡â€çš„æŠ˜çº¿ï¼Œæ–¹ä¾¿å¯¹æ¯”
            fig.add_trace(go.Scatter(
                x=df_attribution['year'].astype(str),
                y=df_attribution['asset_delta_w'],
                name='ğŸ’° å½“å¹´æ€»èµ„äº§å¢é‡',
                mode='lines+markers',
                line=dict(color='#F1C40F', width=3, dash='dot'),
                hovertemplate='å½“å¹´æ€»å¢é‡: %{y:.2f}ä¸‡<extra></extra>'
            ))

            fig.update_layout(
                barmode='relative', # å…³é”®ï¼å…è®¸æ­£è´Ÿå€¼å †å 
                yaxis_title="é‡‘é¢ (ä¸‡å…ƒ)",
                hovermode="x unified",
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            
            st.plotly_chart(fig, use_container_width=True)

            # --- 3. è¯¦ç»†æ•°æ®è¡¨ ---
            st.divider()
            with st.expander("æŸ¥çœ‹è¯¦ç»†å½’å› æ•°æ®è¡¨"):
                st.dataframe(
                    df_attribution[['year', 'asset_delta', 'net_input', 'market_alpha', 'end_amount']],
                    column_config={
                        "year": st.column_config.NumberColumn("å¹´ä»½", format="%d"),
                        "asset_delta": st.column_config.NumberColumn("æ€»èµ„äº§å¢é‡", format="Â¥%.2f"),
                        "net_input": st.column_config.NumberColumn("å‡€æŠ•å…¥æœ¬é‡‘", format="Â¥%.2f"),
                        "market_alpha": st.column_config.NumberColumn("å¸‚åœºæ”¶ç›Š", format="Â¥%.2f"),
                        "end_amount": st.column_config.NumberColumn("å¹´æœ«æ€»èµ„äº§", format="Â¥%.2f"),
                    },
                    hide_index=True,
                    use_container_width=True
                )
            
            # --- 4. æ™ºèƒ½ç‚¹è¯„ ---
            last_year = df_attribution.iloc[-1]
            if last_year['market_alpha'] > last_year['net_input'] and last_year['market_alpha'] > 0:
                st.success(f"ğŸ‰ **åŒè½®é©±åŠ¨ ({(int(last_year['year']))})**ï¼šæ­å–œï¼ä»Šå¹´ä½ çš„ã€ç¡åæ”¶å…¥ã€‘(Â¥{last_year['market_alpha_w']:.1f}ä¸‡) è¶…è¿‡äº†ä½ çš„ã€å·¥èµ„ç»“ä½™ã€‘(Â¥{last_year['net_input_w']:.1f}ä¸‡)ã€‚è¿™æ˜¯ FIRE è·¯ä¸Šé‡è¦çš„é‡Œç¨‹ç¢‘ï¼")
            elif last_year['market_alpha'] < 0:
                st.info(f"ğŸ›¡ï¸ **ç§¯è°·é˜²é¥¥ ({(int(last_year['year']))})**ï¼šä»Šå¹´å¸‚åœºç¯å¢ƒè‰°éš¾ (äºæŸ Â¥{abs(last_year['market_alpha_w']):.1f}ä¸‡)ï¼Œä½†å¥½åœ¨ä½ é€šè¿‡åŠªåŠ›å·¥ä½œå­˜ä¸‹äº† Â¥{last_year['net_input_w']:.1f}ä¸‡ï¼Œå®ˆä½äº†è´¢å¯Œåº•çº¿ã€‚")
            else:
                st.info(f"ğŸ§± **é€šè¿‡ç§¯ç´¯æˆé•¿ ({(int(last_year['year']))})**ï¼šä»Šå¹´è´¢å¯Œå¢é•¿ä¸»è¦æ¥è‡ªäºæœ¬é‡‘æŠ•å…¥ã€‚ç»§ç»­ä¿æŒå‚¨è“„ç‡ï¼Œç­‰å¾…å¸‚åœºé£èµ·ï¼")

        else:
            st.info("æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå¹´åº¦å¤ç›˜ã€‚éœ€è¦è‡³å°‘ä¸€å¹´çš„è·¨åº¦æ•°æ®ã€‚")

# --- æ–°å¢é¡µé¢ï¼šå®šæŠ•è®¡åˆ’ä¸çœ‹æ¿ ---
def page_investment_plans():
    import pandas as pd          # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    import plotly.express as px  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("ğŸ“… å®šæŠ•è®¡åˆ’ä¸æœªæ¥ç°é‡‘æµ")
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    tab1, tab2 = st.tabs(["âš™ï¸ è®¡åˆ’ç®¡ç†", "ğŸ”® æœªæ¥ç°é‡‘æµçœ‹æ¿"])

    # === TAB 1: è®¡åˆ’ç®¡ç† (CRUD) ===
    with tab1:
        st.caption("åœ¨è¿™é‡Œç®¡ç†ä½ çš„è‡ªåŠ¨å®šæŠ•è®¡åˆ’ã€‚æ³¨æ„ï¼šè¿™é‡Œçš„é‡‘é¢æ˜¯æŒ‡ã€åŸå¸ç§ã€‘é‡‘é¢ã€‚")
        
        # 1. æ–°å¢è®¡åˆ’è¡¨å• (å¸¦é«˜çº§ç­›é€‰)
        with st.expander("â• æ–°å¢å®šæŠ•è®¡åˆ’", expanded=True):
            
            # --- A. å‡†å¤‡åŸºç¡€æ•°æ® ---
            # ä¿®æ”¹ï¼šåŒæ—¶è¯»å– currency
            all_assets = pd.read_sql('SELECT asset_id, name, code, currency FROM assets WHERE user_id = ?', conn, params=(user_id,))
            
            if all_assets.empty:
                st.warning("âš ï¸ è¯·å…ˆå»ã€èµ„äº§ä¸æ ‡ç­¾ç®¡ç†ã€‘é¡µé¢æ·»åŠ è‡³å°‘ä¸€ä¸ªèµ„äº§ã€‚")
            else:
                # --- B. ç­›é€‰å·¥å…·æ  (é€»è¾‘ä¿æŒä¸å˜ï¼Œç•¥å¾®çœç•¥ä»¥èŠ‚çœç¯‡å¹…ï¼Œç›´æ¥ä½¿ç”¨) ---
                st.markdown("##### ğŸ” ç¬¬ä¸€æ­¥ï¼šç­›é€‰èµ„äº§")
                f_col1, f_col2, f_col3 = st.columns([2, 1, 2])
                with f_col1:
                    filter_kw = st.text_input("å…³é”®å­—æœç´¢", placeholder="åç§°/ä»£ç ...", key="plan_filter_kw")
                with f_col2:
                    all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
                    grp_list = ["(ä¸ç­›é€‰)"] + all_groups['tag_group'].tolist()
                    sel_group = st.selectbox("æ ‡ç­¾ç»„", grp_list, key="plan_filter_group")
                with f_col3:
                    sel_tags = []
                    if sel_group != "(ä¸ç­›é€‰)":
                        t_df = pd.read_sql("SELECT tag_name FROM tags WHERE user_id=? AND tag_group=?", conn, params=(user_id, sel_group))
                        opts = ["ã€æ— æ­¤æ ‡ç­¾ã€‘"] + t_df['tag_name'].tolist()
                        sel_tags = st.multiselect("æ ‡ç­¾çŠ¶æ€", opts, key="plan_filter_tags")

                # ç­›é€‰é€»è¾‘...
                filtered_ids = set(all_assets['asset_id'].tolist())
                if filter_kw:
                    matched = all_assets[all_assets['name'].str.contains(filter_kw, case=False) | all_assets['code'].str.contains(filter_kw, case=False, na=False)]
                    filtered_ids = filtered_ids.intersection(set(matched['asset_id']))
                if sel_group != "(ä¸ç­›é€‰)" and sel_tags:
                    sql_labeled = '''
                        SELECT atm.asset_id, t.tag_name 
                        FROM asset_tag_map atm JOIN tags t ON atm.tag_id = t.tag_id 
                        WHERE t.user_id = ? AND t.tag_group = ?
                    '''
                    df_labeled = pd.read_sql(sql_labeled, conn, params=(user_id, sel_group))
                    target_group_ids = set()
                    if "ã€æ— æ­¤æ ‡ç­¾ã€‘" in sel_tags: target_group_ids.update(filtered_ids - set(df_labeled['asset_id']))
                    real_tags = [t for t in sel_tags if t != "ã€æ— æ­¤æ ‡ç­¾ã€‘"]
                    if real_tags: target_group_ids.update(set(df_labeled[df_labeled['tag_name'].isin(real_tags)]['asset_id']))
                    filtered_ids = filtered_ids.intersection(target_group_ids)
                
                final_assets = all_assets[all_assets['asset_id'].isin(filtered_ids)].copy()
                
                st.divider()
                st.markdown("##### ğŸ“ ç¬¬äºŒæ­¥ï¼šè®¾ç½®å®šæŠ•å‚æ•°")
                
                if final_assets.empty:
                    st.info("æ²¡æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„èµ„äº§ã€‚")
                else:
                    c1, c2 = st.columns(2)
                    with c1:
                        # æ ¼å¼åŒ–æ˜¾ç¤ºï¼šåŠ å…¥å¸ç§ä¿¡æ¯
                        sel_asset = st.selectbox(
                            f"é€‰æ‹©èµ„äº§ (å½“å‰ç­›é€‰å‡º {len(final_assets)} ä¸ª)", 
                            options=final_assets['asset_id'], 
                            format_func=lambda x: f"{final_assets[final_assets['asset_id']==x]['name'].values[0]} ({final_assets[final_assets['asset_id']==x]['currency'].values[0]})",
                            key="plan_new_asset"
                        )
                        # è·å–é€‰ä¸­èµ„äº§çš„å¸ç§ï¼Œæç¤ºç”¨æˆ·
                        curr_symbol = final_assets[final_assets['asset_id']==sel_asset]['currency'].values[0]
                        amount = st.number_input(f"æ¯æ¬¡å®šæŠ•é‡‘é¢ (å•ä½: {curr_symbol})", min_value=0.0, step=100.0, key="plan_new_amount")
                    
                    with c2:
                        freq = st.selectbox("é¢‘ç‡", ["æ¯å‘¨", "æ¯æœˆ", "æ¯å¤©"], key="plan_new_freq")
                        exec_day = 0
                        if freq == "æ¯å‘¨":
                            weekdays = {0:"å‘¨ä¸€", 1:"å‘¨äºŒ", 2:"å‘¨ä¸‰", 3:"å‘¨å››", 4:"å‘¨äº”", 5:"å‘¨å…­", 6:"å‘¨æ—¥"}
                            exec_day = st.selectbox("é€‰æ‹©å‘¨å‡ ", options=list(weekdays.keys()), format_func=lambda x: weekdays[x], key="plan_new_day_week")
                        elif freq == "æ¯æœˆ":
                            exec_day = st.number_input("é€‰æ‹©æ¯æœˆå‡ å·", min_value=1, max_value=28, value=1, key="plan_new_day_month")

                    st.write("") 
                    
                    if st.button("ğŸ’¾ ä¿å­˜å®šæŠ•è®¡åˆ’", type="primary", key="btn_save_plan"):
                        if amount <= 0:
                            st.error("å®šæŠ•é‡‘é¢å¿…é¡»å¤§äº 0")
                        else:
                            try:
                                conn.execute('''
                                    INSERT INTO investment_plans (user_id, asset_id, amount, frequency, execution_day)
                                    VALUES (?, ?, ?, ?, ?)
                                ''', (user_id, sel_asset, amount, freq, exec_day))
                                conn.commit()
                                st.success(f"âœ… å·²æ·»åŠ å®šæŠ•è®¡åˆ’ï¼")
                                st.rerun()
                            except Exception as e:
                                st.error(f"ä¿å­˜å¤±è´¥: {e}")

        # 2. ç°æœ‰è®¡åˆ’åˆ—è¡¨
        st.subheader("ğŸ“‹ æ­£åœ¨è¿è¡Œçš„è®¡åˆ’")
        
        # ä¿®æ”¹ï¼šåŒæ—¶æŸ¥å‡º assets è¡¨çš„ currency
        plans_df = pd.read_sql('''
            SELECT p.plan_id, a.name, a.currency, p.amount, p.frequency, p.execution_day, p.is_active
            FROM investment_plans p
            JOIN assets a ON p.asset_id = a.asset_id
            WHERE p.user_id = ?
        ''', conn, params=(user_id,))

        if not plans_df.empty:
            def format_freq(row):
                if row['frequency'] == 'æ¯å¤©': return "æ¯å¤©"
                if row['frequency'] == 'æ¯å‘¨': 
                    ws = ["å‘¨ä¸€","å‘¨äºŒ","å‘¨ä¸‰","å‘¨å››","å‘¨äº”","å‘¨å…­","å‘¨æ—¥"]
                    return f"æ¯å‘¨ {ws[int(row['execution_day'])]}"
                if row['frequency'] == 'æ¯æœˆ': return f"æ¯æœˆ {int(row['execution_day'])} å·"
                return ""

            plans_df['æè¿°'] = plans_df.apply(format_freq, axis=1)
            
            edited_plans = st.data_editor(
                plans_df,
                column_config={
                    "plan_id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
                    "name": st.column_config.TextColumn("èµ„äº§åç§°", disabled=True),
                    "currency": st.column_config.TextColumn("å¸ç§", disabled=True, width="small"),
                    "amount": st.column_config.NumberColumn("é‡‘é¢ (åŸå¸)", format="%.2f"),
                    "frequency": st.column_config.TextColumn("é¢‘ç‡", disabled=True),
                    "execution_day": None, 
                    "æè¿°": st.column_config.TextColumn("å®šæŠ•æ—¶é—´", disabled=True),
                    "is_active": st.column_config.CheckboxColumn("å¯ç”¨ä¸­"),
                },
                hide_index=True,
                use_container_width=True,
                num_rows="dynamic",
                key="plans_editor"
            )
            
            if st.button("ğŸ’¾ ä¿å­˜è®¡åˆ’å˜æ›´"):
                # --- ğŸ”¥ ä¿®å¤ï¼šå‰”é™¤çº¯å±•ç¤ºç”¨çš„åˆ—ï¼Œé˜²æ­¢å†™å…¥æ•°æ®åº“æŠ¥é”™ ---
                # 'name', 'currency' æ˜¯ä» assets è¡¨è”æŸ¥å‡ºæ¥çš„ï¼Œ'æè¿°' æ˜¯å‰ç«¯è®¡ç®—çš„
                # æ•°æ®åº“è¡¨ investment_plans é‡Œæ²¡æœ‰è¿™äº›å­—æ®µ
                cols_to_drop = ['name', 'currency', 'æè¿°']
                
                # è¿‡æ»¤æ‰è¿™äº›åˆ—ï¼Œåªä¿ç•™æ•°æ®åº“è¡¨é‡Œæœ‰çš„å­—æ®µ (å¦‚ amount, frequency, execution_day, is_active)
                df_to_save = edited_plans.drop(columns=[c for c in cols_to_drop if c in edited_plans.columns])
                
                if save_changes_to_db(df_to_save, plans_df, 'investment_plans', 'plan_id', user_id, fixed_cols={'user_id':user_id}):
                    st.rerun()
        else:
            st.info("æš‚æ— å®šæŠ•è®¡åˆ’ã€‚")

    # === TAB 2: ç°é‡‘æµçœ‹æ¿ (æ ¸å¿ƒä¿®æ”¹) ===
    with tab2:
        # 1. è®¡ç®—æœªæ¥ç°é‡‘æµé€»è¾‘
        st.subheader("ğŸ—“ï¸ æœªæ¥ 30 å¤©èµ„é‡‘éœ€æ±‚æ¨æ¼” (æŠ˜åˆäººæ°‘å¸)")
        
        # è·å–æœ€æ–°æ±‡ç‡è¡¨
        rates_map = get_latest_rates(conn)
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„è®¡åˆ’ (åŒ…å«å¸ç§)
        active_plans = pd.read_sql('''
            SELECT p.asset_id, a.name, a.currency, p.amount, p.frequency, p.execution_day
            FROM investment_plans p
            JOIN assets a ON p.asset_id = a.asset_id
            WHERE p.user_id = ? AND p.is_active = 1
        ''', conn, params=(user_id,))
        
        asset_tags = pd.read_sql('''
            SELECT atm.asset_id, t.tag_group, t.tag_name
            FROM asset_tag_map atm
            JOIN tags t ON atm.tag_id = t.tag_id
            WHERE t.user_id = ?
        ''', conn, params=(user_id,))

        if active_plans.empty:
            st.info("è¯·å…ˆå¯ç”¨è‡³å°‘ä¸€ä¸ªå®šæŠ•è®¡åˆ’ã€‚")
        else:
            today = datetime.now().date()
            future_days = 30
            projection_data = []

            for i in range(future_days):
                current_date = today + timedelta(days=i)
                current_weekday = current_date.weekday()
                current_day = current_date.day
                
                for _, plan in active_plans.iterrows():
                    hit = False
                    if plan['frequency'] == 'æ¯å¤©': hit = True
                    elif plan['frequency'] == 'æ¯å‘¨' and int(plan['execution_day']) == current_weekday: hit = True
                    elif plan['frequency'] == 'æ¯æœˆ' and int(plan['execution_day']) == current_day: hit = True
                    
                    if hit:
                        # ğŸ”¥ æ ¸å¿ƒä¿®æ­£ï¼šé‡‘é¢æŠ˜ç®—
                        raw_amt = plan['amount']
                        curr = plan['currency']
                        rate = 1.0 if curr == 'CNY' else rates_map.get(curr, 1.0)
                        cny_amt = raw_amt * rate
                        
                        projection_data.append({
                            "date": current_date,
                            "asset_id": plan['asset_id'],
                            "asset_name": plan['name'],
                            "amount_cny": cny_amt, # ä½¿ç”¨æŠ˜ç®—åçš„é‡‘é¢
                            "raw_info": f"{raw_amt} {curr}" # å¤‡æ³¨åŸå¸é‡‘é¢
                        })

            if not projection_data:
                st.warning("æœªæ¥30å¤©å†…æ²¡æœ‰åŒ¹é…çš„å®šæŠ•æ—¥ã€‚")
            else:
                df_proj = pd.DataFrame(projection_data)
                
                # --- å¯è§†åŒ– A: æ€»è§ˆ (CNY) ---
                total_needed = df_proj['amount_cny'].sum()
                col1, col2 = st.columns(2)
                col1.metric("æœªæ¥ 30 å¤©æ€»å®šæŠ• (CNY)", f"Â¥{total_needed:,.2f}")
                col2.metric("å¹³å‡æ¯æ—¥æµå‡º (CNY)", f"Â¥{total_needed/30:,.2f}")

                st.divider()

                # --- å¯è§†åŒ– B: å †å æŸ±çŠ¶å›¾ ---
                all_groups = asset_tags['tag_group'].unique().tolist() if not asset_tags.empty else []
                dim_options = ["æŒ‰å…·ä½“èµ„äº§"] + all_groups
                selected_dim = st.selectbox("é€‰æ‹©åˆ†æç»´åº¦ (å †å æ–¹å¼)", dim_options)
                
                df_viz = df_proj.copy()
                
                if selected_dim == "æŒ‰å…·ä½“èµ„äº§":
                    df_viz['category'] = df_viz['asset_name']
                else:
                    tags_in_group = asset_tags[asset_tags['tag_group'] == selected_dim]
                    df_viz = pd.merge(df_viz, tags_in_group, on='asset_id', how='left')
                    df_viz['tag_name'] = df_viz['tag_name'].fillna('æœªåˆ†ç±»')
                    df_viz['category'] = df_viz['tag_name']

                # æŒ‰ amount_cny èšåˆ
                df_agg = df_viz.groupby(['date', 'category'])['amount_cny'].sum().reset_index()
                
                daily_totals = df_agg.groupby('date')['amount_cny'].transform('sum')
                df_agg['share'] = (df_agg['amount_cny'] / daily_totals) * 100

                fig = px.bar(
                    df_agg, 
                    x='date', 
                    y='amount_cny', 
                    color='category',
                    title=f"æœªæ¥ 30 å¤©æ¯æ—¥å®šæŠ•åˆ†å¸ƒ ({selected_dim}) - æŠ˜åˆäººæ°‘å¸",
                    labels={'amount_cny': 'é‡‘é¢ (CNY)', 'date': 'æ—¥æœŸ', 'category': 'ç±»åˆ«'},
                    custom_data=['share'] 
                )
                
                fig.update_traces(
                    hovertemplate='<b>%{fullData.name}</b>: Â¥%{y:,.0f} (%{customdata[0]:.1f}%)<extra></extra>'
                )
                
                fig.update_layout(
                    hovermode="x unified",
                    legend_title_text="" 
                )
                
                st.plotly_chart(fig, use_container_width=True)

    conn.close()

def page_rebalance():
    import pandas as pd            # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    import plotly.graph_objects as go  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("âš–ï¸ æŠ•èµ„ç»„åˆå†å¹³è¡¡åŠ©æ‰‹")
    st.caption("è®¾å®šä½ çš„ç†æƒ³èµ„äº§é…æ¯”ï¼Œç³»ç»Ÿå°†è®¡ç®—å¦‚ä½•è°ƒæ•´ä»“ä½ä»¥ç»´æŒé£é™©å¹³è¡¡ã€‚")
    
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    # --- 1. é€‰æ‹©è¦è¿›è¡Œå†å¹³è¡¡çš„ç»´åº¦ ---
    # é€šå¸¸æˆ‘ä»¬åªå¯¹å¤§çš„ç»´åº¦åšå†å¹³è¡¡ï¼Œæ¯”å¦‚ "èµ„äº§å¤§ç±»" (è‚¡/å€º/é‡‘) æˆ– "é£é™©ç­‰çº§"
    all_groups = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
    
    if all_groups.empty:
        st.warning("è¯·å…ˆå»è®¾ç½®æ ‡ç­¾ã€‚")
        conn.close()
        return

    col1, col2 = st.columns([1, 2])
    with col1:
        # é»˜è®¤å°è¯•é€‰ä¸­ "èµ„äº§å¤§ç±»" æˆ– "é£é™©ç­‰çº§"ï¼Œå¦‚æœæ²¡æœ‰å°±é€‰ç¬¬ä¸€ä¸ª
        default_idx = 0
        groups_list = all_groups['tag_group'].tolist()
        if "èµ„äº§å¤§ç±»" in groups_list: default_idx = groups_list.index("èµ„äº§å¤§ç±»")
        elif "é£é™©ç­‰çº§" in groups_list: default_idx = groups_list.index("é£é™©ç­‰çº§")
        
        selected_group = st.selectbox("é€‰æ‹©é…ç½®ç»´åº¦", groups_list, index=default_idx)

    # --- 2. è·å–å½“å‰æŒä»“æ•°æ® (Real) ---
    _, df_tags = get_cached_analytics_data(user_id)
    
    if df_tags is None or df_tags.empty:
        st.info("æš‚æ— èµ„äº§æ•°æ®ã€‚")
        conn.close()
        return

    # è¿‡æ»¤å‡ºå½“å‰ç»´åº¦çš„æœ€æ–°æ•°æ®
    latest_date = df_tags['date'].max()
    current_portfolio = df_tags[
        (df_tags['date'] == latest_date) & 
        (df_tags['tag_group'] == selected_group)
    ].copy()
    
    total_asset_val = current_portfolio['amount'].sum() # æ€»èµ„äº§ (CNY)

    # --- 3. è·å–/è®¾ç½®ç›®æ ‡é…ç½® (Target) ---
    # è¯»å–å·²ä¿å­˜çš„ç›®æ ‡
    saved_targets = pd.read_sql(
        "SELECT tag_name, target_percentage FROM rebalance_targets WHERE user_id = ? AND tag_group = ?",
        conn, params=(user_id, selected_group)
    )
    
    # æ„é€ ç¼–è¾‘è¡¨æ ¼æ•°æ®
    # æ‹¿åˆ°è¯¥ç»„ä¸‹æ‰€æœ‰çš„æ ‡ç­¾å
    all_tags_in_group = pd.read_sql(
        "SELECT tag_name FROM tags WHERE user_id = ? AND tag_group = ?", 
        conn, params=(user_id, selected_group)
    )
    
    # åˆå¹¶ï¼šæ ‡ç­¾å + ç°æœ‰ç›®æ ‡ + å½“å‰æŒä»“
    # è¿™æ ·å³ä½¿ç”¨æˆ·è¿˜æ²¡æŒæœ‰æŸä¸ªæ ‡ç­¾çš„èµ„äº§ï¼Œä¹Ÿèƒ½ç»™å®ƒè®¾ç›®æ ‡ï¼ˆå‡†å¤‡ä¹°å…¥ï¼‰
    df_editor = pd.merge(all_tags_in_group, saved_targets, on='tag_name', how='left')
    df_editor['target_percentage'] = df_editor['target_percentage'].fillna(0.0)
    
    # å…³è”å½“å‰å®é™…æŒä»“å æ¯”ï¼Œæ–¹ä¾¿å‚è€ƒ
    current_portfolio['actual_percentage'] = (current_portfolio['amount'] / total_asset_val * 100)
    df_editor = pd.merge(df_editor, current_portfolio[['tag_name', 'actual_percentage']], on='tag_name', how='left')
    df_editor['actual_percentage'] = df_editor['actual_percentage'].fillna(0.0)
    
    st.divider()
    
    c_edit, c_chart = st.columns([2, 3])
    
    with c_edit:
        st.subheader("ğŸ¯ è®¾å®šç›®æ ‡æ¯”ä¾‹")
        st.caption("è¯·ç›´æ¥åœ¨è¡¨æ ¼ä¸­ä¿®æ”¹ã€ç›®æ ‡å æ¯”ã€‘ï¼Œæ€»å’Œåº”ä¸º 100%ã€‚")
        
        edited_df = st.data_editor(
            df_editor[['tag_name', 'target_percentage', 'actual_percentage']],
            column_config={
                "tag_name": st.column_config.TextColumn("ç±»åˆ«", disabled=True),
                "target_percentage": st.column_config.NumberColumn("ç›®æ ‡å æ¯” (%)", min_value=0, max_value=100, step=1.0, required=True),
                "actual_percentage": st.column_config.NumberColumn("å½“å‰å æ¯” (%)", disabled=True, format="%.2f%%"),
            },
            hide_index=True,
            use_container_width=True,
            key=f"rebalance_editor_{selected_group}"
        )
        
        current_sum = edited_df['target_percentage'].sum()
        if abs(current_sum - 100) > 0.01:
            st.warning(f"âš ï¸ å½“å‰ç›®æ ‡æ€»å’Œä¸º {current_sum:.2f}%ï¼Œè¯·è°ƒæ•´è‡³ 100%ã€‚")
        else:
            if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary"):
                # ä¿å­˜é€»è¾‘
                try:
                    conn.execute("DELETE FROM rebalance_targets WHERE user_id = ? AND tag_group = ?", (user_id, selected_group))
                    for _, row in edited_df.iterrows():
                        if row['target_percentage'] > 0:
                            conn.execute(
                                "INSERT INTO rebalance_targets (user_id, tag_group, tag_name, target_percentage) VALUES (?, ?, ?, ?)",
                                (user_id, selected_group, row['tag_name'], row['target_percentage'])
                            )
                    conn.commit()
                    st.success("é…ç½®å·²ä¿å­˜ï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"ä¿å­˜å¤±è´¥: {e}")

    # --- 4. è®¡ç®—ä¸å±•ç¤ºå†å¹³è¡¡å»ºè®® ---
    if abs(current_sum - 100) <= 0.01:
        with c_chart:
            st.subheader("ğŸ“Š åå·®åˆ†æ")
            
            # å‡†å¤‡ç»˜å›¾æ•°æ®
            # æ¯”è¾ƒ Target vs Actual
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=edited_df['tag_name'],
                y=edited_df['actual_percentage'],
                name='å½“å‰å®é™…',
                marker_color='#95A5A6'
            ))
            fig.add_trace(go.Bar(
                x=edited_df['tag_name'],
                y=edited_df['target_percentage'],
                name='ç†æƒ³ç›®æ ‡',
                marker_color='#3498DB'
            ))
            fig.update_layout(barmode='group', title=f"å®é™… vs ç›®æ ‡ ({selected_group})", hovermode="x unified")
            st.plotly_chart(fig, use_container_width=True)

        st.divider()
        st.subheader("ğŸ’Š å†å¹³è¡¡æ“ä½œå»ºè®®")
        st.caption(f"åŸºäºå½“å‰æ€»èµ„äº§æŠ˜åˆäººæ°‘å¸ï¼šÂ¥{total_asset_val:,.2f}")

        # è®¡ç®—å…·ä½“ä¹°å–é‡‘é¢
        # é€»è¾‘ï¼šç†æƒ³é‡‘é¢ = æ€»èµ„äº§ * ç›®æ ‡% - å®é™…æŒæœ‰çš„é‡‘é¢
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾æ€»èµ„äº§ä¸å˜ï¼ˆå³é€šè¿‡å–å‡ºå¤šçš„ä¹°å…¥å°‘çš„ï¼Œæˆ–è€…ç”¨æ–°å¢èµ„é‡‘å»å¡«è¡¥ï¼‰
        
        # é‡æ–°mergeä¸€ä¸‹ç¡®ä¿æ•°æ®æœ€æ–°
        # éœ€è¦æŠŠ edited_df é‡Œçš„ target_percentage å’Œ current_portfolio é‡Œçš„ amount ç»“åˆ
        # current_portfolio å¯èƒ½ç¼ºæŸäº› tagï¼ˆå¦‚æœè¿˜æ²¡ä¹°ï¼‰ï¼Œæ‰€ä»¥è¦ä»¥ edited_df ä¸ºä¸»
        
        # æ„é€ ä¸€ä¸ªå®Œæ•´çš„è®¡ç®—è¡¨
        df_calc = pd.merge(
            edited_df[['tag_name', 'target_percentage']], 
            current_portfolio[['tag_name', 'amount']], 
            on='tag_name', 
            how='left'
        )
        df_calc['amount'] = df_calc['amount'].fillna(0.0)
        
        # æ ¸å¿ƒè®¡ç®—
        df_calc['target_amount'] = total_asset_val * (df_calc['target_percentage'] / 100.0)
        df_calc['diff_amount'] = df_calc['target_amount'] - df_calc['amount']
        
        # åˆ†ç±»å»ºè®®
        to_buy = df_calc[df_calc['diff_amount'] > 100].sort_values('diff_amount', ascending=False) # å¿½ç•¥å°é¢å™ªéŸ³
        to_sell = df_calc[df_calc['diff_amount'] < -100].sort_values('diff_amount', ascending=True)
        
        col_buy, col_sell = st.columns(2)
        
        with col_buy:
            if not to_buy.empty:
                st.success("ğŸ”µ å»ºè®®ä¹°å…¥ / åŠ ä»“")
                for _, row in to_buy.iterrows():
                    st.markdown(f"**{row['tag_name']}**: éœ€ä¹°å…¥ **Â¥{row['diff_amount']:,.0f}**")
                    st.progress(min(1.0, row['amount'] / row['target_amount']) if row['target_amount']>0 else 0)
            else:
                st.write("âœ… æ— éœ€ä¹°å…¥")

        with col_sell:
            if not to_sell.empty:
                st.error("ğŸ”´ å»ºè®®å–å‡º / å‡ä»“")
                for _, row in to_sell.iterrows():
                    sell_val = abs(row['diff_amount'])
                    st.markdown(f"**{row['tag_name']}**: éœ€å–å‡º **Â¥{sell_val:,.0f}**")
                    # è¿›åº¦æ¡å±•ç¤ºè¶…é…ç¨‹åº¦
                    over_ratio = (row['amount'] - row['target_amount']) / row['target_amount'] if row['target_amount']>0 else 1
                    st.progress(min(1.0, over_ratio))
            else:
                st.write("âœ… æ— éœ€å–å‡º")

    conn.close()

def page_performance():
    import pandas as pd
    import plotly.express as px
    import calendar
    from datetime import datetime, timedelta

    st.header("ğŸ† æŠ•èµ„æˆ˜ç»©ä¸æœˆåº¦å¤ç›˜")
    st.caption("æ‰‹åŠ¨è®°å½•æ¯æœˆçš„æœ€ç»ˆæˆ˜æœï¼Œä¸çº ç»“è¿‡ç¨‹ï¼Œåªçœ‹ç»“æœã€‚")

    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    # --- 1. æ ¸å¿ƒç»´åº¦é€‰æ‹© (æ•°æ®éš”ç¦»å¢™) ---
    all_groups_df = pd.read_sql("SELECT DISTINCT tag_group FROM tags WHERE user_id = ?", conn, params=(user_id,))
    
    if all_groups_df.empty:
        st.warning("âš ï¸ è¯·å…ˆå»ã€èµ„äº§ä¸æ ‡ç­¾ç®¡ç†ã€‘å®šä¹‰æ ‡ç­¾ç»„ï¼ˆä¾‹å¦‚æ–°å»ºä¸€ä¸ªç»„å«â€œèµ„é‡‘æ¸ é“â€ï¼‰ã€‚")
        conn.close()
        return

    # æ™ºèƒ½å®šä½é»˜è®¤ç»„
    default_idx = 0
    g_list = all_groups_df['tag_group'].tolist()
    for kw in ["æ¸ é“", "è´¦æˆ·", "æ¥æº"]:
        matches = [i for i, x in enumerate(g_list) if kw in x]
        if matches:
            default_idx = matches[0]
            break
            
    selected_group = st.selectbox("ğŸ“‚ è®°è´¦ç»´åº¦", g_list, index=default_idx)
    
    # è·å–è¯¥ç»„ä¸‹çš„æ ‡ç­¾
    tags_in_group = pd.read_sql("SELECT tag_name FROM tags WHERE user_id = ? AND tag_group = ?", 
                              conn, params=(user_id, selected_group))
    
    if tags_in_group.empty:
        st.info(f"æ ‡ç­¾ç»„ã€{selected_group}ã€‘ä¸‹æ²¡æœ‰æ ‡ç­¾ï¼Œè¯·å…ˆå»æ·»åŠ ã€‚")
        conn.close()
        return
        
    tag_names = tags_in_group['tag_name'].tolist()

    st.divider()

    # --- 2. æ•°æ®å½•å…¥åŒº (åŒä¸‹æ‹‰æ¡† + è‡ªåŠ¨è¦†ç›–) ---
    with st.expander("ğŸ“ å½•å…¥/ä¿®æ”¹ æœˆåº¦æ•°æ®", expanded=False):
        # ä¼˜é›…çš„å¹´æœˆé€‰æ‹©
        today = datetime.now()
        last_month_date = today.replace(day=1) - timedelta(days=1)
        default_year = last_month_date.year
        default_month = last_month_date.month

        c_y, c_m, _ = st.columns([1, 1, 3])
        with c_y:
            sel_year = st.selectbox("å¹´ä»½", list(range(default_year - 5, default_year + 3)), index=5, key="perf_sel_year")
        with c_m:
            sel_month = st.selectbox("æœˆä»½", range(1, 13), index=default_month - 1, key="perf_sel_month")

        month_str = f"{sel_year}-{sel_month:02d}"
        
        # é¢„è¯»å–æ•°æ®
        existing_data = pd.read_sql('''
            SELECT tag_name, amount FROM monthly_profits 
            WHERE user_id = ? AND month = ? AND tag_group = ?
        ''', conn, params=(user_id, month_str, selected_group))
        data_map = dict(zip(existing_data['tag_name'], existing_data['amount']))
        
        existing_note = conn.execute('''
            SELECT content FROM monthly_reviews 
            WHERE user_id = ? AND month = ? AND tag_group = ?
        ''', (user_id, month_str, selected_group)).fetchone()
        note_val = existing_note['content'] if existing_note else ""

        with st.form("perf_entry_form"):
            st.caption(f"å½“å‰å½•å…¥ï¼š{selected_group} - {month_str}")
            cols = st.columns(3)
            input_values = {}
            
            for i, tag in enumerate(tag_names):
                col = cols[i % 3]
                with col:
                    input_values[tag] = st.number_input(
                        tag, 
                        value=float(data_map.get(tag, 0.0)), 
                        step=100.0,
                        format="%.2f",
                        key=f"perf_{month_str}_{tag}"
                    )
            
            st.write("")
            new_note = st.text_area("ğŸ“ æœˆåº¦å¤ç›˜ / å¤‡æ³¨", value=note_val, height=80, placeholder="æœ¬æœˆæ€»ç»“...")
            
            if st.form_submit_button("ğŸ’¾ ä¿å­˜ / æ›´æ–°", type="primary", use_container_width=True):
                try:
                    for tag, amt in input_values.items():
                        conn.execute('''
                            INSERT INTO monthly_profits (user_id, month, tag_group, tag_name, amount, updated_at)
                            VALUES (?, ?, ?, ?, ?, ?)
                            ON CONFLICT(user_id, month, tag_group, tag_name) 
                            DO UPDATE SET amount=excluded.amount, updated_at=excluded.updated_at
                        ''', (user_id, month_str, selected_group, tag, amt, datetime.now()))
                    
                    if new_note.strip():
                        conn.execute('''
                            INSERT INTO monthly_reviews (user_id, month, tag_group, content, updated_at)
                            VALUES (?, ?, ?, ?, ?)
                            ON CONFLICT(user_id, month, tag_group)
                            DO UPDATE SET content=excluded.content, updated_at=excluded.updated_at
                        ''', (user_id, month_str, selected_group, new_note, datetime.now()))
                    else:
                        conn.execute('DELETE FROM monthly_reviews WHERE user_id=? AND month=? AND tag_group=?', 
                                   (user_id, month_str, selected_group))

                    conn.commit()
                    st.toast(f"âœ… {month_str} æ•°æ®å·²ä¿å­˜ï¼", icon="ğŸ’¾")
                    import time
                    time.sleep(0.5)
                    st.rerun()
                except Exception as e:
                    st.error(f"ä¿å­˜å¤±è´¥: {e}")

    # --- 3. æˆ˜ç»©å¢™ (çº¯è§†è§‰å¡ç‰‡) ---
    df_all = pd.read_sql('''
        SELECT month, amount
        FROM monthly_profits 
        WHERE user_id = ? AND tag_group = ?
        ORDER BY month DESC
    ''', conn, params=(user_id, selected_group))
    
    # å› ä¸º monthly_profits æ˜¯ç»†åˆ†åˆ° tag çš„ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæŒ‰ month èšåˆæ€»é‡‘é¢
    if df_all.empty:
        st.info(f"ğŸ·ï¸ æ ‡ç­¾ç»„ã€{selected_group}ã€‘æš‚æ— æ”¶ç›Šè®°å½•ã€‚")
    else:
        # æŒ‰æœˆèšåˆ
        df_agg = df_all.groupby('month')['amount'].sum().reset_index().sort_values('month', ascending=False)
        df_agg['year'] = df_agg['month'].str.slice(0, 4)
        
        unique_years = sorted(df_agg['year'].unique().tolist(), reverse=True)
        
        tabs = st.tabs([f"{y} å¹´åº¦" for y in unique_years])
        
        for i, year in enumerate(unique_years):
            with tabs[i]:
                df_year = df_agg[df_agg['year'] == year]
                
                # A. é¡¶éƒ¨ç»Ÿè®¡
                total_profit = df_year['amount'].sum()
                
                k1, k2, k3 = st.columns(3)
                k1.metric("å¹´åº¦ç´¯è®¡æ”¶ç›Š", f"Â¥{total_profit:,.2f}", delta_color="normal" if total_profit >= 0 else "inverse")
                k2.metric("ç›ˆåˆ©æœˆä»½", f"{len(df_year[df_year['amount']>0])} ä¸ª")
                k3.metric("äºæŸæœˆä»½", f"{len(df_year[df_year['amount']<0])} ä¸ª")
                
                st.divider()

                # B. æœˆä»½è‰²å—çŸ©é˜µ
                # æ”¹ä¸º 6 åˆ—ï¼Œè®©å¡ç‰‡çœ‹èµ·æ¥æ›´çª„
                grid_cols = st.columns(6)
                
                for idx, row in enumerate(df_year.to_dict('records')):
                    m_str = row['month']
                    m_total = row['amount']
                    
                    # é¢œè‰²å®šä¹‰ (Aè‚¡é…è‰²ï¼šçº¢æ¶¨ç»¿è·Œ)
                    # ä½¿ç”¨æŸ”å’Œä¸€ç‚¹çš„è‰²å€¼ï¼Œé˜²æ­¢åˆºçœ¼
                    # çº¢: #e74c3c (Alizarin), ç»¿: #2ecc71 (Emerald), ç°: #95a5a6
                    if m_total > 0:
                        bg_color = "#e74c3c" 
                        sign = "+"
                    elif m_total < 0:
                        bg_color = "#2ecc71" # å¦‚æœä½ ä¹ æƒ¯ç¾è‚¡é…è‰²(ç»¿æ¶¨çº¢è·Œ)ï¼Œè¿™é‡Œäº’æ¢é¢œè‰²å³å¯
                        sign = ""
                    else:
                        bg_color = "#95a5a6"
                        sign = ""

                    col_idx = idx % 6
                    
                    with grid_cols[col_idx]:
                        # ä½¿ç”¨ HTML/CSS ç»˜åˆ¶å¡ç‰‡
                        # height: 80px åŠ ä¸Š narrow column å®ç°äº†"é«˜çª„"è§†è§‰
                        card_html = f"""
                        <div style="
                            background-color: {bg_color};
                            color: white;
                            padding: 10px 2px;
                            border-radius: 6px;
                            text-align: center;
                            margin-bottom: 10px;
                            height: 90px;
                            display: flex;
                            flex-direction: column;
                            justify-content: center;
                            align-items: center;
                            box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
                        ">
                            <div style="font-size: 0.85em; opacity: 0.9; margin-bottom: 4px;">{m_str}</div>
                            <div style="font-size: 1.1em; font-weight: bold;">{sign}{m_total:,.0f}</div>
                        </div>
                        """
                        st.markdown(card_html, unsafe_allow_html=True)

    conn.close()

def page_investment_notes():
    import pandas as pd  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("ğŸ“’ æŠ•èµ„ç¬”è®°ä¸å¤ç›˜")
    st.caption("è®°å½•æ¯ä¸€æ¬¡å†³ç­–çš„æ€è€ƒï¼Œæ„å»ºè‡ªå·±çš„æŠ•èµ„ä½“ç³»ã€‚")
    
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()

    # --- çŠ¶æ€ç®¡ç† ---
    # æˆ‘ä»¬åªéœ€è¦è®°å½•å½“å‰æ­£åœ¨ç¼–è¾‘å“ªä¸€ä¸ª note_id
    if 'editing_note_id' not in st.session_state:
        st.session_state.editing_note_id = None

    # --- A. é¡¶éƒ¨ï¼šä»…ç”¨äºæ–°å»ºç¬”è®° ---
    # ä½¿ç”¨ expander æ”¶çº³ï¼Œæ˜¾å¾—é¡µé¢æ›´å¹²å‡€ï¼Œæƒ³å†™çš„æ—¶å€™å†ç‚¹å¼€
    with st.expander("âœï¸ å†™ä¸€ç¯‡æ–°ç¬”è®°", expanded=False):
        new_title = st.text_input("æ ‡é¢˜", placeholder="ä¾‹å¦‚ï¼šç¾è‚¡å¤§è·Œï¼ŒåŠ ä»“æœºä¼šï¼Ÿ", key="new_note_title")
        new_content = st.text_area("æ­£æ–‡", height=100, placeholder="è®°å½•ä½ çš„åˆ†æã€æƒ…ç»ªå’Œæ“ä½œè®¡åˆ’...", key="new_note_content")
        
        if st.button("ğŸš€ å‘å¸ƒç¬”è®°", type="primary"):
            if not new_title.strip():
                st.warning("æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
            else:
                try:
                    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    conn.execute('''
                        INSERT INTO investment_notes (user_id, title, content, created_at, updated_at) 
                        VALUES (?, ?, ?, ?, ?)
                    ''', (user_id, new_title, new_content, timestamp, timestamp))
                    conn.commit()
                    st.success("å‘å¸ƒæˆåŠŸï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"å‘å¸ƒå¤±è´¥: {e}")

    st.divider()

    # --- B. æ—¶é—´è½´å±•ç¤ºåŒº (å«åŸåœ°ç¼–è¾‘é€»è¾‘) ---
    st.subheader("â³ ç¬”è®°æ—¶é—´è½´")
    
    notes = pd.read_sql('''
        SELECT note_id, title, content, created_at, updated_at 
        FROM investment_notes 
        WHERE user_id = ? 
        ORDER BY created_at DESC
    ''', conn, params=(user_id,))

    if notes.empty:
        st.info("è¿˜æ²¡æœ‰ç¬”è®°ï¼Œå¿«å»å†™ç¬¬ä¸€ç¯‡å§ï¼")
    else:
        for index, note in notes.iterrows():
            note_id = note['note_id']
            
            # ä½¿ç”¨ container æ¨¡æ‹Ÿå¡ç‰‡
            with st.container(border=True):
                
                # === åˆ¤æ–­ï¼šå½“å‰æ˜¯å¦å¤„äºç¼–è¾‘æ¨¡å¼ ===
                if st.session_state.editing_note_id == note_id:
                    # >>>>> ç¼–è¾‘æ¨¡å¼ç•Œé¢ >>>>>
                    st.markdown("##### ğŸ“ ç¼–è¾‘ä¸­...")
                    
                    # è¾“å…¥æ¡† (é»˜è®¤å€¼ä¸ºå½“å‰ç¬”è®°å†…å®¹)
                    edit_title = st.text_input("æ ‡é¢˜", value=note['title'], key=f"edit_title_{note_id}")
                    edit_content = st.text_area("æ­£æ–‡", value=note['content'], height=150, key=f"edit_content_{note_id}")
                    
                    col_save, col_cancel = st.columns([1, 5])
                    with col_save:
                        if st.button("ğŸ’¾ ä¿å­˜", type="primary", key=f"save_{note_id}"):
                            if not edit_title.strip():
                                st.warning("æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
                            else:
                                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                conn.execute('''
                                    UPDATE investment_notes 
                                    SET title = ?, content = ?, updated_at = ? 
                                    WHERE note_id = ?
                                ''', (edit_title, edit_content, timestamp, note_id))
                                conn.commit()
                                # é€€å‡ºç¼–è¾‘æ¨¡å¼
                                st.session_state.editing_note_id = None
                                st.rerun()
                    
                    with col_cancel:
                        if st.button("âŒ å–æ¶ˆ", key=f"cancel_{note_id}"):
                            # é€€å‡ºç¼–è¾‘æ¨¡å¼ï¼Œä¸ä¿å­˜
                            st.session_state.editing_note_id = None
                            st.rerun()
                    # <<<<< ç¼–è¾‘æ¨¡å¼ç»“æŸ <<<<<

                else:
                    # >>>>> æµè§ˆæ¨¡å¼ç•Œé¢ >>>>>
                    # 1. æ ‡é¢˜è¡Œ
                    col_title, col_time = st.columns([3, 1])
                    with col_title:
                        st.markdown(f"**{note['title']}**")
                    with col_time:
                        t_str = pd.to_datetime(note['created_at']).strftime('%Y-%m-%d %H:%M')
                        st.caption(f"ğŸ“… {t_str}")

                    # 2. æ­£æ–‡ (å·²ä¿®å¤æ¢è¡Œæ˜¾ç¤ºé—®é¢˜)
                    st.markdown(note['content'].replace('\n', '  \n'))
                    
                    # 3. åº•éƒ¨æ“ä½œæ 
                    st.divider()
                    f_c1, f_c2, f_c3 = st.columns([4, 1, 1])
                    
                    with f_c1:
                        # æ˜¾ç¤ºæœ€åä¿®æ”¹æ—¶é—´
                        if note['updated_at'] != note['created_at']:
                            up_str = pd.to_datetime(note['updated_at']).strftime('%Y-%m-%d %H:%M')
                            st.caption(f"ğŸ“ ä¿®æ”¹äº: {up_str}")
                    
                    with f_c2:
                        # ç‚¹å‡»ç¼–è¾‘ï¼Œæ›´æ–° stateï¼Œè§¦å‘ rerunï¼Œä¸‹ä¸€æ¬¡æ¸²æŸ“å°±ä¼šè¿›å…¥ä¸Šé¢çš„ if åˆ†æ”¯
                        if st.button("âœï¸ ç¼–è¾‘", key=f"btn_edit_{note_id}"):
                            st.session_state.editing_note_id = note_id
                            st.rerun()
                    
                    with f_c3:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"btn_del_{note_id}"):
                            conn.execute('DELETE FROM investment_notes WHERE note_id = ?', (note_id,))
                            conn.commit()
                            st.success("å·²åˆ é™¤")
                            st.rerun()
                    # <<<<< æµè§ˆæ¨¡å¼ç»“æŸ <<<<<
    
    conn.close()

def page_fire_projection():
    import pandas as pd            # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    import plotly.graph_objects as go  # ğŸ‘ˆ åŠ ä¸Šè¿™å¥
    st.header("ğŸ”¥ FIRE è´¢å¯Œè‡ªç”±å±•æœ› 2.0")
    st.caption("å¼•å…¥é€šèƒ€è°ƒèŠ‚ä¸é£é™©åŒºé—´ï¼Œè¿˜åŸæœ€çœŸå®çš„è´¢å¯Œè‡ªç”±ä¹‹è·¯ã€‚")
    
    user_id = st.session_state.user['user_id']
    conn = get_db_connection()
    
    # --- 1. è·å–å½“å‰æ€»èµ„äº§ (èµ·ç‚¹) ---
    rates_map = get_latest_rates(conn)
    latest_date_row = conn.execute('SELECT MAX(date) as d FROM snapshots JOIN assets ON snapshots.asset_id = assets.asset_id WHERE assets.user_id = ?', (user_id,)).fetchone()
    
    current_total_assets_cny = 0.0
    start_year = datetime.now().year
    
    if latest_date_row and latest_date_row['d']:
        latest_date = latest_date_row['d']
        rows = conn.execute('''
            SELECT s.amount, a.currency
            FROM snapshots s
            JOIN assets a ON s.asset_id = a.asset_id
            WHERE a.user_id = ? AND s.date = ?
        ''', (user_id, latest_date)).fetchall()
        
        for row in rows:
            amt = row['amount']
            curr = row['currency']
            rate = 1.0 if curr == 'CNY' else rates_map.get(curr, 1.0)
            current_total_assets_cny += amt * rate
            
    conn.close()

    # --- 2. å‚æ•°è®¾ç½®åŒºåŸŸ ---
    with st.expander("ğŸ› ï¸ æ ¸å¿ƒå‚æ•°è®¾å®š", expanded=True):
        c1, c2, c3 = st.columns(3)
        with c1:
            base_amount_wan = st.number_input("å½“å‰æ€»èµ„äº§ (ä¸‡ CNY)", value=float(current_total_assets_cny) / 10000.0, step=1.0, format="%.2f")
            base_amount = base_amount_wan * 10000
            
            annual_addition_wan = st.number_input("æ¯å¹´å®šæŠ•/è¿½åŠ  (ä¸‡)", value=20.0, step=1.0)
            annual_addition = annual_addition_wan * 10000

        with c2:
            current_age = st.number_input("å½“å‰å¹´é¾„", value=28, step=1)
            
            annual_rate = st.number_input("é¢„æœŸå¹´åŒ–æ”¶ç›Šç‡ (%)", value=8.0, step=0.5, help="é•¿æœŸæ¥çœ‹ï¼Œæ ‡æ™®500çº¦ 8-10%")
            
        with c3:
            inflation_rate = st.number_input("é¢„ä¼°é€šèƒ€ç‡ (%)", value=3.0, step=0.1)
            target_monthly_expense = st.number_input("ç†æƒ³æœˆç”Ÿæ´»è´¹ (å…ƒ)", value=10000, step=1000)

    st.divider()

    # --- 3. 4% æ³•åˆ™ä»ªè¡¨ç›˜ ---
    safe_withdrawal_rate = 0.04
    monthly_passive_income = (base_amount * safe_withdrawal_rate) / 12
    coverage_ratio = (monthly_passive_income / target_monthly_expense) * 100
    fire_number = (target_monthly_expense * 12) / safe_withdrawal_rate
    
    kpi1, kpi2, kpi3 = st.columns(3)
    with kpi1:
        st.metric("å½“å‰æ¯æœˆè¢«åŠ¨æ”¶å…¥ (4%)", f"Â¥{monthly_passive_income:,.0f}", help="æŒ‰4%æ³•åˆ™æå–çš„æœˆå®‰å…¨æ”¶å…¥")
    with kpi2:
        st.metric("ç”Ÿæ´»è´¹è¦†ç›–ç‡", f"{coverage_ratio:.1f}%", delta=f"å·® {100-coverage_ratio:.1f}%" if coverage_ratio < 100 else "å·²è¾¾æˆï¼", delta_color="normal" if coverage_ratio < 100 else "inverse")
        st.progress(min(1.0, coverage_ratio / 100))
    with kpi3:
        st.metric("FIRE ç›®æ ‡é‡‘é¢", f"Â¥{fire_number/10000:.0f}ä¸‡", delta=f"å½“å‰: {base_amount/10000:.0f}ä¸‡")

    st.divider()

    # --- 4. å¤åˆ©ä¸é£é™©æ¨æ¼”è®¡ç®— ---
    years_to_project = 40
    projection_data = []
    
    curr_bal = base_amount
    curr_principal = base_amount
    
    # åˆå§‹å¹´ä»½æ•°æ®
    projection_data.append({
        "year": start_year, "age": current_age,
        "balance": curr_bal, "balance_real": curr_bal,
        "principal": curr_principal
    })

    for i in range(1, years_to_project + 1):
        # æ ¸å¿ƒå¤åˆ©å…¬å¼
        curr_bal = curr_bal * (1 + annual_rate / 100.0) + annual_addition
        curr_principal += annual_addition
        
        # çœŸå®è´­ä¹°åŠ› (å‰”é™¤é€šèƒ€)
        real_purchasing_power = curr_bal / ((1 + inflation_rate / 100.0) ** i)
        
        projection_data.append({
            "year": start_year + i, "age": current_age + i,
            "balance": curr_bal, "balance_real": real_purchasing_power,
            "principal": curr_principal
        })

    df_proj = pd.DataFrame(projection_data)
    # å•ä½æ¢ç®—ä¸ºâ€œä¸‡â€
    cols_to_convert = ['balance', 'balance_real', 'principal']
    for c in cols_to_convert: df_proj[f'{c}_w'] = df_proj[c] / 10000

    # --- 5. ç»˜å›¾ (Plotly) ---
    st.subheader("ğŸ“ˆ èµ„äº§æ¨æ¼”ï¼šåä¹‰ vs çœŸå®")
    
    fig = go.Figure()

    # A. åä¹‰æ€»èµ„äº§
    fig.add_trace(go.Scatter(
        x=df_proj['age'], y=df_proj['balance_w'],
        mode='lines',
        name='åä¹‰é¢„æœŸ',
        line=dict(color='#2E86C1', width=3),
        customdata=df_proj['year'],
        hovertemplate='<b>âš–ï¸ åä¹‰é¢„æœŸ</b><br>å¹´ä»½: %{customdata}<br>èµ„äº§: <b>%{y:.0f}ä¸‡</b><extra></extra>'
    ))

    # B. çœŸå®è´­ä¹°åŠ›
    fig.add_trace(go.Scatter(
        x=df_proj['age'], y=df_proj['balance_real_w'],
        mode='lines',
        name='çœŸå®è´­ä¹°åŠ› (å‰”é™¤é€šèƒ€)',
        line=dict(color='#E74C3C', width=3, dash='dash'),
        customdata=df_proj['year'],
        hovertemplate='<b>ğŸ” çœŸå®è´­ä¹°åŠ›</b><br>å¹´ä»½: %{customdata}<br>æŠ˜åˆç°å€¼: <b>%{y:.0f}ä¸‡</b><extra></extra>'
    ))

    # C. æŠ•å…¥æœ¬é‡‘
    fig.add_trace(go.Scatter(
        x=df_proj['age'], y=df_proj['principal_w'],
        mode='lines',
        name='æŠ•å…¥æœ¬é‡‘',
        line=dict(color='#95A5A6', width=2, dash='dot'),
        customdata=df_proj['year'],
        hovertemplate='ğŸŒ± ç´¯è®¡æœ¬é‡‘: %{y:.0f}ä¸‡<extra></extra>'
    ))

    fig.update_layout(
        xaxis_title="å¹´é¾„", yaxis_title="é‡‘é¢ (ä¸‡)",
        hovermode="x unified",
        legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01),
        height=500
    )
    st.plotly_chart(fig, use_container_width=True)

    # --- 6. å…³é”®æ•°æ®è§£è¯» ---
    # æ‰¾20å¹´åçš„æ•°æ®
    target_year_20 = df_proj.iloc[20]

    st.info(f"""
    **ğŸ’¡ æ·±åº¦è§£è¯» (20å¹´å / {int(target_year_20['year'])}å¹´)ï¼š**
    
    * **è´¦é¢å¯Œè´µ**ï¼šæŒ‰ç…§é¢„æœŸï¼Œ20å¹´åä½ çš„è´¦æˆ·é‡Œä¼šæœ‰ **{target_year_20['balance_w']:.0f}ä¸‡**ã€‚
    * **çœŸå®ç¼©æ°´**ï¼šä½†åœ¨ {inflation_rate}% çš„é€šèƒ€ä¸‹ï¼Œè¿™ç¬”é’±çš„è´­ä¹°åŠ›åªç›¸å½“äºä»Šå¤©çš„ **{target_year_20['balance_real_w']:.0f}ä¸‡**ã€‚
    * **å¯¹æŠ—é€šèƒ€**ï¼šåªè¦ã€åä¹‰é¢„æœŸã€‘é‚£æ¡è“çº¿è·‘èµ¢äº†ã€çœŸå®è´­ä¹°åŠ›ã€‘çº¢è™šçº¿ï¼Œå°±è¯´æ˜ä½ çš„è´¢å¯Œåœ¨å¢å€¼ã€‚
    """, icon="ğŸ§")

    # --- 7. æ•°æ®è¡¨ ---
    with st.expander("æŸ¥çœ‹è¯¦ç»†æ¨æ¼”æ•°æ®"):
        st.dataframe(
            df_proj[['age', 'year', 'balance_w', 'balance_real_w', 'principal_w']],
            column_config={
                "age": "å¹´é¾„",
                "year": "å¹´ä»½",
                "balance_w": st.column_config.NumberColumn("åä¹‰èµ„äº§ (ä¸‡)", format="%.0f"),
                "balance_real_w": st.column_config.NumberColumn("çœŸå®è´­ä¹°åŠ› (ä¸‡)", format="%.0f"),
                "principal_w": st.column_config.NumberColumn("ç´¯è®¡æœ¬é‡‘ (ä¸‡)", format="%.0f"),
            },
            hide_index=True,
            use_container_width=True
        )
  
# --- å¤‡ä»½æ ¸å¿ƒé€»è¾‘ ---
def send_email_backup(filepath, settings):
    """å‘é€å¸¦æœ‰æ•°æ®åº“é™„ä»¶çš„é‚®ä»¶ (ä¿®å¤ SSL å…³é—­æŠ¥é”™ç‰ˆ)"""
    if not settings['email_host'] or not settings['email_user'] or not settings['email_password']:
        return False, "é‚®ç®±é…ç½®ä¸å®Œæ•´"

    try:
        msg = MIMEMultipart()
        msg['Subject'] = f'ã€è‡ªåŠ¨å¤‡ä»½ã€‘èµ„äº§æ•°æ®å¤‡ä»½ - {datetime.now().strftime("%Y-%m-%d")}'
        msg['From'] = settings['email_user']
        msg['To'] = settings['email_to'] if settings['email_to'] else settings['email_user']
        
        # æ­£æ–‡
        body = "è¿™æ˜¯æ‚¨çš„ä¸ªäººèµ„äº§ç®¡ç†ç³»ç»Ÿæ•°æ®åº“è‡ªåŠ¨å¤‡ä»½ï¼Œè¯·å¦¥å–„ä¿ç®¡ã€‚\n\n"
        body += f"å¤‡ä»½æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        msg.attach(MIMEText(body, 'plain'))

        # é™„ä»¶
        filename = os.path.basename(filepath)
        with open(filepath, "rb") as f:
            part = MIMEApplication(f.read(), Name=filename)
            part['Content-Disposition'] = f'attachment; filename="{filename}"'
            msg.attach(part)

        # --- æ ¸å¿ƒä¿®æ”¹å¼€å§‹ï¼šæ‰‹åŠ¨ç®¡ç†è¿æ¥ï¼Œå¿½ç•¥é€€å‡ºé”™è¯¯ ---
        server = smtplib.SMTP_SSL(settings['email_host'], settings['email_port'])
        try:
            server.login(settings['email_user'], settings['email_password'])
            server.send_message(msg)
            
            # é‚®ä»¶å·²å‘é€æˆåŠŸï¼Œå°è¯•ç¤¼è²Œé€€å‡ºï¼Œä½†å¦‚æœæŠ¥é”™åˆ™å¿½ç•¥
            try:
                server.quit()
            except Exception:
                pass  # å¿½ç•¥ (-1, b'\x00\x00\x00') è¿™ç§é€€å‡ºé”™è¯¯
            
            return True, "é‚®ä»¶å‘é€æˆåŠŸ"
            
        except Exception as e:
            # åªæœ‰å‘é€è¿‡ç¨‹ä¸­çš„é”™è¯¯æ‰æ˜¯çœŸæ­£çš„å¤±è´¥
            return False, f"å‘é€ä¸­æ–­: {str(e)}"
        finally:
            # ç¡®ä¿è¿æ¥å…³é—­
            try:
                server.close()
            except Exception:
                pass
        # --- æ ¸å¿ƒä¿®æ”¹ç»“æŸ ---

    except Exception as e:
        return False, f"é‚®ä»¶å‡†å¤‡å¤±è´¥: {str(e)}"

def generate_and_send_ai_prompt(user_id, target_group, start_date_str, end_date_str):
    """
    ç”Ÿæˆ AI é¡¾é—®æç¤ºè¯ (CIO å®è§‚è§†è§’ç‰ˆ - åŒ…å«ç²¾å‡†æ°´ä½ä¸æœ¬é‡‘åˆ†æ)
    """
    import pandas as pd
    import smtplib
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    
    conn = get_db_connection()
    
    # --- 1. è·å–ç³»ç»Ÿè®¾ç½® ---
    settings = conn.execute('SELECT * FROM system_settings WHERE id = 1').fetchone()
    if not settings['email_host']:
        conn.close()
        return False, "æœªé…ç½®é‚®ç®± SMTPï¼Œæ— æ³•å‘é€ã€‚"

    # --- 2. æœé›†ä¸è®¡ç®—æ ¸å¿ƒæ•°æ® (å¯¹é½çœ‹æ¿é€»è¾‘) ---
    # A. è·å–èµ„äº§å¿«ç…§
    df_assets, df_tags = get_cached_analytics_data(user_id)
    
    if df_assets is None or df_assets.empty:
        conn.close()
        return False, "æš‚æ— èµ„äº§æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆåˆ†æã€‚"

    # è½¬æ¢æ—¥æœŸæ ¼å¼
    start_date = pd.to_datetime(start_date_str)
    end_date = pd.to_datetime(end_date_str)

    # B. å‡†å¤‡æ¯æ—¥æ€»èµ„äº§ (Amount)
    daily_monitor = df_assets.groupby('date')[['amount']].sum().reset_index().sort_values('date')
    
    # C. å‡†å¤‡çœŸå®æœ¬é‡‘ (Cashflows) - æ ¸å¿ƒé€»è¾‘å¤ç”¨
    df_cf = pd.read_sql("SELECT date, type, amount FROM cashflows WHERE user_id = ?", conn, params=(user_id,))
    
    # åˆå§‹åŒ–æœ¬é‡‘åˆ—
    daily_monitor['final_principal'] = 0.0
    
    if not df_cf.empty:
        df_cf['date'] = pd.to_datetime(df_cf['date'])
        # æ”¶å…¥=+ï¼Œæ”¯å‡º=-
        df_cf['net_flow'] = df_cf.apply(lambda x: x['amount'] if x['type'] == 'æ”¶å…¥' else -x['amount'], axis=1)
        # è®¡ç®—ç´¯è®¡å‡€æŠ•å…¥
        df_principal = df_cf.groupby('date')['net_flow'].sum().sort_index().cumsum().reset_index()
        df_principal.rename(columns={'net_flow': 'cumulative_principal'}, inplace=True)
        # åˆå¹¶
        daily_monitor = pd.merge_asof(daily_monitor, df_principal, on='date', direction='backward')
        daily_monitor['final_principal'] = daily_monitor['cumulative_principal'].fillna(0)
    else:
        # å¦‚æœæ²¡ç°é‡‘æµè®°å½•ï¼Œé™çº§ä½¿ç”¨ Cost (è™½ä¸å‡†ä½†æ¯”æŠ¥é”™å¥½)
        daily_cost = df_assets.groupby('date')[['cost']].sum().reset_index()
        daily_monitor = pd.merge(daily_monitor, daily_cost, on='date', how='left')
        daily_monitor['final_principal'] = daily_monitor['cost']

    # D. è®¡ç®—æ¯æ—¥æ”¶ç›Š (Profit)
    daily_monitor['profit'] = daily_monitor['amount'] - daily_monitor['final_principal']

    # --- 3. æå–å…³é”®èŠ‚ç‚¹æ•°æ® ---
    
    # è·å– èµ·ç‚¹(Start) å’Œ ç»ˆç‚¹(End) çš„è¡Œæ•°æ®
    # ä½¿ç”¨ asof æˆ–ç›´æ¥æŸ¥æ‰¾ (è¿™é‡Œå‡è®¾ start_date å¯èƒ½ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œç”¨ asof æ‰¾æœ€è¿‘çš„å‰ä¸€å¤©æ¯”è¾ƒç¨³å¦¥ï¼Œæˆ–è€…ç²¾ç¡®åŒ¹é…)
    # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œå…ˆå°è¯•ç²¾ç¡®åŒ¹é…ï¼ŒåŒ¹é…ä¸åˆ°æ‰¾æœ€è¿‘çš„
    
    def get_closest_row(target_date):
        # æ‰¾å°äºç­‰äº target_date çš„æœ€åä¸€æ¡
        mask = daily_monitor['date'] <= target_date
        if not mask.any(): return None
        return daily_monitor[mask].iloc[-1]

    row_start = get_closest_row(start_date)
    row_end = get_closest_row(end_date)

    if row_end is None:
        conn.close()
        return False, f"æ‰¾ä¸åˆ° {end_date_str} ä¹‹å‰çš„ä»»ä½•æ•°æ®ã€‚"

    # æå–ç«¯ç‚¹å€¼
    # æœŸåˆ
    s_amt = row_start['amount'] if row_start is not None else 0.0
    s_prin = row_start['final_principal'] if row_start is not None else 0.0
    s_prof = row_start['profit'] if row_start is not None else 0.0
    
    # æœŸæœ«
    e_amt = row_end['amount']
    e_prin = row_end['final_principal']
    e_prof = row_end['profit']
    
    # è®¡ç®—æœŸé—´å˜åŠ¨
    period_yield_val = e_prof - s_prof # æœŸé—´äº§ç”Ÿçš„åˆ©æ¶¦
    # æœŸé—´æ”¶ç›Šç‡ (åˆ†æ¯ç”¨ æœŸåˆæœ¬é‡‘ æˆ– æœŸåˆèµ„äº§ï¼Œè¿™é‡Œç”¨æœŸåˆèµ„äº§ä½œä¸ºå‚è€ƒ)
    period_yield_pct = (period_yield_val / s_amt * 100) if s_amt > 0 else 0.0

    # --- 4. è®¡ç®—å…­å¤§æ°´ä½æŒ‡æ ‡ (åŸºäºæˆªè‡³ End Date çš„å†å²æ•°æ®) ---
    # æˆªå–å†å²åˆ‡ç‰‡ (ç›´åˆ°å¤ç›˜ç»“æŸé‚£ä¸€å¤©)
    history_slice = daily_monitor[daily_monitor['date'] <= end_date].copy()
    
    # 1. å½“å‰èµ„äº§ (End Date)
    curr_asset = e_amt
    
    # 2. å†å²æœ€é«˜ (ATH)
    ath_asset = history_slice['amount'].max()
    
    # 3. å›æ’¤è®¡ç®—
    history_slice['rolling_max'] = history_slice['amount'].cummax()
    history_slice['dd_amt'] = history_slice['rolling_max'] - history_slice['amount']
    # å¤„ç†åˆ†æ¯0
    history_slice['dd_pct'] = 0.0
    mask = history_slice['rolling_max'] > 0
    history_slice.loc[mask, 'dd_pct'] = (history_slice.loc[mask, 'dd_amt'] / history_slice.loc[mask, 'rolling_max']) * 100
    
    # å½“å‰å›æ’¤ (End Date)
    curr_dd_pct = history_slice.iloc[-1]['dd_pct']
    curr_dd_amt = history_slice.iloc[-1]['dd_amt']
    
    # å†å²æœ€å¤§å›æ’¤ (åœ¨ End Date ä¹‹å‰å‘ç”Ÿè¿‡çš„æœ€æƒ¨å›æ’¤)
    max_dd_pct = history_slice['dd_pct'].max()
    max_dd_amt = history_slice['dd_amt'].max()
    
    # 4. æ”¶ç›ŠæŒ‡æ ‡
    curr_profit = e_prof
    max_profit = history_slice['profit'].max() # å†å²æœ€é«˜ç´¯è®¡æ”¶ç›Š

    # --- 5. æ ¸å¿ƒæŒä»“ç»“æ„ (å æ¯” > 0.5%) ---
    target_assets = df_assets[df_assets['date'] == end_date].copy()
    target_assets = target_assets.sort_values('amount', ascending=False)
    target_assets['ratio'] = target_assets['amount'] / e_amt if e_amt > 0 else 0
    
    significant_assets = target_assets[target_assets['ratio'] > 0.005]
    
    holdings_str = ""
    if significant_assets.empty:
        holdings_str = "æ— å•ä¸€èµ„äº§å æ¯”è¶…è¿‡ 0.5%ã€‚"
    else:
        for i, row in significant_assets.iterrows():
            currency_info = f" ({row['currency']})" if 'currency' in row and row['currency'] != 'CNY' else ""
            holdings_str += f"- {row['name']}{currency_info}: Â¥{row['amount']:,.0f} (å æ¯” {row['ratio']*100:.2f}%)\n"

    # --- 6. ç»´åº¦é…ç½®å˜åŒ–å¤ç›˜ (Start vs End) ---
    analysis_str = ""
    if df_tags is not None and not df_tags.empty:
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦é‡æ–°æŒ‰ç…§ start_date å’Œ end_date ç­›é€‰ tags æ•°æ®
        # å› ä¸º df_tags æ˜¯é¢„è®¡ç®—å¥½çš„ï¼Œå¯ä»¥ç›´æ¥è¿‡æ»¤
        tags_start = df_tags[(df_tags['date'] == start_date) & (df_tags['tag_group'] == target_group)].copy()
        tags_end = df_tags[(df_tags['date'] == end_date) & (df_tags['tag_group'] == target_group)].copy()
        
        # å¦‚æœ precise match å¤±è´¥ï¼Œå°è¯•æ‰¾æœ€è¿‘çš„ (ç®€å•å¤„ç†ï¼šå¦‚æœä¸ºç©ºå°±ä¸å±•ç¤ºäº†ï¼Œæˆ–è€…ä½ å¯ä»¥åŠ ç±»ä¼¼ get_closest çš„é€»è¾‘)
        # è¿™é‡Œä¿æŒåŸé€»è¾‘ï¼Œå‡è®¾ tags æ•°æ®æ˜¯è¿ç»­çš„
        
        tags_start = tags_start[['tag_name', 'amount']].rename(columns={'amount': 's_amt'})
        tags_end = tags_end[['tag_name', 'amount']].rename(columns={'amount': 'e_amt'})
        
        df_compare = pd.merge(tags_end, tags_start, on='tag_name', how='outer').fillna(0)
        
        df_compare['s_ratio'] = (df_compare['s_amt'] / s_amt * 100) if s_amt > 0 else 0.0
        df_compare['e_ratio'] = (df_compare['e_amt'] / e_amt * 100) if e_amt > 0 else 0.0
        
        df_compare = df_compare.sort_values('e_amt', ascending=False)
        
        analysis_str += f"åŸºäºã€{target_group}ã€‘ç»´åº¦çš„å˜åŒ–å¯¹æ¯”ï¼š\n"
        for _, row in df_compare.iterrows():
            if row['s_amt'] < 100 and row['e_amt'] < 100: continue
            analysis_str += (
                f"- **{row['tag_name']}**:\n"
                f"  - èµ„é‡‘: Â¥{row['s_amt']:,.0f} â¡ï¸ Â¥{row['e_amt']:,.0f}\n"
                f"  - å æ¯”: {row['s_ratio']:.1f}% â¡ï¸ {row['e_ratio']:.1f}%\n"
            )
    else:
        analysis_str = "(æš‚æ— æ ‡ç­¾æ•°æ®)"

    conn.close()

    # --- 7. ç»„è£… Prompt æ¨¡æ¿ (æ›´æ–°ç‰ˆ) ---
    prompt_content = f"""
===== è¯·å°†ä»¥ä¸‹å†…å®¹å®Œæ•´å‘é€ç»™ AI (å¦‚ ChatGPT/Claude) =====

# Role / è§’è‰²è®¾å®š
**ä½ æ˜¯ä¸€ä½æ‹¥æœ‰åå°”è¡—é¡¶çº§æŠ•è¡ŒèƒŒæ™¯çš„é¦–å¸­æŠ•èµ„å®˜ (CIO)ã€‚**
ä½ ç²¾é€šå…¨çƒå®è§‚ç»æµåˆ†æã€å¤§ç±»èµ„äº§é…ç½®ç­–ç•¥ï¼ˆå¦‚è€¶é²æ¨¡å¼ã€å…¨å¤©å€™ç­–ç•¥ï¼‰ä»¥åŠè¡Œä¸ºé‡‘èå­¦ã€‚ä½ ä¸ä»…å…³æ³¨è´¦æˆ·çš„ç»å¯¹æ•°å­—ï¼Œæ›´æ“…é•¿å°†ä¸ªäººæŠ•èµ„ç»„åˆçš„è¡¨ç°ç½®äºå®è§‚å¸‚åœºèƒŒæ™¯ä¸‹è¿›è¡Œâ€œå½’å› åˆ†æâ€ã€‚ä½ çš„åˆ†æé£æ ¼æ˜¯ï¼šå®¢è§‚ã€çŠ€åˆ©ã€æ•°æ®é©±åŠ¨ï¼Œå¹¶èƒ½ç»™å‡ºå¯è½åœ°çš„æˆ˜æœ¯å»ºè®®ã€‚

# Context / å¤ç›˜èƒŒæ™¯
- **å¤ç›˜å‘¨æœŸ**ï¼š{start_date_str} è‡³ {end_date_str}
- **ç”¨æˆ·ç”»åƒ**ï¼šä¸­å›½ä¸ªäººæŠ•èµ„è€…ï¼Œä»¥äººæ°‘å¸è®¡ä»·ã€‚

# Internal Data / å†…éƒ¨æŠ•èµ„ç»„åˆæ•°æ®

## 1. èµ„é‡‘é¢æ¦‚å†µ (Financial Overview)

### A. å‘¨æœŸç«¯ç‚¹å¿«ç…§ (Snapshot)
- **æœŸåˆ ({start_date_str})**:
  - æŠ•å…¥æœ¬é‡‘: Â¥{s_prin:,.0f}
  - ç´¯è®¡æ”¶ç›Š: Â¥{s_prof:,.0f}
  - èµ„äº§æ€»å€¼: Â¥{s_amt:,.0f}
- **æœŸæœ« ({end_date_str})**:
  - æŠ•å…¥æœ¬é‡‘: Â¥{e_prin:,.0f}
  - ç´¯è®¡æ”¶ç›Š: Â¥{e_prof:,.0f}
  - èµ„äº§æ€»å€¼: Â¥{e_amt:,.0f}

**ğŸ‘‰ æœŸé—´å˜åŒ–**: æœ¬é‡‘æŠ•å…¥å˜åŠ¨ Â¥{e_prin - s_prin:+,.0f}ï¼ŒæœŸé—´åˆ›é€ åˆ©æ¶¦ Â¥{period_yield_val:+,.0f}ã€‚

### B. é£é™©æ°´ä½ç›‘æ§ (æˆªè‡³æœŸæœ« {end_date_str})
> ä»¥ä¸‹æŒ‡æ ‡åŸºäºå…¨å†å²æ•°æ®ç»Ÿè®¡ï¼š
- **å½“å‰æ€»èµ„äº§**: Â¥{curr_asset:,.0f} (å†å²æœ€é«˜ ATH: Â¥{ath_asset:,.0f})
- **å½“å‰å›æ’¤**: {curr_dd_pct:.2f}% (æµ®äºé‡‘é¢: -Â¥{curr_dd_amt:,.0f})
- **å†å²æœ€å¤§å›æ’¤**: {max_dd_pct:.2f}% (æœ€å¤§äºæŸé¢: -Â¥{max_dd_amt:,.0f})
- **å½“å‰ç´¯è®¡æ”¶ç›Š**: Â¥{curr_profit:,.0f} (å†å²æœ€é«˜æ”¶ç›Š: Â¥{max_profit:,.0f})

## 2. æ ¸å¿ƒæŒä»“ (Top Holdings > 0.5%)
{holdings_str}

## 3. ç»“æ„æ¼”å˜ (ç»´åº¦ï¼š{target_group})
{analysis_str}

---

# Action Required / ä½ çš„ä»»åŠ¡
è¯·åŠ¡å¿…æ‰§è¡Œä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ†æï¼š

## ç¬¬ä¸€æ­¥ï¼šå¤–éƒ¨å¸‚åœºç¯å¢ƒæ‰«æ (å¿…é¡»è”ç½‘æœç´¢)
è¯·åˆ©ç”¨ä½ çš„è”ç½‘èƒ½åŠ›ï¼Œ**æŸ¥è¯¢ {start_date_str} è‡³ {end_date_str} æœŸé—´çš„ä»¥ä¸‹å¸‚åœºæ•°æ®**ï¼Œä½œä¸ºåˆ†æçš„åŸºå‡†é”šç‚¹ï¼š
1.  **å…³é”®æŒ‡æ•°è¡¨ç°**ï¼šçº³æ–¯è¾¾å…‹100 (NDX)ã€æ ‡æ™®500 (SPX)ã€é»„é‡‘ (Gold)ã€‚
2.  **æ ¸å¿ƒå®è§‚äº‹ä»¶**ï¼šæœŸé—´æ˜¯å¦æœ‰ç¾è”å‚¨è®®æ¯ã€é‡å¤§åœ°ç¼˜æ”¿æ²»äº‹ä»¶ã€æˆ–ç§‘æŠ€å·¨å¤´(å¦‚ NVDA/AAPL)çš„è´¢æŠ¥å‘å¸ƒï¼Ÿ

## ç¬¬äºŒæ­¥ï¼šæ·±åº¦å½’å› åˆ†æ
åŸºäºæŸ¥è¯¢åˆ°çš„å¤–éƒ¨æ•°æ®å’Œä¸Šè¿°å†…éƒ¨æ•°æ®ï¼Œå›ç­”ä»¥ä¸‹ä¸¤ä¸ªé—®é¢˜ï¼š

### 1. é£é™©ä¸æ”¶ç›Šè¯„ä¼° (Risk & Return)
- **æ°´ä½åˆ†æ**ï¼šç”¨æˆ·å½“å‰çš„ç´¯è®¡æ”¶ç›Š ({curr_profit:,.0f}) è·ç¦»å†å²æœ€é«˜æ”¶ç›Š ({max_profit:,.0f}) è¿˜æœ‰å¤šè¿œï¼Ÿç»“åˆå½“å‰çš„å›æ’¤æ°´å¹³ ({curr_dd_pct:.2f}%)ï¼Œè¯„ä»·å½“å‰è´¦æˆ·çš„â€œå®‰å…¨å«â€åšåº¦ã€‚
- **é˜¿å°”æ³•éªŒè¯**ï¼šç”¨æˆ·çš„æœŸé—´åˆ©æ¶¦ ({period_yield_val:+,.0f}) æ˜¯æ¥è‡ªå¸‚åœºçš„ Beta æ™®æ¶¨ï¼Œè¿˜æ˜¯ç”¨æˆ·çš„ Alpha é€‰æ‹©ï¼Ÿ(å¯¹æ¯”åŒæœŸçš„æŒ‡æ•°è¡¨ç°)

### 2. æˆ˜æœ¯å»ºè®® (Tactical Advice)
- **å†å¹³è¡¡æŒ‡å¼•**ï¼šåŸºäºæœŸæœ«çš„æŒä»“ç»“æ„å’Œå½“å‰å®è§‚ç¯å¢ƒï¼Œç»™å‡ºå…·ä½“çš„è°ƒä»“å»ºè®®ã€‚

================================
    """

    # --- 8. å‘é€é‚®ä»¶ ---
    try:
        msg = MIMEMultipart()
        msg['Subject'] = f'ğŸ¤– AI å®è§‚å¯¹å†²å¤ç›˜ ({start_date_str} ~ {end_date_str})'
        msg['From'] = settings['email_user']
        msg['To'] = settings['email_to'] if settings['email_to'] else settings['email_user']
        
        body = "è¿™æ˜¯ä¸ºæ‚¨è‡ªåŠ¨ç”Ÿæˆçš„ CIO çº§æ·±åº¦å¤ç›˜æç¤ºè¯ã€‚\n\n" + prompt_content
        msg.attach(MIMEText(body, 'plain'))

        server = smtplib.SMTP_SSL(settings['email_host'], settings['email_port'])
        server.login(settings['email_user'], settings['email_password'])
        server.send_message(msg)
        server.quit()
        
        return True, f"å·²å‘é€ {start_date_str} è‡³ {end_date_str} çš„æ·±åº¦åˆ†ææç¤ºè¯ï¼"
    except Exception as e:
        return False, f"é‚®ä»¶å‘é€å¤±è´¥: {str(e)}"
    
def perform_backup(manual=False):
    """æ‰§è¡Œå¤‡ä»½ï¼š1.æœ¬åœ°å¤åˆ¶ 2.å‘é€é‚®ä»¶ 3.æ›´æ–°æ—¶é—´"""
    conn = get_db_connection()
    settings = conn.execute('SELECT * FROM system_settings WHERE id = 1').fetchone()
    
    # 1. å‡†å¤‡ç›®å½•
    backup_dir = "backups"
    if not os.path.exists(backup_dir):
        os.makedirs(backup_dir)
        
    # 2. ç”Ÿæˆæœ¬åœ°å¤‡ä»½æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"asset_tracker_{timestamp}.db"
    backup_path = os.path.join(backup_dir, filename)
    
    try:
        # ä¸ºäº†é˜²æ­¢å¤åˆ¶æ—¶æ•°æ®åº“æ­£åœ¨å†™å…¥ï¼Œè™½ç„¶ sqlite å…è®¸è¯»æ—¶å¤åˆ¶ï¼Œä½†ç¨³å¦¥èµ·è§æˆ‘ä»¬ç”¨ connection çš„ backup API æˆ–è€…ç®€å• copy
        # ç®€å• copy å¯¹äºå•ç”¨æˆ·ç³»ç»Ÿé€šå¸¸è¶³å¤Ÿ
        shutil.copy2(DB_FILE, backup_path)
        
        log_msg = f"æœ¬åœ°å¤‡ä»½å·²ä¿å­˜: {filename}"
        email_status = "æœªé…ç½®é‚®ä»¶"
        
        # 3. å‘é€é‚®ä»¶
        if settings['email_host']:
            success, msg = send_email_backup(backup_path, settings)
            email_status = "é‚®ä»¶å·²å‘é€" if success else f"é‚®ä»¶å¤±è´¥: {msg}"
        
        # 4. æ›´æ–°ä¸Šæ¬¡å¤‡ä»½æ—¶é—´
        now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        conn.execute('UPDATE system_settings SET last_backup_at = ? WHERE id = 1', (now_str,))
        conn.commit()
        
        conn.close()
        return True, f"{log_msg} | {email_status}"
    
    except Exception as e:
        conn.close()
        return False, f"å¤‡ä»½å‡ºé”™: {e}"

def auto_backup_check():
    """åœ¨ App å¯åŠ¨/è¿è¡Œæ—¶è¢«åŠ¨æ£€æŸ¥æ˜¯å¦éœ€è¦å¤‡ä»½"""
    conn = get_db_connection()
    try:
        row = conn.execute('SELECT backup_frequency, last_backup_at FROM system_settings WHERE id = 1').fetchone()
        if not row: return

        freq = row['backup_frequency']
        last_at = row['last_backup_at']
        
        if freq == 'å…³é—­':
            return
            
        should_backup = False
        now = datetime.now()
        
        if not last_at:
            should_backup = True
        else:
            last_date = datetime.strptime(last_at, '%Y-%m-%d %H:%M:%S')
            delta = now - last_date
            
            if freq == 'æ¯å¤©' and delta.days >= 1:
                should_backup = True
            elif freq == 'æ¯å‘¨' and delta.days >= 7:
                should_backup = True
            elif freq == 'æ¯æœˆ' and delta.days >= 30:
                should_backup = True
        
        if should_backup:
            # æ‰§è¡Œå¤‡ä»½ (ä¸é˜»å¡ UI å¤ªä¹…ï¼Œä½¿ç”¨ toast æç¤º)
            st.toast("æ­£åœ¨åå°æ‰§è¡Œè‡ªåŠ¨å¤‡ä»½...", icon="â³")
            success, msg = perform_backup(manual=False)
            if success:
                st.toast(f"è‡ªåŠ¨å¤‡ä»½å®Œæˆï¼\n{msg}", icon="âœ…")
            else:
                st.error(f"è‡ªåŠ¨å¤‡ä»½å¤±è´¥: {msg}")
                
    except Exception as e:
        print(f"Auto backup check failed: {e}")
    finally:
        conn.close()

def page_settings():
    import pandas as pd
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®ä¸ç®¡ç†")
    conn = get_db_connection()
    
    # è¯»å–å½“å‰é…ç½®
    settings = conn.execute('SELECT * FROM system_settings WHERE id = 1').fetchone()
    
    tab1, tab2, tab3 = st.tabs(["ğŸ”„ å¤‡ä»½ç­–ç•¥ä¸é‚®ç®±", "ğŸ“‚ æœ¬åœ°å¤‡ä»½ç®¡ç†", "ğŸ‘¥ æˆå‘˜ç®¡ç†(å±é™©)"])
    
    # === Tab 1: ç­–ç•¥é…ç½® (ä¿æŒä¸å˜) ===
    with tab1:
        st.subheader("1. è‡ªåŠ¨å¤‡ä»½ç­–ç•¥")
        with st.form("settings_form"):
            new_freq = st.radio("å¤‡ä»½é¢‘ç‡", ["å…³é—­", "æ¯å¤©", "æ¯å‘¨", "æ¯æœˆ"], 
                              index=["å…³é—­", "æ¯å¤©", "æ¯å‘¨", "æ¯æœˆ"].index(settings['backup_frequency']),
                              horizontal=True)
            st.divider()
            st.subheader("2. é‚®ç®±æ¨é€è®¾ç½®")
            c1, c2 = st.columns(2)
            with c1:
                email_host = st.text_input("SMTP æœåŠ¡å™¨", value=settings['email_host'] or "")
                email_port = st.number_input("SMTP ç«¯å£", value=settings['email_port'] or 465)
            with c2:
                email_user = st.text_input("é‚®ç®±è´¦å·", value=settings['email_user'] or "")
                email_password = st.text_input("æˆæƒç /å¯†ç ", value=settings['email_password'] or "", type="password")
            email_to = st.text_input("æ¥æ”¶é‚®ç®±", value=settings['email_to'] or "")
            if st.form_submit_button("ğŸ’¾ ä¿å­˜é…ç½®"):
                conn.execute('''UPDATE system_settings SET backup_frequency=?, email_host=?, email_port=?, email_user=?, email_password=?, email_to=? WHERE id=1''', (new_freq, email_host, email_port, email_user, email_password, email_to))
                conn.commit()
                st.success("é…ç½®å·²ä¿å­˜ï¼")
                st.rerun()

    # === Tab 2: æœ¬åœ°ç®¡ç† (ä¿æŒä¸å˜) ===
    with tab2:
        st.subheader("ğŸ“‚ æœ¬åœ°å¤‡ä»½æ–‡ä»¶ç®¡ç†")
        if st.button("ğŸš€ ç«‹å³æ‰‹åŠ¨å¤‡ä»½"):
            success, msg = perform_backup(manual=True)
            if success: st.success(msg); st.rerun()
            else: st.error(msg)
        # ... (æ­¤å¤„çœç•¥éƒ¨åˆ†å±•ç¤ºä»£ç ï¼Œå‡è®¾ä½ å·²ç»æœ‰äº†) ...

    # === Tab 3: æˆå‘˜ç®¡ç† (ä¿®å¤ç‰ˆ) ===
    with tab3:
        st.subheader("ğŸ’€ å±é™©åŒºåŸŸï¼šåˆ é™¤æˆå‘˜")
        st.warning("æ³¨æ„ï¼šæ­¤æ“ä½œä¸å¯é€†ï¼å°†åˆ é™¤è¯¥æˆå‘˜åä¸‹çš„æ‰€æœ‰èµ„äº§ã€è®°å½•å’Œç¬”è®°ã€‚")
        
        # 1. è·å–æ‰€æœ‰ç”¨æˆ·
        all_users = conn.execute('SELECT user_id, username FROM users').fetchall()
        user_options = {u['username']: u['user_id'] for u in all_users}
        
        if not user_options:
            st.info("æš‚æ— ç”¨æˆ·ã€‚")
        else:
            # 2. é€‰æ‹©ç”¨æˆ·
            # æ³¨æ„ï¼šåŠ ä¸Š keyï¼Œé˜²æ­¢åˆ‡æ¢ tab æ—¶çŠ¶æ€ä¸¢å¤±
            target_username = st.selectbox(
                "é€‰æ‹©è¦ç§»é™¤çš„æˆå‘˜", 
                options=list(user_options.keys()),
                key="sel_user_to_del_fixed"
            )
            
            # --- æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨ checkbox è€Œä¸æ˜¯åµŒå¥— button ---
            # Checkbox æœ‰çŠ¶æ€ï¼Œå‹¾é€‰åä¸€ç›´ä¿æŒ Trueï¼Œç›´åˆ°ä½ å–æ¶ˆå‹¾é€‰
            confirm_mode = st.checkbox(f"ğŸ”“ è§£é”åˆ é™¤æŒ‰é’® (ç›®æ ‡: {target_username})", key="del_unlock_checkbox")
            
            if confirm_mode:
                st.error(f"âš ï¸ ä¸¥é‡è­¦å‘Šï¼šä½ ç¡®å®šè¦å½»åº•åˆ é™¤ ã€{target_username}ã€‘ å—ï¼Ÿ")
                st.write("è¯¥æ“ä½œä¼šè¿å¸¦åˆ é™¤ï¼šèµ„äº§è®°å½•ã€å®šæŠ•è®¡åˆ’ã€æ‰€æœ‰ç¬”è®°ã€‚æ•°æ®æ— æ³•æ¢å¤ï¼")
                
                # çœŸæ­£çš„æ‰§è¡ŒæŒ‰é’®
                if st.button("ğŸ§¨ ç¡®è®¤åˆ é™¤", type="primary", key="btn_real_delete"):
                    target_id = user_options[target_username]
                    
                    # æ‰§è¡Œåˆ é™¤
                    success, msg = delete_user_fully(target_id)
                    
                    if success:
                        st.toast(f"æˆå‘˜ {target_username} å·²è¢«ç§»é™¤ã€‚", icon="âœ…")
                        
                        # å¦‚æœåˆ çš„æ˜¯å½“å‰ç™»å½•çš„äººï¼Œæ¸…ç©º session
                        if 'user' in st.session_state and st.session_state.user and st.session_state.user['username'] == target_username:
                            st.session_state.user = None
                        
                        # ç¨å¾®ç­‰ä¸€ä¸‹è®© toast æ˜¾ç¤ºå®Œï¼Œç„¶åå¼ºåˆ¶åˆ·æ–°é¡µé¢
                        import time
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error(msg)

    conn.close()

# ==============================================================================
# ğŸš€ ä¸»ç¨‹åºå…¥å£ (Main) - åŠ¨æ€è¯»å–ç”¨æˆ·ç‰ˆ
# ==============================================================================
def main():
    # 1. åŸºç¡€åˆå§‹åŒ–
    init_db()
    auto_backup_check()

    # --- æ”¹é€ æ ¸å¿ƒï¼šä¾§è¾¹æ ç”¨æˆ·åˆ‡æ¢å™¨ ---
    with st.sidebar:
        st.header("ä¸ªäººèµ„äº§ç®¡ç†ç³»ç»Ÿ")
        
        # 1. åŠ¨æ€è·å–æ•°æ®åº“é‡Œçš„æ‰€æœ‰ç”¨æˆ·
        existing_users = get_all_usernames()
        
        # 2. æ„é€ ä¸‹æ‹‰èœå•é€‰é¡¹ï¼šç°æœ‰ç”¨æˆ· + æ–°å¢é€‰é¡¹
        # å³ä½¿æ•°æ®åº“æ˜¯ç©ºçš„ï¼Œè‡³å°‘ä¼šæœ‰ä¸€ä¸ªâ€œæ–°å¢æˆå‘˜â€çš„é€‰é¡¹
        menu_options = existing_users + ["â• æ–°å¢æˆå‘˜..."]
        
        # 3. ç¡®å®šä¸‹æ‹‰æ¡†çš„é»˜è®¤é€‰ä¸­é¡¹
        # å¦‚æœå½“å‰ session é‡Œå·²ç»ç™»å½•äº†ç”¨æˆ·ï¼Œä¸”è¯¥ç”¨æˆ·åœ¨åˆ—è¡¨é‡Œï¼Œå°±é»˜è®¤é€‰ä¸­ä»–
        # å¦åˆ™é»˜è®¤é€‰åˆ—è¡¨ç¬¬ä¸€ä¸ª
        default_index = 0
        if 'user' in st.session_state and st.session_state.user:
            current_name = st.session_state.user['username']
            if current_name in existing_users:
                default_index = existing_users.index(current_name)
        
        # 4. æ˜¾ç¤ºä¸‹æ‹‰æ¡†
        selected_option = st.selectbox(
            "å½“å‰æˆå‘˜", 
            menu_options, 
            index=default_index,
            key="user_selector_dynamic"
        )

        # 5. åˆ†æ”¯é€»è¾‘ï¼šæ˜¯åˆ‡æ¢è€ç”¨æˆ·ï¼Œè¿˜æ˜¯åˆ›å»ºæ–°ç”¨æˆ·ï¼Ÿ
        if selected_option == "â• æ–°å¢æˆå‘˜...":
            st.info("ğŸ‘‹ æ¬¢è¿æ–°æˆå‘˜åŠ å…¥ï¼")
            new_username = st.text_input("è¯·è¾“å…¥ä½ çš„æ˜µç§°/åå­—", placeholder="ä¾‹å¦‚ï¼šå¥¶å¥¶")
            
            if st.button("ç¡®è®¤åˆ›å»ºå¹¶è¿›å…¥", type="primary"):
                if new_username.strip():
                    if new_username in existing_users:
                        st.error("è¿™ä¸ªåå­—å·²ç»å­˜åœ¨å•¦ï¼Œç›´æ¥åœ¨ä¸‹æ‹‰æ¡†é€‰å°±è¡Œã€‚")
                    else:
                        # è°ƒç”¨ä¹‹å‰çš„ get_or_create å‡½æ•°åˆ›å»ºæ–°ç”¨æˆ·
                        new_user = get_or_create_user_by_name(new_username)
                        st.session_state.user = new_user
                        st.success(f"æ¬¢è¿ {new_username}ï¼")
                        st.rerun() # åˆ·æ–°é¡µé¢ï¼Œè®©æ–°åå­—å‡ºç°åœ¨ä¸‹æ‹‰æ¡†é‡Œ
                else:
                    st.warning("åå­—ä¸èƒ½ä¸ºç©ºå“¦")
            
            # å¦‚æœæ­£åœ¨åˆ›å»ºæ–°ç”¨æˆ·ï¼Œå°±ä¸è¦æ˜¾ç¤ºä¸‹é¢çš„å¯¼èˆªæ äº†ï¼Œå¼ºåˆ¶æš‚åœ
            st.stop()
            
        else:
            # === é€‰ä¸­äº†ç°æœ‰ç”¨æˆ· ===
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢ session
            # å¦‚æœå½“å‰æ²¡ç™»å½•ï¼Œæˆ–è€…ç™»å½•çš„äººè·Ÿé€‰çš„äººä¸ä¸€æ ·ï¼Œå°±åˆ‡æ¢
            if 'user' not in st.session_state or st.session_state.user is None or st.session_state.user['username'] != selected_option:
                user_obj = get_or_create_user_by_name(selected_option) # è¿™é‡Œå…¶å®åªèµ·åˆ° get çš„ä½œç”¨
                st.session_state.user = user_obj
                st.toast(f"å·²åˆ‡æ¢åˆ°è´¦æˆ·: {selected_option}", icon="ğŸ‘‹")
                st.rerun()

        st.divider()

        # === ä»¥ä¸‹æ˜¯åŸæœ¬çš„å¯¼èˆªé€»è¾‘ (ä¿æŒä¸å˜) ===
        # åªæœ‰åœ¨é€‰ä¸­äº†æœ‰æ•ˆç”¨æˆ·åï¼Œæ‰ä¼šæ‰§è¡Œåˆ°è¿™é‡Œ
        
        # A. ç”¨æˆ·ä¿¡æ¯åŒº
        st.caption(f"æ­£åœ¨ç®¡ç† {st.session_state.user['username']} çš„èµ„äº§")
        
        # B. å¯¼èˆªèœå•
        nav_map = {
            "ğŸ“Š èµ„äº§çœ‹æ¿": "nav_dashboard",
            "ğŸ’° ç°é‡‘æµä¸æœ¬é‡‘": "nav_cashflow",
            "ğŸ† ç´¯è®¡æ”¶ç›Š": "nav_performance",
            "ğŸ“’ æŠ•èµ„ç¬”è®°": "nav_notes",
            "ğŸ¦ èµ„äº§ç®¡ç†": "nav_assets",
            "ğŸ“ æ•°æ®å½•å…¥": "nav_entry",
            "ğŸ“… å®šæŠ•è®¡åˆ’": "nav_plans",
            "âš–ï¸ æŠ•èµ„å†å¹³è¡¡": "nav_rebalance",
            "ğŸ”¥ FIREæ¨æ¼”": "nav_fire",
            "âš™ï¸ ç³»ç»Ÿè®¾ç½®": "nav_settings"
        }
        
        selected_label = st.radio("åŠŸèƒ½èœå•", list(nav_map.keys()))
        selected_key = nav_map[selected_label]
        
        # --- åœ¨ main() å‡½æ•°å†…éƒ¨ï¼Œä¾§è¾¹æ é€»è¾‘ä¹‹å ---

        # å¦‚æœæ˜¯ demo è´¦å·ï¼Œæ˜¾ç¤ºå…¨å±€è­¦å‘Š
        if 'user' in st.session_state and st.session_state.user and st.session_state.user['username'] == 'demo':
            st.warning("âš ï¸ **æ¼”ç¤ºæ¨¡å¼ (Demo Mode)**ï¼šå½“å‰å±•ç¤ºæ•°æ®å‡ä¸º AI éšæœºç”Ÿæˆçš„è™šæ‹Ÿæ ·æœ¬ï¼Œä»…ä¾›åŠŸèƒ½æ¼”ç¤ºï¼ŒéçœŸå®èµ„äº§ã€‚", icon="ğŸ¤–")
            # ç”šè‡³å¯ä»¥æä¸ªä¾§è¾¹æ çš„æ°”æ³¡
            st.sidebar.info("å½“å‰å¤„äº Demo æ¼”ç¤ºæ¨¡å¼")

        if IS_RASPBERRY_PI:
            st.divider()
            if st.button("ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ•°æ®"):
                st.cache_data.clear()
                st.toast("ç¼“å­˜å·²æ¸…é™¤ï¼Œæ­£åœ¨é‡æ–°åŠ è½½...", icon="ğŸš€")
                st.rerun()

    # === é¡µé¢è·¯ç”±åˆ†å‘ (ä¿æŒä¸å˜) ===
    if selected_key == "nav_dashboard":
        page_dashboard()
    elif selected_key == "nav_cashflow":
        page_cashflow()
    elif selected_key == "nav_performance":
        page_performance()
    elif selected_key == "nav_notes":
        page_investment_notes()
    elif selected_key == "nav_assets":
        page_assets_tags()
    elif selected_key == "nav_entry":
        page_data_entry()
    elif selected_key == "nav_plans":
        page_investment_plans()
    elif selected_key == "nav_fire":
        page_fire_projection()
    elif selected_key == "nav_settings":
        page_settings()
    elif selected_key == "nav_rebalance":
        page_rebalance()

if __name__ == '__main__':
    main()